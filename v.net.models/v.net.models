#!/bin/env bash
############################################################################
#
# MODULE:     	v.net.models
# AUTHOR(S): 	Benjamin Ducke <benducke AT fastmail.fm>
# PURPOSE:		Model-based reconstruction of a network from points (nodes).
#				This script takes points as input and reconstructs a networkmodel_complete_thread
#             	by adding lines (links) between all or a subset of them. Links 
#				are added according to the chosen connectivity model.
#				Connection costs between nodes are computed as Euclidean (default)
#				For more realism, connection costs and
#				actual link shapes can be modeled as least-cost paths (LCP)
#				between nodes (requires a raster cost surface as additional input).
#
# COMPATIBILITY:
#				This script has been written to run under GRASS 8 (and possibly
#				any later version that retains the GRASS 8 syntax for the GRASS
#				commands called by this script). Care has been taken to allow
#               v.net.models to also run under earlier versions of GRASS.
#
# COPYRIGHT:    (C) 2020 by Benjamin Ducke
#
#               This program is free software under the GNU General Public
#               License (>=v2). Read the file COPYING that comes with GRASS
#               for details.
#
#############################################################################

#
# REQUIRED EXTERNAL PROGRAMS:
# - grep
# - awk
# - echo (on Windows)
# - expr
# - date
# - sort
# - cut
# - pkill
# - sleep
# - wc
#


#%Module
#% description: Performs model-based reconstruction of network links from input points.
#% keywords: vector, points, lines, network, reconstruction
#%End

# TODO: IMPLEMENTME (FLAG -L)!
##%Flag
##%  key: l
##%  description: Link isolated nodes to network if reachable
##%End
#DELETEME: This is only defined, so that the shell tests don't freak out
#if the variable is not defined. Remove once implemented!
GIS_FLAG_L=0

#%Flag
#%  key: k
#%  description: 'Knight's move' for more accurate (but slower) cost computations
#%End

#%Flag
#%  key: m
#%  description: Measure least-cost paths in meters instead of costs
#%End

#%Flag
#%  key: r
#%  description: Reduce input points to those in current region
#%End

#%Flag
#%  key: s
#%  description: Skip input data consistency checks
#%End

#%Option
#% key: input
#% type: string
#% required: yes
#% multiple: no
#% key_desc: name
#% description: Input vector map with network nodes (points)
#% gisprompt: old,vector,vector
#%End

#%option G_OPT_V_FIELD
#% key: layer
#%end

#%option G_OPT_V_CATS
#% key: cats
#%end

#%option G_OPT_DB_WHERE
#% key: where
#%end

#%Option
#% key: initial
#% type: string
#% required: no
#% multiple: no
#% key_desc: name
#% description: Initial links produced by previous run (lines)
#% gisprompt: old,vector,vector
#%End

#%Option
#% key: costmap
#% type: string
#% required: no
#% multiple: no
#% key_desc: name
#% description: Input raster map representing cost surface
#% gisprompt: old,cell,raster
#%End

#%Option
#% key: links
#% type: string
#% required: yes
#% multiple: no
#% key_desc: name
#% description: Output vector map for reconstructed network links (lines)
#% gisprompt: new,vector,vector
#%End

#%Option
#% key: nodes
#% type: string
#% required: yes
#% multiple: no
#% key_desc: name
#% description: Output vector map for attributed network nodes (points)
#% gisprompt: new,vector,vector
#%End

#%Option G_OPT_DB_COLUMN
#% key: key
#% required: yes
#% description: Name of INTEGER key field in input nodes' attribute table
#% gisprompt: old,dbcolumn,dbcolumn
#%End

#%option G_OPT_DB_COLUMN
#% key: label
#% required: no
#% description: Name of label/name field (default: same as 'key')
#% gisprompt: old,dbcolumn,dbcolumn
#%end

#%Option
#% key: model
#% type: string
#% required: yes
#% multiple: no
#% key_desc: value
#% options: attsim,complete,delaunay,nn,xtent
#% description: Choice of network connectivity model
#% answer: complete
#%End

#%Option G_OPT_DB_COLUMN
#% key: attributes
#% required: no
#% multiple: yes
#% description: Attribute field(s) for similarity test(s) (model 'attsim')
#% gisprompt: old,dbcolumn,dbcolumn
#%End

#%Option
#% key: neighbors
#% type: integer
#% required: no
#% multiple: no
#% key_desc: value
#% description: Number of nearest neighbors to connect (model 'nn')
#%End

#%Option
#% key: maxdist
#% type: double
#% required: no
#% multiple: no
#% key_desc: value
#% description: Absolute cost/distance threshold (several models)
#%End

#%Option G_OPT_DB_COLUMN
#% key: size
#% required: no
#% description: Numeric attribute field with node 'size' (models 'xtent', 'nn')
#% gisprompt: old,dbcolumn,dbcolumn
#%End

#%Option
#% key: a
#% type: double
#% required: no
#% multiple: no
#% key_desc: value
#% description: Exponential size weight 'a' (model 'xtent')
#%End

#%Option
#% key: k
#% type: double
#% required: no
#% multiple: no
#% key_desc: value
#% description: Linear distance weight 'k' (model 'xtent')
#%End

#%Option
#% key: avg
#% type: string
#% required: no
#% multiple: no
#% key_desc: value
#% options: mean,median
#% description: Distance averaging function (model 'xtent')
#% answer: mean
#%End

#%Option
#% key: costsyn
#% type: double
#% required: no
#% multiple: no
#% key_desc: value
#% description: Cost synergy effect of re-using network links (requires 'costmap')
#% options: 0.0-1.0
#% answer: 0.0
#%End

#%Option
#% key: costerr
#% type: double
#% required: no
#% multiple: no
#% key_desc: value
#% description: Costmap error margin (+/-) in percent (requires 'costmap')
#% options: 0.0-100.0
#% answer: 0.0
#%End

#%Option
#% key: costres
#% type: integer
#% required: no
#% multiple: no
#% key_desc: value
#% description: Costmap resampling factor (requires 'costmap' and 'costerr')
#% options: 1-10
#% answer: 1
#%End

#%Option
#% key: costmem
#% type: integer
#% required: no
#% multiple: no
#% key_desc: value
#% description: Max. memory for cost raster ops in MB (passed to 'r.cost')
#% options: 300-300000
#% answer: 300
#%End

#%Option
#% key: threshold
#% type: double
#% required: no
#% multiple: no
#% key_desc: value
#% description: Threshold distance for topology tests (0=skip)
#% options: 0.0-100000000
#% answer: 0.000001
#%End

#%Option
#% key: threads
#% type: integer
#% required: no
#% multiple: no
#% key_desc: value
#% description: Number of concurrent processing threads (1=no concurrency) 
#% options: 1-1024
#% answer: 1
#%End

#%Option
#% key: sqlbuflen
#% type: integer
#% required: no
#% multiple: no
#% key_desc: value
#% answer: 20
#% options: 1-1000
#% description: Number of SQL statements to buffer (performance)
#%End

# System setup: Modify if needed.
if [ -n "${MSYSPATH}" ] ; then
	# "MSYSPATH" was set by the Windows ".bat" script that called
	# this script. It contains the path to the "bin" folder of
	# the local MSYS(2) installation, using Linux style "/" separators
	# but NOT INCLUDING the final path separator, like so:
	# "/c/msys64/usr/bin"
	# That means we are running under MS Windows,
	# and we must make some adjustments to external program calls!
	AWK="${MSYSPATH}/awk.exe"
	CUT="${MSYSPATH}/cut.exe"
	DATE="${MSYSPATH}/date.exe"
	ECHO="${MSYSPATH}/echo.exe"
	EXPR="${MSYSPATH}/expr.exe"
	GREP="${MSYSPATH}/grep.exe"
	SLEEP="${MSYSPATH}/sleep.exe"
	SORT="${MSYSPATH}/sort.exe"
	WAIT="wait" # Builtin command of Bash
	WC="${MSYSPATH}/wc.exe"
	# These are the GRASS commands that are actually Shell/Python scripts.
	# On Windows, they must be called with their ".bat" extensions, or the shell won't find them!
	R_GROW="r.grow.bat"
	V_DB_ADDCOLUMN="v.db.addcolumn.bat"
	V_DB_ADDTABLE="v.db.addtable.bat"
	V_DB_DROPCOLUMN="v.db.dropcolumn.bat"
	V_DB_DROPROW="v.db.droprow.bat"
	V_DB_DROPTABLE="v.db.droptable.bat"
	V_DB_UPDATE="v.db.update.bat"
	V_TO_LINES="v.to.lines.bat"
	# Set filter for line endings for this system:
	IFS_NEWLINE=$'\r\n\b'
else
	# Linux and macOS: Use default built-in commands
	AWK="awk"
	CUT="cut"
	DATE="date"
	ECHO="echo"
	EXPR="expr"
	GREP="grep"
	PKILL="pkill"
	SLEEP="sleep"
	SORT="sort"	
	WAIT="wait"
	WC="wc"
	# These are the GRASS commands that are actually Shell/Python scripts.
	# On Linux/macOS they are called by this script just like binaries.
	R_GROW="r.grow"
	V_DB_ADDCOLUMN="v.db.addcolumn"
	V_DB_ADDTABLE="v.db.addtable"
	V_DB_DROPCOLUMN="v.db.dropcolumn"
	V_DB_DROPROW="v.db.droprow"
	V_DB_DROPTABLE="v.db.droptable"
	V_DB_UPDATE="v.db.update"
	V_TO_LINES="v.to.lines"
	# Set filter for line endings for this system:
	IFS_NEWLINE=$'\n\b'
fi

# Keep a copy of IFS, as it was set before running this script!
IFS_ORIGINAL="$IFS"

# Basic module setup.
MODULE_NAME="v_net_models" # for prefixing temporary object names
MODULE_NAME_EXEC="v.net.models" # name as run on the command line
MODULE_VERSION="1.1.0b1"

# Exit status variables.
EXIT_OK=0
EXIT_CTRL_C=1
EXIT_TERMINATED=2
EXIT_ERROR=3

# Processing states.
RUNMODE_COST="FALSE" # Cost-based processing mode

# DBMS backend idiosyncracies
DBMS_LOCKS_REQUIRED=0   # DBMS locking off (will be set later, as required)
DBMS_THREAD_SAFE=0		# Indicates whether the DBMS is thread safe (in the context of this script)
DBMS_INDEX_SUPPORTED=0  # Indicates whether the DBMS supports building an index.
DBMS_PRESERVES_ORDER=0  # Indicates whether the DBMS preserves order of record insertion reliably.
DBMS_FILE_PATH=0		# Indicates whether the DBMS driver uses a file path to specify the location of a database
DBMS_IDENT_QUOTE='"'	# Quoting character for field/table names that (might) contain spaces
DBMS_BEGIN="BEGIN;"		# Opening statement for an SQL transction; most DBMS should understand "BEGIN;"
DBMS_COMMIT="COMMIT;";	# Closing statement for an SQL transction; most DBMS should understand "COMMIT;"
LABEL_TYPE_OUT="TEXT"   # Default type for creating new label fields that might contain lots of text	

# Basic sanity checks.
if [ -z "$GISBASE" ] ; then
    "${ECHO}" "ERROR: You must be in GRASS GIS to run this program." 1>&2
    exit ${EXIT_ERROR}
fi

if [ "$1" != "@ARGS_PARSED@" ] ; then
    exec g.parser "$0" "$@"
fi

# Check if we are running under old GRASS 6
GRASS_V6=`g.version -e | "${GREP}" "GRASS 6"`

# Check if we are running under old GRASS 7
GRASS_V7=`g.version -e | "${GREP}" "GRASS 7"`

# Check if we are running under old GRASS 8
GRASS_V8=`g.version -e | "${GREP}" "GRASS 8"`

if [ -n "$GRASS_V6" ] ; then
	g.message -e "This script requires GRASS GIS version 7 or higher."
	exit ${EXIT_ERROR}
fi

# Create prefix for all temporary maps
TMP_PREFIX="tmp_${MODULE_NAME}_`"${ECHO}" $$`_d"

# Names of temporary maps (VECTOR)
TMP_VECT_NODES="${TMP_PREFIX}_v_nodes" 					# Input nodes (after WHERE and layer= options applied)
TMP_VECT_REGION="${TMP_PREFIX}_v_region" 				# Polygon that represents bbox of current GRASS region
TMP_VECT_SELECT="${TMP_PREFIX}_v_select" 				# Input points, reduced to those in current region
TMP_VECT_SORT="${TMP_PREFIX}_v_sort" 					# Input points, strictly sorted by primary keys of their attribute records
TMP_VECT_EXTRACT="${TMP_PREFIX}_v_extract" 				# Feature(s) extracted from input vector map
TMP_VECT_EXTRACT2="${TMP_PREFIX}_v_extract" 			# Feature(s) extracted from input vector map (2)
TMP_VECT_LINKS="${TMP_PREFIX}_v_links" 					# Newly created network links (lines)
TMP_VECT_LINKS_ADD="${TMP_PREFIX}_v_links_add" 			# Additional network links (lines) to add to links output map
TMP_VECT_LINKS_CAT="${TMP_PREFIX}_v_links_cat" 			# Network links (lines) with rebuilt category IDs
TMP_VECT_LINKS_COSTS="${TMP_PREFIX}_v_links_costs" 		# Stores from-to costs for each pair of links (cost-based mode only)
TMP_VECT_LINKS_SMOOTH="${TMP_PREFIX}_v_smoothed" 		# Smoothed least-cost paths
TMP_VECT_LINKS_CLEAN="${TMP_PREFIX}_v_cleaned" 			# Cleaned least-cost paths
TMP_VECT_LINKS_DROPROW_1="${TMP_PREFIX}_v_l_droprow_1" 	# Links with row dropped from table
TMP_VECT_LINKS_DROPROW_2="${TMP_PREFIX}_v_l_droprow_2" 	# Links with row dropped from table (swapped)
TMP_VECT_LINKS_DELAUNAY_P="${TMP_PREFIX}_v_delaunay_p" 	# Delaunay mesh (polygon)
TMP_VECT_LINKS_DELAUNAY_L="${TMP_PREFIX}_v_delaunay_l" 	# Delaunay mesh (lines)
TMP_VECT_NODES_DROPROW_1="${TMP_PREFIX}_v_n_droprow_1" 	# Nodes with row dropped from table
TMP_VECT_NODES_DROPROW_2="${TMP_PREFIX}_v_n_droprow_2"	# Nodes with row dropped from table (swapped)
TMP_VECT_LINKS_PATCH="${TMP_PREFIX}_v_l_patch" 			# BASE name of one vector map patch for model_complete
TMP_VECT_NODES_ALIGNED="${TMP_PREFIX}_v_n_aligned"		# Cost raster-aligned input nodes
TMP_VECT_NODES_ORDER="${TMP_PREFIX}_v_n_order" 			# Strictly ordered copy of original input points map

# Names of temporary maps (RASTER)
TMP_RAST_COST_RSP="${TMP_PREFIX}_r_cost_rsp" # Resampled version of original cost raster map
TMP_RAST_COST_MIN="${TMP_PREFIX}_r_cost_min" # Minimum cost output of r.cost
TMP_RAST_COST_DIR="${TMP_PREFIX}_r_cost_dir" # Directional surface output r.cost
TMP_RAST_COST_ERR="${TMP_PREFIX}_r_cost_err" # Directional surface output r.cost (random error)
TMP_RAST_COST_NRM="${TMP_PREFIX}_r_cost_nrm" # Directional surface output r.cost (normalized random error)
TMP_RAST_COST_SYN="${TMP_PREFIX}_r_cost_syn" # Directional surface output r.cost (cost synergy effect)
TMP_RAST_COST_SYN2="${TMP_PREFIX}_r_cost_syn2" # Directional surface output r.cost (cost synergy effect, backup map)
TMP_RAST_RSTLNKS1="${TMP_PREFIX}_r_rstlnks1" # Rasterized link from map supplied via "initial="
TMP_RAST_RSTLNKS2="${TMP_PREFIX}_r_rstlnks2" # Rasterized link from map supplied via "initial=" (version 2)
TMP_RAST_MAPCALC1="${TMP_PREFIX}_r_mapcalc1" # Temporary output of an r.mapcalc run (1)
TMP_RAST_NODES_RASTERIZED="${TMP_PREFIX}_r_nodes_rast" # Rasterized input nodes.

# Names of temporary fields
TMP_FLD_DIST="${TMP_PREFIX}_f_dist" # Dummy field for mandatory 'upload=' option of v.distance.

# Names of temporary regions
TMP_GEN_REGION_ORG="${TMP_PREFIX}_g_region_org" # Original region settings

# Reserved names of attribute table fields that will be added to LINKS output map
LINKS_FLD_KEY="cat"				# Default GRASS primary key
LINKS_FLD_FROM_ID="from_id"		# ID of start node
LINKS_FLD_TO_ID="to_id"			# ID of end node
LINKS_FLD_FROM_LBL="from_lbl"	# Label (name) of start node
LINKS_FLD_TO_LBL="to_lbl"		# Label (name) of end node
LINKS_FLD_FROM_X="from_x"		# X coordinates of start node.
LINKS_FLD_FROM_Y="from_y"		# Y coordinates of start node.
LINKS_FLD_TO_X="to_x"			# X coordinates of end node.
LINKS_FLD_TO_Y="to_y"			# Y coordinates of end node.
LINKS_FLD_LEN_M="length_m"		# Total length of link in meters
LINKS_FLD_LEN_KM="length_km" 	# Total length of link in kilometers
LINKS_FLD_COST="cost"			# Total cost of link in unspecified units (will only exist if 'costmap=" provided)
LINKS_FLD_STRENGTH="strength"	# Link strength (number of similarities: will only exist for model 'attsim')

# Reserved names of attribute table fields that will be added to NODES output map
NODES_FLD_COORD_X="coordx" 		# Input node X coordinate
NODES_FLD_COORD_Y="coordy" 		# Input node Y coordinate

# FUNCTION
# grass_db_connect_default: Restores current GRASS session's initial database
# connection parameters. This function is used extensively by 'model_complete_thread()'
# to switch between a thread's local (temporary) database storage and that of the
# GRASS session running this script. It is also called by clean_up, to make sure
# that this script does not mess with a user's database connection parameters.
#
# This locking mechanism will only run if the current mapset uses a DBMS that
# is not safe for multi-threaded operations, and if this script is actually running
# in multi-threading mode!
#
grass_db_connect_default () {
	if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
		if [ -n "${GRASS_DB_driver}" ] ; then
			# DEBUG
			#echo "Restore GRASS DB driver = '${GRASS_DB_driver}'"
			db.connect driver="${GRASS_DB_driver}"
			check_error "Failed to restore GRASS session's default database connection ('db.connect driver=${GRASS_DB_driver}')."
		fi
	
		if [ -n "${GRASS_DB_database}" ] ; then
			# DEBUG
			#echo "Restore GRASS DB database = '${GRASS_DB_database}'"
			db.connect database="${GRASS_DB_database}"	
			check_error "Failed to restore GRASS session's default database connection ('db.connect database=${GRASS_DB_database}')."
		fi
	fi
}


# FUNCTION
# grass_db_connect_local: Sets current GRASS session's database connection.
# This function is used extensively by 'model_complete_thread()'
# to switch database storage from the current GRASS session's default to
# a temporary SQlite file. This is required to avoid database corruption
# when running multi-threaded processes.
#
# Arguments:
#	$1 - name of local database file (passed by caller as a unique SQLite file name)
#
# This locking mechanism will only run if the current mapset uses a DBMS that
# is not safe for multi-threaded operations, and if this script is actually running
# in multi-threading mode!
#
grass_db_connect_local () {
	if [ ${GIS_OPT_THREADS} -eq 1 ] ; then
		# If we are not running in multi-threading mode, then we return
		# immediately: No need to handle all of the below!
		return
	fi
	
	if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
		if [ -n "$1" ] ; then
			db.connect driver="sqlite" database='$GISDBASE/$LOCATION_NAME/$MAPSET/sqlite/'"$1"
			check_error "Failed to set GRASS session's database connection ('db.connect driver=sqlite' database=$GISDBASE/$LOCATION_NAME/$MAPSET/sqlite/$1)."
		else
			check_error "Cannot set GRASS session's database connection to an empty value."	
		fi
	fi	
}


# FUNCTION
# clean_up: Remove temporary maps, reset region to what it was, etc.
clean_up () {	
	
	g.message -i "Cleaning up..."
	
	# Temporary VECTOR maps
	type="vector"
	# Extracted nodes from input vector map.
	elem="${TMP_VECT_NODES}"	
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Nodes extracted from input vector map by multi-threaded process.
	elem="${TMP_VECT_NODES}"
	g.remove type="${type}" pattern="${elem}_*" -f --q 2>/dev/null
	
	# Polygonal bbox of current GRASS region.
	elem="${TMP_VECT_REGION}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Input points reduced to within current region.
	elem="${TMP_VECT_SELECT}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Input points sorted by attribute primary keys.
	elem="${TMP_VECT_SORT}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Feature(s) extracted from input vector map.
	elem="${TMP_VECT_EXTRACT}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Feature(s) extracted from input vector map by multi-threaded process.
	elem="${TMP_VECT_EXTRACT}"
	g.remove type="${type}" pattern="${elem}_*" -f --q 2>/dev/null
	
	# Feature(s) extracted from input vector map (2).
	elem="${TMP_VECT_EXTRACT2}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Lines representing newly created network links.
	elem="${TMP_VECT_LINKS}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Additional network links (lines) to add to links output map.
	elem="${TMP_VECT_LINKS_ADD}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi	
	# Network links (lines) with rebuilt category IDs. 
	elem="${TMP_VECT_LINKS_CAT}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Stores from-to costs for each pair of links (cost-based mode only) 
	elem="${TMP_VECT_LINKS_COSTS}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Smoothed least-cost paths. 
	elem="${TMP_VECT_LINKS_SMOOTH}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Cleaned least-cost paths. 
	elem="${TMP_VECT_LINKS_CLEAN}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Links with row dropped from table
	elem="${TMP_VECT_LINKS_DROPROW_1}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Links with row dropped from table (swapped)
	elem="${TMP_VECT_LINKS_DROPROW_2}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Nodes with row dropped from table
	elem="${TMP_VECT_NODES_DROPROW_1}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Nodes with row dropped from table (swapped)
	elem="${TMP_VECT_NODES_DROPROW_2}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Delaunay mesh (polygon)
	elem="${TMP_VECT_LINKS_DELAUNAY_P}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Delaunay mesh (lines)
	elem="${TMP_VECT_LINKS_DELAUNAY_L}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Patched maps generated by model_complete:
	# There are 1 or more such maps: use a pattern to find them
	# all and remove them!
	elem="${TMP_VECT_LINKS_PATCH}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" pattern="${elem}_*" -f --q 2>/dev/null
	fi
	# Copy of original input nodes, aligned to region's raster cells
	elem="${TMP_VECT_NODES_ALIGNED}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Strictly ordered copy of original input points map
	elem="${TMP_VECT_NODES_ORDER}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Temporary RASTER maps
	type="raster"
	# Resampled version of original cost raster map
	elem="${TMP_RAST_COST_RSP}"
	 found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Minimum cost output of r.cost	
	elem="${TMP_RAST_COST_MIN}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Cost maps produced by multi-threaded process
	elem="${TMP_RAST_COST_MIN}"
	g.remove type="${type}" pattern="${elem}_*" -f --q 2>/dev/null
	# Directional surface output of r.cost
	elem="${TMP_RAST_COST_DIR}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Directional surfaces produced by multi-threaded process
	elem="${TMP_RAST_COST_DIR}"
	g.remove type="${type}" pattern="${elem}_*" -f --q 2>/dev/null
	# Directional surface output of r.cost (with added random error)
	elem="${TMP_RAST_COST_ERR}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Directional surface output of r.cost (normalized random error)
	elem="${TMP_RAST_COST_NRM}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Directional surface output of r.cost (cost synergy effect)
	elem="${TMP_RAST_COST_SYN}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Directional surface output of r.cost (cost synergy effect, backup map)
	elem="${TMP_RAST_COST_SYN2}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	 # Rasterized link from map supplied via "initial="
	elem="${TMP_RAST_RSTLNKS1}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Rasterized link from map supplied via "initial=" (2nd version)
	elem="${TMP_RAST_RSTLNKS2}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Temporary output of an r.mapcalc run (1)
	elem="${TMP_RAST_MAPCALC1}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	# Temporary map of rasterized input nodes (points)
	elem="${TMP_RAST_NODES_RASTERIZED}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	
	# Temporary REGIONS
	type="region"
	# Restore saved (original) region
	elem="${TMP_GEN_REGION_ORG}"
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.region region="${TMP_GEN_REGION_ORG}"
		if [ ! "$?" -eq "0" ] ; then
			g.message -i "FAILED to restore original GRASS region. Please check and adjust manually if required (g.region)."
		else
			g.message -i "Restored original GRASS region."
		fi
		g.remove type="${type}" name="${elem}" -f --q 2>/dev/null
	fi
	
	# Switch back to default DB driver and database:
	if [ -n "${GRASS_DB_driver}" ] ; then
		db.connect driver="${GRASS_DB_driver}"
		check_error "Failed to restore GRASS session's default database connection ('db.connect driver=${GRASS_DB_driver}')."
	fi
	if [ -n "${GRASS_DB_database}" ] ; then
		db.connect database="${GRASS_DB_database}"	
		check_error "Failed to restore GRASS session's default database connection ('db.connect database=${GRASS_DB_database}')."
	fi
}


# FUNCTION
# clean_output: Remove any (partial) output data if program aborted with an error.
clean_output () {
	# Output VECTOR maps
	type="vector"
	# Result map (links).
	elem="${GIS_OPT_LINKS}"	
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q
	fi
	# Result map (nodes).
	elem="${GIS_OPT_NODES}"	
	found=`g.list type="${type}" | "${GREP}" -c "${elem}"`
	if [ $found -gt 0 ] ; then
		g.remove type="${type}" name="${elem}" -f --q
	fi
}


# Make sure we get to clean up!
trap "g.message -i 'Terminated by user (CTRL+C).' ; clean_up ; exit ${EXIT_CTRL_C}" 2 # user interrupt (CTRL+C)
#trap "'Unexpected termination.' ; clean_up ; exit ${EXIT_TERMINATED}" 1 # external interrupt


# FUNCTION
# clean_links: Remove links output map: This can be done to get rid of a transient
#				version of the links output map (e.g. when incrementally re-writing
#				that map, to avoid useless warnings from g.remove).
clean_links () {
	found=`g.list type="vector" | "${GREP}" -c "${GIS_OPT_LINKS}"`
	if [ $found -gt 0 ] ; then
		g.remove type="vector" name="${GIS_OPT_LINKS}" -f --q
	fi
}


# FUNCTION
# check_error: Check last return status, issue an error message and abort if appropriate.
#
# Arguments:
#
# $1 - Error message to display (mandatory)
# $2 - PID (optional)
#
# At least $1 must be provided (error message) for this function to
# work correctly.
#
# If $2 is also provided, then its value will be interpreted as
# an integer type PID, and a 'kill' command with Signal type '1'
# will be issued to terminate the corresponding job.
#
check_error () {
	if [ ! "$?" -eq "0" ] ; then
		g.message -e "$1"
		if [ -n "${PKILL}" ] && [ -n $2 ] && [ "$2" != "" ] ; then
			# PID passed and "pkill" command available: kill this and all
			# subprocesses!
			clean_up
			g.message -e "Terminating job with PID $2 and all subprocesses."	
			"${PKILL}" --signal 9 -P $2 &
			exit ${EXIT_ERROR}
		else
			clean_up
			clean_output
			exit ${EXIT_ERROR}
		fi		
	fi
}


# FUNCTION
# check_warn: Check last return status, issue a warning message if appropriate.
check_warn () {
	if [ ! "$?" -eq "0" ] ; then
		g.message -w "$1"
	fi
}


# FUNCTION
# exit_error: Display an error message and exit with default error code.
# 
# Arguments:
#
# $1 - Error message to display (mandatory)
# $2 - PID (optional)
#
# At least $1 must be provided (error message) for this function to
# work correctly.
#
# If $2 is also provided, then its value will be interpreted as
# an integer type PID, and a 'kill' command with Signal type '1'
# will be issued to terminate the corresponding job.
#
exit_error () {
	g.message -e "$1"	
	if [ -n $2 ] && [ "$2" != "" ] ; then
	    # PID passed: kill!
	    # Note: The trap set at the beginning of this script will make
	    # sure that all clean-up functions are run.
	    g.message -e "Terminating job with PID $2."
		#kill -s 1 $2
		clean_up
		clean_output
		exit ${EXIT_ERROR}
	else
		clean_up
		clean_output
		exit ${EXIT_ERROR}
	fi	
}


# FUNCTION
# eval_ws_safe:  White-space resilient setting of variables from command output.
#                This is useful for many GRASS commands that produce shell style
#				  output (like 'g.region -pg') of the form:
#                   var1=abc
#                   var2=123
#                   ...
#                Pass string with a command's full output as $1.
#                Pass name of a variable to set from output as $2.
#                This function will then grep the _first_ occurrence
#                of the variable name (case sensitive!) from the command output
#                and set it to the value following "=" (equal sign).
#				  As opposed to a simple 'eval', this function is able
#                to correctly set variable values that contain whitespace!
#				  This is also the safer option to use if an 'eval' statement would
#                potentially encounter values with white space for variables other
#			 	  than the target variable.
#                The contents for setting the variable are returend in "EVAL_RESULT".
eval_ws_safe () {
	OLD_IFS_EVAL_WS_SAFE="$IFS"
	IFS="${IFS_NEWLINE}"
	# Process (list of) input line(s):
	str=`"${ECHO}" "$1" | "${GREP}" "$2="`
	for i in $str
	do
		IFS="="
		CUR=$i
		for j in $CUR
		do			
			EVAL_RESULT="$j"
		done
	done	
	IFS="$OLD_IFS_EVAL_WS_SAFE"
}


# FUNCTION
# get_primary_keys: Build array of primary key values (from field chosen via 'key=' option).
#                   FUNCTION check_input MUST RUN FIRST to validate GIS_OPT_KEY!!!
#				 	The only argument for this function ($1) is the name of the GRASS vector
#                   map from which to gather the keys.
#					The name of the primary key field is read from $GIS_OPT_KEY.
#                   Primary keys are returned in array PRIMARY_KEYS.
#                   This function will abort the program if it encounters any errors!
#
#					WARNING: Make sure to set IFS correctly when parsing PRIMARY_KEYS as
#					returned by this function!
#
get_primary_keys () {
	PRIMARY_KEYS=`v.db.select map="$1" columns="${GIS_OPT_KEY}" -c --quiet`
	check_error "Failed to retrieve primary keys (map='$1')."
}


# FUNCTION
# get_grass_cats:	Build array of all GRASS internal primary key values for map in $1.
#					Normally, these keys are in the 'cats' column, but this is customizable,
#					so this function makes sure to get the correct column name from the
#					map's metadata first.
#                 	The only argument for this function ($1) is the name of the GRASS vector
#                  	map from which to gather the keys.
#                 	Primary keys are returned in array GRASS_CATS.
#					Name of GRASS primary key column for map '$1' is returned in variable GRASS_PKEY. 
#                 	This function will abort the program if it encounters any errors!
#
#					WARNING: Make sure to set IFS correctly when parsing GRASS_CATS as
#					returned by this function!
#
get_grass_cats () {
	cmd=`v.info -e map="$1"`
	check_error "Failed to query vector map '$1' for extended metadata."
	eval_ws_safe "${cmd}" "attribute_primary_key"
	if [ -z "${EVAL_RESULT}" ] ; then
		exit_error "Failed to retrieve name of GRASS primary key column for vector map '$1'."
	fi
	GRASS_CATS=`v.db.select map="$1" columns="${EVAL_RESULT}" -c --quiet`
	GRASS_PKEY="${EVAL_RESULT}"
	check_error "Failed to retrieve list of GRASS primary keys (map='$1')."
}


# FUNCTION
# get_label: 	Gets the label for the input site's record with a given primary key.
#			  	FUNCTION check_input MUST RUN FIRST to validate GIS_OPT_LABEL!!!
#			  	Labels are used for making messages and result tables more readable
#			  	if the primary key is a simple 'anonymous' index. Labels could be
#			  	e.g. names of towns in the network.
#            	By default, the label field is the same as the primary key field.
#				The name of the label field is read from $GIS_OPT_LABEL.
#            	This function reads two arguments:
#				$1 -- name of GRASS vector map from which to read primary key and label
#				$2 -- value of primary key for which to retrieve label
#				The label value will be written into the variable LABEL.
get_label () {
	if [ "${GIS_OPT_LABEL}" = "${GIS_OPT_KEY}" ] ; then
		LABEL="$2" # label field = key field
	else		 
		if [ "${LABEL_TYPE}" = "CHARACTER" ] || [ "${LABEL_TYPE}" = "TEXT" ] ; then
				LABEL=`v.db.select map="$1" columns="${GIS_OPT_LABEL}" where="${GIS_OPT_KEY}='$2'" -c --quiet`
			else
				LABEL=`v.db.select map="$1" columns="${GIS_OPT_LABEL}" where="${GIS_OPT_KEY}=$2" -c --quiet`
			fi		
	fi
	check_error "Failed to retrieve label for primary key value '${2}' (map='$1')."
}


# FUNCTION
# get_label_fast: 
#				This function is a faster replacement for get_label(), which
#				uses db.select for access to the attribute database.
# 
#            	This function reads the same two arguments as get_label():
#				$1 -- name of GRASS vector map TABLE from which to read primary key and label
#				$2 -- value of primary key for which to retrieve label
#				... PLUS three more which tell db.execute exactly what source to query
#				$4 -- DB driver name
#				$5 -- database name
#
#				The label value will be written into the variable LABEL.
get_label_fast () {
	if [ "${GIS_OPT_LABEL}" = "${GIS_OPT_KEY}" ] ; then
		LABEL="$2" # label field = key field
	else		 
		if [ "${LABEL_TYPE}" = "CHARACTER" ] || [ "${LABEL_TYPE}" = "TEXT" ] ; then
				LABEL=`db.select sql="SELECT ${GIS_OPT_LABEL} FROM ${1} WHERE ${GIS_OPT_KEY}='${2}';" driver="${3}" database="${4}" -c --quiet`
			else
				LABEL=`db.select sql="SELECT ${GIS_OPT_LABEL} FROM ${1} WHERE ${GIS_OPT_KEY}=${2};" driver="${3}" database="${4}" -c --quiet`
			fi		
	fi
	check_error "Failed to retrieve label for primary key value '${2}' (map='${1}')."
}


# FUNCTION
# get_label_no_spaces: 	Gets the label for the input site's record with a given primary key.
#			  				This function is identical to 'get_label', except that it replaces
#							spaces with '_' (underscore). 
get_label_no_spaces () {
	if [ "${GIS_OPT_LABEL}" = "${GIS_OPT_KEY}" ] ; then
		LABEL="$2" # label field = key field
	else		 
		if [ "${LABEL_TYPE}" = "CHARACTER" ] || [ "${LABEL_TYPE}" = "TEXT" ] ; then
				LABEL=`v.db.select map="$1" columns="${GIS_OPT_LABEL}" where="${GIS_OPT_KEY}='$2'" -c --quiet | "${AWK}" '{ gsub (" ", "_", $0); print}'`
			else
				LABEL=`v.db.select map="$1" columns="${GIS_OPT_LABEL}" where="${GIS_OPT_KEY}=$2" -c --quiet | "${AWK}" '{ gsub (" ", "_", $0); print}'`
			fi		
	fi
	check_error "Failed to retrieve label for primary key value '${2}' (map='$1')."
}


# FUNCTION
# get_where_clause:		Composes an SQL 'where' clause to be used in a "where=" option
#						of a GRASS module. The clause can be used to retrieve the feature
#						that matches the value of the primary key passed in $1.
#						This function will take care that field names and values are
#						properly quoted, the latter depending on the type of the primary
#						key.
#						The name of the primary key is read from ${GIS_OPT_KEY}.
#						The resulting clause will be written into the variable WHERE.
#
get_where_clause () {
	WHERE="${GIS_OPT_KEY}=$1"
}


# FUNCTION
# get_where_clause_inv:	Same as get_where_clause, but with inverted result, i.e.
#						This function generates a 'where' clauses suitable for
#						retrieving all features that do _not_ match the primary
#						key value.
#
get_where_clause_inv () {
	WHERE="${GIS_OPT_KEY}<>$1"
}


# FUNCTION
# get_tbl_info: Retrieves essential information for first attribute table's DB connection
#				("layer 1") connected to a GRASS vector map. The information is read from
#				the output of 'v.info'.
#
#            	This function reads one argument:
#					$1 -- name of GRASS vector map that has the attibute table of interest
#
#            	This function sets three variables:
#               	attribute_database_driver = GRASS database driver used for the connection
#												(same as used/listed by 'db.connect')
#					attribute_database = the name of the actual DB that stores the table
#					attribute_table = the name of the linked attribute table in the DB
#
#				 It will abort the program if there is a problem with the map and/or its table.            
#
get_tbl_info () {
	cmd=`v.info -e map="${1}" layer="1"`
	check_error "Failed to query vector map '$1' for extended metadata."
	
	# Get DB driver name:
	eval_ws_safe "${cmd}" "attribute_database_driver"
	if [ -z "${EVAL_RESULT}" ] ; then
		exit_error "Failed to retrieve driver of database connection for vector map '1'."
	fi
	attribute_database_driver="${EVAL_RESULT}"
	
	# Get name of connected database:
	eval_ws_safe "${cmd}" "attribute_database"
	if [ -z "${EVAL_RESULT}" ] ; then
		exit_error "Failed to retrieve name of database connection for vector map '$1'."
	fi
	attribute_database="${EVAL_RESULT}"
	
	# Get name of linked table in conntected DB:
	eval_ws_safe "${cmd}" "attribute_table"
	if [ -z "${EVAL_RESULT}" ] ; then
		exit_error "Failed to retrieve name of database table for vector map '1'."
	fi
	attribute_table="${EVAL_RESULT}"
}


# FUNCTION
# add_index: Adds an index for an attribute table to speed up query operations.
#            This will only work if the driver supports it (SQLite or PostgreSQL).
#            Only the attribute table connected to layer 1 is supported.
#
#            This function reads two arguments:
#				$1 -- name of GRASS vector map that has the attibute table
#				$2 -- name of field for which to add the index
#
#            This function returns nothing. It will abort the program if there
#            is a fundamental problem with the map and/or its table.
#            It will only warn if the index could not be build (performance impairment only).
#
add_index () {
	if [ ${DBMS_INDEX_SUPPORTED} -eq 1 ] ; then
		# Store existing connection information:
		attribute_database_driver_BAK="${attribute_database_driver}"
		attribute_database_BAK="${attribute_database}"
		attribute_table_BAK="${attribute_table}"
		# Get fresh info for this function:
		get_tbl_info "$1"
		# Build index for specified map and field.
		db.execute sql="CREATE INDEX ${attribute_table}_${2}_idx ON ${attribute_table}($2)" database="${attribute_database}"	
		# Restore existing connection information:
		attribute_database_driver="${attribute_database_driver_BAK}"
		attribute_database="${attribute_database_BAK}"
		attribute_table="${attribute_table_BAK}"}
	else
		# Driver not supported: Warn.
		g.message -w "Cannot build an index for database connections of type '${attribute_database_driver}'."
	fi
}


# FUNCTION
# del_index: Deletes (drops) an index for an attribute table.
#            This will only work if the driver supports it (SQLite or PostgreSQL).
#            Only the attribute table connected to layer 1 is supported.
#
#            This function reads two arguments:
#				$1 -- name of GRASS vector map that has the attibute table
#				$2 -- name of field for which to delete the index
#
#            This function returns nothing. It will abort the program if there
#            is a fundamental problem with the map and/or its table.
#
del_index () {
	if [ ${DBMS_INDEX_SUPPORTED} -eq 1 ] ; then
		# Store existing connection information:
		attribute_database_driver_BAK="${attribute_database_driver}"
		attribute_database_BAK="${attribute_database}"
		attribute_table_BAK="${attribute_table}"
		# Get fresh info for this function:
		get_tbl_info "$1"
		# Delete index for specified map and field: This requires a specific syntax, depending on DBMS!
		if [ "${attribute_database_driver}" = "mysql" ] || [ "${attribute_database_driver}" = "mesql" ] ; then
			db.execute sql="DROP INDEX ${attribute_table}_${2}_idx ON ${attribute_table}" database="${attribute_database}"
		else
			db.execute sql="DROP INDEX ${attribute_table}_${2}_idx" database="${attribute_database}"
		fi
		# Restore existing connection information:
		attribute_database_driver="${attribute_database_driver_BAK}"
		attribute_database="${attribute_database_BAK}"
		attribute_table="${attribute_table_BAK}"}
	fi
}


# FUNCTION
# list_len:		Computes the length of a list of values (array).
#				This function takes only one argument:
#				
#				$1 -- a list/array
#
#				REMEMBER to put "$1" in quotes of the list values are separated by whitespace!
#
#				The result will be returned as an integer in the variable LIST_LEN.
#
list_len () {
	
	# IMPORTANT! We change IFS, but save the current value to a local(ly named)
	# variable, so that this will work without clashes from within a caller
	# caller loop that also fiddles around with IFS (not uncommon)!
	OLD_IFS_LIST_LEN="$IFS"
	IFS="${IFS_NEWLINE}"
	
	LIST_LEN=0
	for item in $1 ; do
		if [ -n $BASH_VERSION ] ; then
			let LIST_LEN=${LIST_LEN}+1
		else
			LIST_LEN=`"${EXPR}" ${LIST_LEN} + 1`
		fi
	done
	
	# IMPORTANT: Reset IFS!
	IFS="$OLD_IFS_LIST_LEN"
}


# FUNCTION
# list_get:		Retrieves an item from a list of values (array).
# 				This function takes two arguments:
#				
#				$1 -- a list/array
#				$2 -- an integer that is the number of the item to get (0 or larger)
#				$3 -- (optional): an integer that represents the list length (for upper boundary checks)
#
#				REMEMBER to put "$1" in quotes if the list values are separated by whitespace!
#
#				The requested value will be returned in variable LIST_ITEM.
#				LIST_ITEM can be empty if the list is empty.
#				An error will be thrown if $2 contains an invalid index value.
#
list_get () {
	
	# IMPORTANT! We change IFS, but save the current value to a local(ly named)
	# variable, so that this will work without clashes from within a caller
	# caller loop that also fiddles around with IFS (not uncommon)!
	OLD_IFS_LIST_GET="$IFS"
	IFS="${IFS_NEWLINE}"
	
	LIST_ITEM=
	if [ $2 -lt 0 ] ; then
		exit_error "list_get(): Attempted to read list/array using negative index value."
	fi

	# Getting the list length every time before retreiving an element, just for
	# boundary checking, incurs a huge performance penalty. So uppper boundary checking
	# is optional (by passing the known list length as $3 in addition):
	if [ -n "$3" ] ; then
		if [ $2 -gt $3 ] ; then
			exit_error "list_get(): Attempted to read list/array using out-of-bounds index value."
		fi
	fi

	cur_list_item=0
	for item in $1 ; do
		LIST_ITEM="${item}"
		if [ ${cur_list_item} -eq $2 ] ; then
			# Got item: Return.
			break
		else
			# Get next item.
			if [ -n $BASH_VERSION ] ; then
				let cur_list_item=${cur_list_item}+1
			else
				cur_list_item=`"${EXPR}" ${cur_list_item} + 1`
			fi
		fi
	done
	
	# IMPORTANT: Rest IFS!
	IFS="$OLD_IFS_LIST_GET"	
}


# FUNCTION
# awk_calc:		Uses AWK to calculate an expression and returns the result
#				in 'AWK_VALUE', e.g.:
#				awk_calc "((1+(2^3.4))/9)-2"
#
#				Result will be returned in variable 'AWK_VALUE'
awk_calc () {
	AWK_VALUE=`"${AWK}" "BEGIN{ print $* }"`
}


# FUNCTION
# awk_equal:	Uses AWK to test whether two numbers are equal.
#				The two numbers must be passed as $1 as $2.
#				Result will be returned in variable 'AWK_VALUE':
#					1 = equal
#					0 = not equal
awk_equal () {
	AWK_VALUE=`"${AWK}" "BEGIN{ print $1==$2 }"`
}


# FUNCTION
# awk_smaller:	Uses AWK to test whether $1 is smaller than $2
#				Result will be returned in variable 'AWK_VALUE':
#					1 = $1 < $2
#					0 = $1 >= $2
awk_smaller () {
	AWK_VALUE=`"${AWK}" "BEGIN{ print $1<$2 }"`
}


# FUNCTION
# awk_smaller_eq:	Uses AWK to test whether $1 is smaller or equal $2
#					Result will be returned in variable 'AWK_VALUE':
#					1 = $1 <= $2
#					0 = $1 > $2
awk_smaller_eq () {
	AWK_VALUE=`"${AWK}" "BEGIN{ print $1<=$2 }"`
}


# FUNCTION
# awk_larger:	Uses AWK to test whether $1 is larger than $2
#				Result will be returned in variable 'AWK_VALUE':
#					1 = $1 > $2
#					0 = $1 <= $2
awk_larger () {
	AWK_VALUE=`"${AWK}" "BEGIN{ print $1>$2 }"`
}


# FUNCTION
# awk_larger_eq:	Uses AWK to test whether $1 is larger or equal $2
#					Result will be returned in variable 'AWK_VALUE':
#					1 = $1 >= $2
#					0 = $1 < $2
awk_larger_eq () {
	AWK_VALUE=`"${AWK}" "BEGIN{ print $1>=$2 }"`
}


# FUNCTION
# awk_abs:		Uses AWK to calculate the absolute difference between two numbers.
#				The two numbers must be passed as $1 as $2.
#				Result will be returned in variable 'AWK_VALUE'
awk_abs () {
	AWK_VALUE=`"${AWK}" 'BEGIN{x = $1-$2; print x < 0 ? -x : x}'`
}


# FUNCTION
# awk_min:		Uses AWK to compare two numbers passed in $1 and $1 using "<".
#				'AWK_VALUE' will be set to the smaller of the two.
#				If the first number is passed as empty string, then 'AWK_VALUE'
#				will be the second number.
#				
#				Note: The "0+" in the awk program forces type conversion to
#				numeric (otherwise, awk will compare by character position).
awk_min () {
	if [ -z "$1" ] ; then
		AWK_VALUE="$2"
	else
		AWK_VALUE="$1"
		min=`"${ECHO}" "$1 $2" | "${AWK}" "BEGIN{}{if (0+$2<0+$1) min=$2} END{print min}"`
		if [ -n "${min}" ] ; then
			AWK_VALUE="$min"
		fi
	fi
}


# FUNCTION
# awk_max:		Uses AWK to compare two numbers passed in $1 and $1 using ">".
#				'AWK_VALUE' will be set to the larger of the two.
#				If the first number is passed as empty string, then 'AWK_VALUE'
#				will be the second number.
#				
#				Note: The "0+" in the awk program forces type conversion to
#				numeric (otherwise, awk will compare by character position).
awk_max () {
	if [ -z "$1" ] ; then
		AWK_VALUE="$2"
	else
		AWK_VALUE="$1"
		max=`"${ECHO}" "$1 $2" | "${AWK}" "BEGIN{}{if (0+$2>0+$1) max=$2} END{print max}"`
		if [ -n "${max}" ] ; then
			AWK_VALUE="$max"
		fi
	fi
}


# FUNCTION awk_median:	Compute median for a list of values.
#						Reads just one argument:
#						
#						$1 -- list of values (separated by line breaks!)
#
#						Result is returned in variable 'AWK_VALUE'.
#						An empty value will be returned if there are no values
#						found in $1.
awk_median () {
	
	# Below is the command for sorting with AWK. However, only GNU AWK provides 'asorti(a,b)', 
	# so this would now work on macOS (would need to install 'gawk' through e.b. MacPorts).
	# med_list=`"${ECHO}" "$1" | "${AWK}" '{a[$0]}END{asorti(a,b,"@ind_num_asc");for(i=1;i<=NR;i++)print b[i]}'`
	# Sort list of input values in $1, numerically, ascending:
	med_list=`"${ECHO}" "$1" | "${SORT}" -n`
	# Get number of items on list:
	list_len "${med_list}"
	if [ -z "${med_list}" ] || [ ${LIST_LEN} -eq 0 ] ; then
		AWK_VALUE=""
	else
		if [ ${LIST_LEN} -eq 1 ] ; then
			# special case: just one item on list
			list_get "${med_list}" 0
			awk_median_val="${med_list}"
		fi
		if [ ${LIST_LEN} -eq 2 ] ; then
			# special case: just two items on list
			list_get "${med_list}" 0
			a="${LIST_ITEM}"
			list_get "${med_list}" 1
			b="${LIST_ITEM}"
			awk_calc "(${a}+${b})/2"
			awk_median_val="${AWK_VALUE}"
		fi
		# This is the non-special case:
		if [ ${LIST_LEN} -gt 2 ] ; then
			if [[ $((${LIST_LEN} % 2)) -eq 0 ]] ; then
				# Even list length: median is the mean of the two values at the
				# list's center.
				posa=`"${EXPR}" ${LIST_LEN} / 2`
				posb=`"${EXPR}" ${posa} - 1`
				list_get "${med_list}" "${posa}"
				a="${LIST_ITEM}"
				list_get "${med_list}" "${posb}"
				b="${LIST_ITEM}"
				awk_calc "(${a}+${b})/2"
				awk_median_val="${AWK_VALUE}"		
			else
				# Odd index: median is the value at the list's center.
				posa=`"${EXPR}" ${LIST_LEN} / 2`
				list_get "${med_list}" "${posa}"
				awk_median_val="${LIST_ITEM}"
			fi
		fi
		# Result
		AWK_VALUE="$awk_median_val"
	fi
	
}


# FUNCTION
# is_uint:			Returns '1' if $1 is an unsigned int.
is_uint() { case $1        in '' | *[!0-9]*              ) return 1;; esac ;}

# FUNCTION
# is_int:			Returns '1' if $1 is an int.
is_int()  { case ${1#[-+]} in '' | *[!0-9]*              ) return 1;; esac ;}

# FUNCTION
# is_unum:			Returns '1' if $1 is an unsigned number.
is_unum() { case $1        in '' | . | *[!0-9.]* | *.*.* ) return 1;; esac ;}

# FUNCTION
# is_num:			Returns '1' if $1 is a number.
is_num()  { case ${1#[-+]} in '' | . | *[!0-9.]* | *.*.* ) return 1;; esac ;}


# FUNCTION
# grep_is_zero:		Uses 'grep' to check whether $1 contains a numeric caracter
#					in the range [1-9]. This is useful for checking whether an
# 					option value is true zero ('0','0.0','0.00', etc.).
#					This function will set 'GREP_VALUE' to an empty string if
#					$1 represents '0', or to the same string as $1, otherwise.
#					THIS FUNCTION ASSUMES that $1 is already a valid string
#					representation of a number!
grep_is_zero () {
	GREP_VALUE=
	GREP_VALUE=`"${ECHO}" "$1" | "${GREP}" '[1-9]'`
}


# FUNCTION
# grep_is_positive:	Uses 'grep' to check whether $1 contains a numeric caracter
#					in the range +[1-9]. This is useful for checking whether an
# 					option value is a positive number larger then zero.
#					This function will set 'GREP_VALUE' to an empty string if
#					$1 represents a number '<=0', or to the same string as $1, otherwise.
#					THIS FUNCTION ASSUMES that $1 is already a valid string
#					representation of a number!
grep_is_positive () {
	GREP_VALUE=
	GREP_VALUE=`"${ECHO}" "$1" | "${GREP}" -Ei '[+1-9]' | "${GREP}" -Eiv '[-]'`
}


# FUNCTION
# str_substr:	Checks whether a string contains a substring.
#				Uses BASH internal check if available, 'grep' (external, slow), otherwise.
#
#				Parameters:
#					$1		some string
#					$2		substring to check for in $1
#
#				Returns:
#					Variable SUBSTR_EXIST will be returned as substring ($2) if
#					the substring exists, as empty string otherwise.
# 
str_substr () {
	if [ -n $BASH_VERSION ] ; then							
		if [[ "${1}" == *"${2}"* ]] ; then
			SUBSTR_EXIST="$2"
			return
		else
			SUBSTR_EXIST=
			return
		fi
	else
		str_substr_check=`"${ECHO}" "${1}" | "${GREP}" "${2}" -c`
		if [ ${str_substr_check} -gt 0 ] ; then
			SUBSTR_EXIST="$2"
			return
		else
			SUBSTR_EXIST=
			return
		fi
	fi
}


# FUNCTION
# stats_compute_links: 	Computes statistics for network links (to be printed later).
#
stats_compute_links () {
	# Get attribute table info for output links map:
	get_tbl_info "${GIS_OPT_LINKS}"
	# Get global statistics for unreduced network and store them in some variables
	# that will be used later by the "xtent" model or any other model that requires
	# them.
	if [ ${GRASS_VERBOSE} -gt 0 ] ; then
		g.message -i "Computing statistics for network links:"
	fi
	eval `v.info -t map="${GIS_OPT_LINKS}" layer="1"`
	get_grass_cats "${GIS_OPT_LINKS}"	
	total_cost=0
	total_len=0
	# min/max initially empty strings
	min_len=""
	max_len=""
	min_cost=""
	max_cost=""
	step=1 # This one is just for progress reporting.
	# Compute simple metrics
	OLD_IFS="$IFS"
	IFS="${IFS_NEWLINE}"
	for cat in ${GRASS_CATS} ; do
		len=`db.select sql="SELECT ${LINKS_FLD_LEN_M} FROM ${GIS_OPT_LINKS} WHERE ${GRASS_PKEY}=${cat};" database="$attribute_database" driver="$attribute_database_driver" -c --quiet`
		check_error "Failed to query field '${LINKS_FLD_LEN_M}' from links output layer (${GRASS_PKEY}='${cat}')"
		awk_min "${min_len}" "${len}"
		min_len="${AWK_VALUE}"
		awk_max "${max_len}" "${len}"
		max_len="${AWK_VALUE}"
		awk_calc "$total_len+$len"
		total_len="${AWK_VALUE}"
		if [ "${RUNMODE_COST}" == "TRUE" ] ; then
			cost=`db.select sql="SELECT ${LINKS_FLD_COST} FROM ${GIS_OPT_LINKS} WHERE ${GRASS_PKEY}=${cat};" database="$attribute_database" driver="$attribute_database_driver" -c --quiet`
			check_error "Failed to query field '${LINKS_FLD_COST}' from links output layer (${GRASS_PKEY}='${cat}')"
			awk_min "${min_cost}" "${cost}"
			min_cost="${AWK_VALUE}"
			awk_max "${max_cost}" "${cost}"
			max_cost="${AWK_VALUE}"			
			awk_calc "$total_cost+$cost"
			total_cost="${AWK_VALUE}"
		fi
		if [ ${GRASS_VERBOSE} -gt 0 ] ; then
			g.message -p "${step} ${lines} 1"
		fi
		if [ -n $BASH_VERSION ] ; then
			let step=${step}+1
		else
			step=`"${EXPR}" ${step} + 1`
		fi		
	done
	IFS="${OLD_IFS}"
	net_nodes_undreduced="${NUM_INPUT_NODES}"
	net_links_unreduced="${lines}"
	net_len_unreduced="${total_len}"
	net_len_min_unreduced="${min_len}"
	net_len_max_unreduced="${max_len}"
	if [ "${RUNMODE_COST}" == "TRUE" ] ; then
		net_cost_unreduced="${total_cost}"
		net_cost_min_unreduced="${min_cost}"
		net_cost_max_unreduced="${max_cost}"
		net_cost_max_unreduced="${max_cost}"
	fi
	# Compute means
	awk_calc "(($lines*2)/$NUM_INPUT_NODES)" # 1 link = 2 connections (one at each end!)
	net_cons_mean_unreduced="${AWK_VALUE}"
	awk_calc "$total_len/$lines"
	net_len_mean_unreduced="${AWK_VALUE}"
	if [ "${RUNMODE_COST}" == "TRUE" ] ; then
		awk_calc "$total_cost/$lines"
		net_cost_mean_unreduced="${AWK_VALUE}"
	fi
	# Compute median(s)
	lengths=`v.db.select map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_LEN_M}" -c`
	check_error "Failed to query field '${LINKS_FLD_LEN_M}' from links output layer (${GIS_OPT_LINKS})."
	awk_median "$lengths"	
	if [ -z "${AWK_VALUE}" ] ; then
		exit_error "No length data found in attribute table of links output layer (${GIS_OPT_LINKS})."
	fi
	net_len_median_unreduced="${AWK_VALUE}"
	if [ "${RUNMODE_COST}" == "TRUE" ] ; then
		costs=`v.db.select map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_COST}" -c`
		check_error "Failed to query field '${LINKS_FLD_COST}' from links output layer (${GIS_OPT_LINKS})."
		awk_median "$costs"	
		if [ -z "${AWK_VALUE}" ] ; then
			exit_error "No cost data found in attribute table of links output layer (${GIS_OPT_LINKS})."
		fi
		net_cost_median_unreduced="${AWK_VALUE}"
	fi
}


# FUNCTION
# get_interpreter: 		Runs a lot of code in an attempt to accurately determine
#						the interpreter that is currently running this script.
#						It is not guaranteed that the interpreter is the same as
#						the login shell or user default shell. Thus, reading typical
#						environment variables is pretty pointless.
#						The code in this function has been taken from:
#						
#						https://www.in-ulm.de/~mascheck/various/whatshell/
#
#						Originally, it was designed to echo the name of the running
#						interpreter to the terminal.
#
#						Within this script it is used to read the interpreter's name
#						into a variable for further analysis:
#
#						interpreter=`get_interpreter`
#						
get_interpreter () {
'echo' +"'\
@ goto dos \
[exit[if {[lsearch -exact [package names] Expect]>=0} {puts expect\ [\
package require Expect]\ (Tcl\ [info patchlevel])} elseif {[lsearch -exact [\
package names] Tk]>=0} {puts wish\ (Tcl\ [info patchlevel],\ Tk\ [package \
require Tk])} else {puts tcl\ [info patchlevel]}]]' >/dev/null ' {\">/dev/null \
">"/dev/null" +"\'";q='''=.q,';q=%[\"
echo ">/dev/null;status=0;@ {status=1};*=(" '$' ");~ $status 1&&{e='"\
"';eval catch $2 ^'&version {eval ''echo <='^ $2 ^'&version''}';exit};e='"\
"';if (eval '{let ''a^~a''} >[2] /dev/null'){e='"\
"';exec echo akanga};eval exec echo rc $2 ^ version;\" > /dev/null
: #;echo possibly pre-Bourne UNIX V1-6 shell;exit
if { bindkey >& /dev/null } then
exec echo $version
else
exec echo csh
endif
: dos
@echo off
cls
echo %OS% %COMSPEC%
goto fin
", unless eval 'printf "perl %vd\n",$^V;exit;'> "/dev/null";eval ': "\'';
=S"'
: 'This script aims at recognizing all Bourne compatible shells.
   Emphasis is on shells without any version variables.
   Please comment to mascheck@in-ulm.de'
: '$Id: whatshell.sh,v 1.26 2018/02/18 23:38:06 xmascheck Exp xmascheck $'
: 'fixes are tracked on www.in-ulm.de/~mascheck/various/whatshell/'

LC_ALL=C; export LC_ALL
: 'trivial cases first, yet parseable for historic shells'
case $BASH_VERSION in *.*) { echo "bash $BASH_VERSION";exit;};;esac
case $ZSH_VERSION  in *.*) { echo "zsh $ZSH_VERSION";exit;};;esac
case "$VERSION" in *zsh*) { echo "$VERSION";exit;};;esac
case  "$SH_VERSION" in *PD*) { echo "$SH_VERSION";exit;};;esac
case "$KSH_VERSION" in *PD*|*MIRBSD*) { echo "$KSH_VERSION";exit;};;esac
case "$POSH_VERSION" in 0.[1234]|0.[1234].*) \
     { echo "posh $POSH_VERSION, possibly slightly newer, yet<0.5";exit;}
  ;; *.*|*POSH*) { echo "posh $POSH_VERSION";exit;};; esac
case $YASH_VERSION in *.*) { echo "yash $YASH_VERSION";exit;};;esac

: 'traditional Bourne shell'
(eval ': $(:)') 2>/dev/null || {
  case `(:^times) 2>&1` in *0m*):;;
    *)p=' (and pipe check for Bourne shell failed)';;esac
  : 'pre-SVR2: no functions, no echo built-in.'
  (eval 'f(){ echo :; };f') >/dev/null 2>&1 || {
    ( eval '# :' ) 2>/dev/null || { echo '7th edition Bourne shell'"$p";exit;}
    ( : ${var:=value} ) 2>/dev/null ||
    { echo '7th edition Bourne shell, # comments (BSD, or port)'"$p";exit;}
    set x x; shift 2;test "$#" != 0 && { echo 'System III Bourne shell'"$p";exit;}
    { echo 'SVR1 Bourne shell'"$p";exit;}
  }
}; : 'keep syntactical block small for pre-SVR2'

myex(){ echo "$@";exit;} # "exec echo" might call the external command

(eval ': $(:)') 2>/dev/null || {
  (set -m; set +m) 2>/dev/null && {
    priv=0;(priv work)>/dev/null 2>&1 &&
      case `(priv work)2>&1` in *built*|*found*) priv=1;;esac
    read_r=0;(echo|read -r dummy 2>/dev/null) && read_r=1
    a_read=0;unset var;set -a;read var <&-;case `export` in
       *var*) a_read=1;;esac
    case_in=0;(eval 'case x in in) :;;esac')2>/dev/null && case_in=1
    ux=0;a=`(notexistent_cmd) 2>&1`; case $a in *UX*) ux=1;;esac
    case $priv$ux$read_r$a_read$case_in in
       11110) myex 'SVR4.2 MP2 Bourne shell'
    ;; 11010) myex 'SVR4.2 Bourne shell'
    ;; 10010|01010) myex 'SVR4.x Bourne shell (between 4.0 and 4.2)'
    ;; 00111) myex 'SVR4 Bourne shell (SunOS 5 schily variant, before 2016-02-02)'
    ;; 00101) myex 'SVR4 Bourne shell (SunOS 5 heirloom variant)'
    ;; 00001) myex 'SVR4 Bourne shell (SunOS 5 variant)'
    ;; 00000) myex 'SVR4.0 Bourne shell'
    ;; *)     myex 'unknown SVR4 Bourne shell variant' ;;esac
  }
  r=0; case `(read) 2>&1` in *"missing arguments"*) r=1;;esac
  g=0; (set -- -x; getopts x var) 2>/dev/null && g=1
  case $r$g in
     11) myex 'SVR3 Bourne shell'
  ;; 10) myex 'SVR3 Bourne shell (but getopts built-in is missing)'
  ;; 01) myex 'SVR3 Bourne shell (but read built-in does not match)'
  ;; 00) (builtin :) >/dev/null 2>&1 &&
 	myex '8th edition (SVR2) Bourne shell'"$p"
 	(type :) >/dev/null 2>&1 && myex 'SVR2 Bourne shell'"$p" ||
 	myex 'SVR2 shell (but type built-in is missing)'"$p"
  ;;esac
}

case $( (:^times) 2>&1) in *0m*)
  case `eval '(echo $((1+1))) 2>/dev/null'` in
    2) myex 'SVR4 Bourne shell (SunOS 5 schily variant, posix-like, since 2016-05-24)'
  ;;*) myex 'SVR4 Bourne shell (SunOS 5 schily variant, since 2016-02-02, before 2016-05-24)'
  ;;esac
;;esac

type -F >/dev/null 2>&1 &&
  myex 'SVR4 Bourne shell (SunOS 5 schily variant, since 2016-08-08, in posix mode)'

# Almquist shell aka ash
(typeset -i var) 2>/dev/null || {
  case $SHELLVERS in "ash 0.2") myex 'original ash';;esac
  test "$1" = "debug" && debug=1
  n=1; case `(! :) 2>&1` in *not*) n=0;;esac
  b=1; case `echo \`:\` ` in '`:`') b=0;;esac
  g=0; { set -- -x; getopts x: var
         case $OPTIND in 2) g=1;;esac;} >/dev/null 2>&1
  p=0; (eval ': ${var#value}') 2>/dev/null && p=1
  r=0; ( (read</dev/null)) 2>/dev/null; case $? in 0|1|2)
	  var=`(read</dev/null)2>&1`; case $var in *arg*) r=1;;esac
	;;esac
  v=1; set x; case $10 in x0) v=0;;esac
  t=0; (PATH=;type :) >/dev/null 2>&1 && t=1
  test -z "$debug" || echo debug '$n$b$g$p$r$v$t: ' $n$b$g$p$r$v$t
  case $n$b$g$p$r$v$t in
     00*) myex 'early ash (4.3BSD, 386BSD 0.0-p0.2.3/NetBSD 0.8)'
  ;; 010*) myex 'early ash (ash-0.2 port, Slackware 2.1-8.0,'\
	'386BSD p0.2.4, NetBSD 0.9)'
  ;; 1110100) myex 'early ash (Minix 2.x-3.1.2)'
  ;; 1000000) myex 'early ash (4.4BSD Alpha)'
  ;; 1100000) myex 'early ash (4.4BSD)'
  ;; 11001*) myex 'early ash (4.4BSD Lite, early NetBSD 1.x, BSD/OS 2.x)'
  ;; 1101100) myex 'early ash (4.4BSD Lite2, BSD/OS 3 ff)'
  ;; 1101101) myex 'ash (FreeBSD -10.x, Cygwin pre-1.7, Minix 3.1.3 ff)'
  ;; 1111101) myex 'ash (FreeBSD 11.0 ff)'
  ;; esac
  e=0; case `(PATH=;exp 0)2>&1` in 0) e=1;;esac
  n=0; case y in [^x]) n=1;;esac
  r=1; case `(PATH=;noexist 2>/dev/null) 2>&1` in
        *not*) r=0 ;; *file*) r=2 ;;esac
  f=0; case `eval 'for i in x;{ echo $i;}' 2>/dev/null` in x) f=1;;esac
  test -z "$debug" || echo debug '$e$n$r$a$f: ' $e$n$r$a$f
  case $e$n$r$f in
     1100) myex 'ash (dash 0.3.8-30 - 0.4.6)'
  ;; 1110) myex 'ash (dash 0.4.7 - 0.4.25)'
  ;; 1010) myex 'ash (dash 0.4.26 - 0.5.2)'
  ;; 0120|1120|0100) myex 'ash (Busybox 0.x)'
  ;; 0110) myex 'ash (Busybox 1.x)'
  ;;esac
  a=0; case `eval 'x=1;(echo $((x)) )2>/dev/null'` in 1) a=1;;esac
  x=0; case `f(){ echo $?;};false;f` in 1) x=1;;esac
  c=0; case `echo -e '\x'` in *\\x) c=1;;esac
  test -z "$debug" || echo debug '$e$n$r$f$a$x$c: ' $e$n$r$f$a$x$c
  case $e$n$r$f$a$x$c in
     1001010) myex 'ash (Slackware 8.1 ff, dash 0.3.7-11 - 0.3.7-14)'
  ;; 10010??) myex 'ash (dash 0.3-1 - 0.3.7-10, NetBSD 1.2 - 3.1/4.0)'
  ;; 10011*)  myex 'ash (NetBSD 3.1/4.0 ff)'
  ;; 00101*)  myex 'ash (dash 0.5.5.1 ff)'
  ;; 00100*)  myex 'ash (dash 0.5.3-0.5.5)'
  ;;      *)  myex 'unknown ash'
  ;;esac
}

savedbg=$! # save unused $! for a later check

# Korn shell ksh93, $KSH_VERSION not implemented before 93t'
# protected: fatal substitution error in non-ksh
( eval 'test "x${.sh.version}" != x' ) 2>/dev/null &
wait $! && { eval 'PATH=;case $(XtInitialize 2>&1) in Usage*)
    DTKSH=" (dtksh/CDE variant)";;esac
    myex "ksh93 ${.sh.version}${DTKSH}"'; }

# Korn shell ksh86/88
_XPG=1;test "`typeset -Z2 x=0; echo $x`" = '00' && {
  case `print -- 2>&1` in *"bad option"*)
    myex 'ksh86 Version 06/03/86(/a)';; esac
  test "$savedbg" = '0'&& myex 'ksh88 Version (..-)11/16/88 (1st release)'
  test ${x-"{a}"b} = '{ab}' && myex 'ksh88 Version (..-)11/16/88a'
  case "`for i in . .; do echo ${i[@]} ;done 2>&1`" in
    "subscript out of range"*)
    myex 'ksh88 Version (..-)11/16/88b or c' ;; esac
  test "`whence -v true`" = 'true is an exported alias for :' &&
    myex 'ksh88 Version (..-)11/16/88d'
  test "`(cd /dev/null 2>/dev/null; echo $?)`" != '1' &&
    myex 'ksh88 Version (..-)11/16/88e'
  test "`(: $(</file/notexistent); echo x) 2>/dev/null`" = '' &&
    myex 'ksh88 Version (..-)11/16/88f'
   case `([[ "-b" > "-a" ]]) 2>&1` in *"bad number"*) \
    myex 'ksh88 Version (..-)11/16/88g';;esac # fixed in OSR5euc
  test "`cd /dev;cd -P ..;pwd 2>&1`" != '/' &&
    myex 'ksh88 Version (..-)11/16/88g' # fixed in OSR5euc
  test "`f(){ typeset REPLY;echo|read;}; echo dummy|read; f;
     echo $REPLY`" = "" && myex 'ksh88 Version (..-)11/16/88h'
  test $(( 010 )) = 8 &&
    myex 'ksh88 Version (..-)11/16/88i (posix octal base)'
  myex 'ksh88 Version (..-)11/16/88i'
}

echo 'UNKNOWN'
]

}


# FUNCTION
# check_setup: Check system setup (required external programs available?).
#
# This function runs a basic test for a number of known CLI tools.
# Each test will only be run if the corresponding variable has been set
# to a non-null string.
#
check_setup () {	
	
	message="Required program not found or not working as expected: "
	
	# Echo (test first, since the following require a working echo command!)
	prg="${ECHO}"
	result=`"${ECHO}" "1 2 4 3"`
	if [ "$result" != "1 2 4 3" ] ; then
		exit_error "$message ${prg}"
	fi
	
	# The following commands are only tested if they have been defined!
	
	# Awk	
	prg="${AWK}"
	if [ -n "${prg}" ] ; then
		result=`"${ECHO}" "1 2 4 3" | ${prg} '{ print $3 }'`
		if [ $result -ne 4 ] ; then
			exit_error "$message ${prg}"
		fi
	fi
	
	# Cut
	prg="${CUT}"
	if [ -n "${prg}" ] ; then
		result=`"${ECHO}" "1,2,4,3" | ${prg} -f3 -d,`
		if [ $result -ne 4 ] ; then
			exit_error "$message ${prg}"
		fi
	fi
	
	# Date
	prg="${DATE}"
	if [ -n "${prg}" ] ; then
		: $(${prg} -u)
		check_error "${message} '${prg}'."
	fi
	
	# Expr
	prg="${EXPR}"
	if [ -n "${prg}" ] ; then
		result=`${prg} 1 + 3`
		if [ $result -ne 4 ] ; then
			exit_error "$message ${prg}"
		fi
	fi
	
	# Grep
	prg="${GREP}"
	if [ -n "${prg}" ] ; then
		result=`"${ECHO}" "1 2 3 4" | ${prg} "3 4" -c`
		if [ $result -ne 1 ] ; then
			exit_error "$message ${prg}"
		fi
	fi
	
	# Head
	prg="${HEAD}"
	if [ -n "${prg}" ] ; then	
		result=`"${ECHO}" -e "one\ntwo\nfive" | ${prg} -n 1`
		if [ "$result" != "one" ] ; then
			exit_error "$message ${prg}"
		fi
	fi
	
	# Check for multi-threading support.
	# Pkill, Sleep, Wait: Multi-threading support
	if [ -z "${PKILL}" ] || [ -z "${WAIT}" ] || [ -z "${SLEEP}" ] ; then
		# If any of these commands are missing then we are running on a system (likely Windows)
		# that does not have what it takes for concurrent execution of shell scripts.
		MULTI_THREADING_SUPPORT=
	else
		# In the other case, all three of pkill, wait and sleep must be present!
		#
		# We have pkill command: Let's check that it works!
		# TODO: There seems to be no portable AND safe way of checking
		#       that pkill works. For now, we just trust that it's there
		#		if $PKILL is declared!
		#prg="${PKILL}"
		#: $(${prg} --help)
		#check_error "${message} '${prg}'."
		# We have sleep command: Let's check that it works!
		prg="${SLEEP}"
		: $(${prg} 0.1)
		check_error "${message} '${prg}'."
		# We have wait command: Let's check that it works!
		prg="${WAIT}"
		: $(${prg})
		check_error "${message} '${prg}'."
		# Support for multi-threading exists!
		MULTI_THREADING_SUPPORT="y"
	fi
	
	# Sort
	prg="${SORT}"
	if [ -n "${prg}" ] ; then
		result=`"${ECHO}" "Just one line." | ${prg}`
		check_error "${message} '${prg}'."
	fi
	
	# Tail
	prg="${TAIL}"
	if [ -n "${prg}" ] ; then	
		result=`"${ECHO}" -e "one\ntwo\nfive" | ${prg} -n 1`
		if [ "$result" != "five" ] ; then
			exit_error "$message ${prg}"
		fi
	fi

	# Wc
	prg="${WC}"
	if [ -n "${prg}" ] ; then	
		result=`"${ECHO}" "one two five" | ${prg} -w`
		if [ $result -ne 3 ] ; then
			exit_error "$message ${prg}"
		fi
	fi
	
}


# FUNCTION
# check_environment: Query GRASS environment for some important variables.
check_environment () {
	
	# Determine/report shell capabilities
	interpreter=`get_interpreter`
	g.message -i "Running in '$interpreter'."
	is_bash=0
	is_bourne=0
	is_bash=`${ECHO} ${interpreter} |${GREP} "bash" -c`
	is_bourne=`${ECHO} ${interpreter} |${GREP} "Bourne" -c`
	if [ $is_bash -eq 0 ] ; then
		if [ $is_bourne -eq 1 ] ; then
			g.message -w "Running in slow Bourne shell compatibility mode."
			g.message -w "For better performance, try running this script in Bash explicitly."
		else
			g.message -w "Could not assert that the current interpreter is Bash or Bourne shell."
			g.message -w "If this script throws inexplicable errors, try running it in Bash."
			g.message -w "Running in slow Bourne shell compatibility mode."
		fi
	else
		if [ -z $BASH_VERSION ] ; then
			# If BASH_VERSION has not been set then we just assume a version!
			BASH_VERSION="3" # Version 3 is the latest one shipped on macOS
			g.message -w "BASH_VERSION not set. Assuming version $BASH_VERSION."
		fi
	fi
	
	# Get essential GRASS environment settings
	GISDBASE=`g.gisenv get=GISDBASE`
	LOCATION_NAME=`g.gisenv get=LOCATION_NAME`
	MAPSET=`g.gisenv get=MAPSET`
	
	# Set GRASS verbosity (no --q or --v given):
	if [ -z "$GRASS_VERBOSE" ] ; then
		GRASS_VERBOSE=1
	fi
	
	# Get current region settings.
	eval `g.region -p -g`	

	# Store projection (to differentiate x/y and lat/lon)
	GRASS_REG_PROJECTION="${projection}"
	if [ "${GRASS_REG_PROJECTION}" = "3" ] ; then
		g.message -w "Running in lat/lon mode. Expect reduced performance."
	fi

	# Get current GRASS database connection	
	cmd=`db.connect -pg`
	check_error "Failed to query GRASS session for current database connection ('db.connect')."
	eval_ws_safe "${cmd}" "driver"
	GRASS_DB_driver="${EVAL_RESULT}"
	eval_ws_safe "${cmd}" "database"
	GRASS_DB_database="${EVAL_RESULT}"
	
	# Ensure that we are running with a supported DBMS!
	# A supported DBMS must have sufficient SQL capabilities for this script's attribute data
	# operations. If it is not thread-safe, it will still work, but with reduced performance
	# in multi-threaded operations, due to the necessity of keeping a DBMS lock.
	# At the same time, we set LABEL_TYPE_OUT to be the SQL data type that is best suited
	# for creating new fields representing (potential long) string data in the specific DBMS.
	#
	DBMS_SUPPORTED=0
	DBMS_NAME="unsupported"
	# SQLite: Sufficient SQL capabilities, but not thread-safe with default setup
	# (=one SQLite database per mapset).
	if [ "${GRASS_DB_driver}" = "sqlite" ] ; then
		DBMS_SUPPORTED=1
		DBMS_NAME="SQLite"
		DBMS_INDEX_SUPPORTED=1
		DBMS_PRESERVES_ORDER=1
		DBMS_IDENT_QUOTE="'"
		LABEL_TYPE_OUT="TEXT"
		# It is possible to force the SQLite backend driver to use one
		# DB per vector map instead of one DB per mapset. This will make SQLite
		# attribute table operations thread safe for the purposes of this script.
		# In order to achieve this, the user has to set the current mapset's DB connection
		# to include variable '$MAP' in the storage path of 'sqlite.db', like this
		# (note: use single quotes!):
		# db.connect database='$GISDBASE/$LOCATION_NAME/$MAPSET/vector/$MAP/sqlite.db'
		# We check whether this condition is true and issue an information, otherwise.
		result=`"${ECHO}" "$GRASS_DB_database" | "${GREP}" '/vector/$MAP/' -c`
		if [ ${result} -gt 0 ] ; then
			DBMS_THREAD_SAFE=1
		else
			g.message -i "SQLite backend appears to be in default mode (single database)."
		fi
		DBMS_FILE_PATH=1
	fi
	# PostgreSQL: Full SQL capabilities and thread safe
	if [ "${GRASS_DB_driver}" = "pg" ] ; then
		DBMS_SUPPORTED=1
		DBMS_NAME="PostgreSQL"
		DBMS_THREAD_SAFE=1
		DBMS_INDEX_SUPPORTED=1
		DBMS_PRESERVES_ORDER=0
		DBMS_IDENT_QUOTE='"'
		LABEL_TYPE_OUT="TEXT"
	fi
	# MySQL/MariaDB: Full SQL capabilities and thread safe
	if [ "${GRASS_DB_driver}" = "mysql" ] ; then
		g.message -w "MySQL/MariaDB used: Use input data with minimal number of attribute fields to avoid storage size errors."
		DBMS_SUPPORTED=1
		DBMS_NAME="MySQL/MariaDB"		
		DBMS_THREAD_SAFE=1
		DBMS_INDEX_SUPPORTED=1
		DBMS_PRESERVES_ORDER=1
		DBMS_IDENT_QUOTE='`'
		LABEL_TYPE_OUT="TEXT"
	fi
	# Embedded version of MySQL/MariaDB: Full SQL capabilities and thread safe
	if [ "${GRASS_DB_driver}" = "mesql" ] ; then
		DBMS_SUPPORTED=1
		DBMS_NAME="MySQL/MariaDB (embedded)"
		DBMS_THREAD_SAFE=1
		DBMS_INDEX_SUPPORTED=1
		DBMS_PRESERVES_ORDER=1
		DBMS_IDENT_QUOTE='`'
		LABEL_TYPE_OUT="TEXT"
	fi
	if [ ${DBMS_SUPPORTED} -lt 1 ] ; then
		exit_error "Current mapset does not use a known DBMS."
	fi
	g.message -i "Running with DBMS driver '${GRASS_DB_driver}' (${DBMS_NAME})."
	
	# If the DBMS cannot preserve record insertion order, then we might expect some trouble.
	# Also, exporting the result maps using v.out.ogr might be very slow for large datasets,
	# since that the 'cat' sequence in the attribute table maps might not be unbroken!
	if [ ${DBMS_PRESERVES_ORDER} -eq 0 ] ; then
		if [ -n "${GIS_OPT_COSTMAP}" ] ; then
			exit_error "DBMS does not strictly preserve record insertion order. Cannot run in cost-based mode (option 'costmap=')."
		fi
		g.message -w "DBMS does not strictly preserve record insertion order. Expect reduced performance and check output for correct order."
	fi
	
	# TODO: We never seem to use this!? It was probably intended to be used in the
	#      context of adjusting node (point) locations to link (line) start/end vertices.
	# Set default snapping distance to be half the diagonal of region's cell dimensions.
	SNAPDIST=`"${ECHO}" ${nsres} ${ewres} | "${AWK}" '{ printf "%.8f\n", sqrt(\$1^2 + \$2^2)/2 }'`
	if [ -z "${SNAPDIST}" ] ; then
		exit_error "Failed to determine default line snapping threshold from GRASS region settings."
	fi
}


# FUNCTION
# check_field: Checks attribute field validity.
#
# Number of tests depends on number of arguments provided.
# Arguments are positional:
# 	$1 - Name of map for which to test attribute field
#	$2 - Name of attribute field to test (case sensitive)
#   $3 - Field type to test for. Can be one of (case matters!):
#       "INTEGER"
#       "DOUBLE PRECISION"
#       "NUMERIC"
#       "TEXT"
#		"ANY"
#		(The first four match the GRASS GIS field data types!)
#   $4 - All field contents must be non-empty? Can be one of (case matters!):
#		"TRUE"
#		"FALSE"
#   $5 - Field contents must be unique? Can be one of (case matters!):
#		"TRUE"
#		"FALSE"
#
# It is always assumed that the name of the attribute table is identical
# with the name of the map in $1, and that the table is connected as layer 1.
#
# This function will quit the entire program, if an error occurs
# while querying the field or its contents!
#
# Return value is stored in RET_FLD_TEST as a string:
#   == field name ($2): ok (all tests passed)
#   != field name ($2): not all tests passed (return string contains descr of first failed test) 
#   empty = unknown error
#
check_field () {
	
	FLD_TEST_KEY_TYPE="${3}"
	
	# Initialize return value:	
	RET_FLD_TEST=""
	
	# 1. Check if field exists (always run)
	#fld_test_result=`v.info -c --quiet map="${1}" layer="1" | "${GREP}" "|${2}" -o`
	fld_test_result=`v.info -c --quiet map="${1}" layer="1" | ${CUT} -f 2 -d "|" | "${GREP}" "${2}" -w`
	if [ "${fld_test_result}" != "${2}" ] ; then
		RET_FLD_TEST="Field '$2' does not exist in attribute table of map '$1'."
		return
	fi
	
	# 2. Check for given field type (run if at least three arguments given)
	if [ $# -gt 2 ] ; then
		fld_test_key_type="UNKNOWN"
		fld_test_result=`v.info -c --quiet map="${1}" layer="1" | "${GREP}" "INTEGER|${2}" -w -c`
		if [ ${fld_test_result} -eq 1 ] ; then
			fld_test_key_type="INTEGER"
			if [ "$FLD_TEST_KEY_TYPE" != "INTEGER" ] && [ "$FLD_TEST_KEY_TYPE" != "NUMERIC" ] && [ "$FLD_TEST_KEY_TYPE" != "ANY" ] ; then
				RET_FLD_TEST="Field '$2' in attribute table of map '$1' is not of type '$FLD_TEST_KEY_TYPE'."
				return
			fi
		fi
		fld_test_result=`v.info -c --quiet map="${1}" layer="1" | "${GREP}" "DOUBLE PRECISION|${2}" -w -c`
		if [ ${fld_test_result} -eq 1 ] ; then
			fld_test_key_type="DOUBLE PRECISION"
			if [ "$FLD_TEST_KEY_TYPE" != "DOUBLE PRECISION" ] && [ "$FLD_TEST_KEY_TYPE" != "NUMERIC" ] && [ "$FLD_TEST_KEY_TYPE" != "ANY" ] ; then
				RET_FLD_TEST="Field '$2' in attribute table of map '$1' is not of type '$FLD_TEST_KEY_TYPE'."
				return
			fi
		fi
		fld_test_result=`v.info -c --quiet map="${1}" layer="1" | "${GREP}" "CHARACTER|${2}" -w -c`
		if [ ${fld_test_result} -eq 1 ] ; then
			fld_test_key_type="CHARACTER"
			if [ "$FLD_TEST_KEY_TYPE" != "TEXT" ] && [ "$FLD_TEST_KEY_TYPE" != "ANY" ] ; then
				RET_FLD_TEST="Field '$2' in attribute table of map '$1' is not of type '$FLD_TEST_KEY_TYPE'."
				return
			fi
		fi
		fld_test_result=`v.info -c --quiet map="${1}" layer="1" | "${GREP}" "TEXT|${2}" -w -c`
		if [ ${fld_test_result} -eq 1 ] ; then
			fld_test_key_type="TEXT"
			if [ "$FLD_TEST_KEY_TYPE" != "TEXT" ] && [ "$FLD_TEST_KEY_TYPE" != "ANY" ] ; then
				RET_FLD_TEST="Field '$2' in attribute table of map '$1' is not of type '$FLD_TEST_KEY_TYPE'."
				return
			fi
		fi
		# ANY != UNKNOWN
		if [ "${fld_test_key_type}" = "UNKNOWN" ] ; then
			RET_FLD_TEST="Field '$2' in attribute table of map '$1' has unknown type."
			return
		fi
	fi
	
	# 3. Check for non-empty contents (run if at least 4 arguments given) 
	if [ $# -gt 3 ] ; then
		if [ "$4" == "TRUE" ] ; then
			# Get number of features in map:
			# We compare the number of (typical) geometries that can have
			# attributes attached with the total number of attributes
			# returned by a v.db.select query.
			# The below are all sensitive vars that might already be set!
			fld_test_points_old="${points}"
			fld_test_lines_old="${lines}"
			fld_test_areas_old="${areas}"
			#DEBUG
			#"${ECHO}" "FLD = ${2}"
			eval `v.info -t map="${1}" layer=1`
			check_error "Failed to query map '$1' for feature count."
			fld_test_num_keys=`v.db.select -c --quiet columns="${2}" map="${1}" layer="1" | "${GREP}" -v -e '^$' -c`
			check_error "Failed to query map '$1' for contents of field '$2'."
			fld_test_num_geoms=`"${EXPR}" ${points} + ${lines} + ${areas}`
			#DEBUG			
			#echo "  NUM_GEOMS = ${fld_test_num_geoms}"
			#echo "  NUM_KEY = ${fld_test_num_keys}"
			if [ ${fld_test_num_geoms} -gt ${fld_test_num_keys} ] ; then
				RET_FLD_TEST="Field '$2' in attribute table of map '$1' is empty in one or more instances."
				# Restore previous geometry data:
				points="${fld_test_points_old}"
				lines="${fld_test_lines_old}"
				areas="${fld_test_areas_old}"
				return
			fi
			# Restore previous geometry data:
			points="${fld_test_points_old}"
			lines="${fld_test_lines_old}"
			areas="${fld_test_areas_old}"
		fi
	fi
	
	# 4. Check for uniqueness (run if at least 5 arguments given) 
	if [ $# -gt 4 ] ; then
		if [ "$5" == "TRUE" ] ; then
			FLD_TEST_KEYS=`v.db.select -c --quiet columns="${2}" map="${1}" layer="1" | "${GREP}" -v -e '^$'`
			for fld_test_key in ${FLD_TEST_KEYS} ; do
				if [ "${FLD_TEST_KEY_TYPE}" = "CHARACTER" ] || [ "${FLD_TEST_KEY_TYPE}" = "TEXT" ] ; then
					fld_test_num_matches=`v.db.select -c --quiet columns="${2}" where="${2}='$fld_test_key'" map="${1}" layer="1" | "${GREP}" -v -e '^$' -c`
					check_error "Failed to query map '$1' for contents of field '$2'."
				else
					fld_test_num_matches=`v.db.select -c --quiet columns="${2}" where="${2}=$fld_test_key" map="${1}" layer="1" | "${GREP}" -v -e '^$' -c`
					check_error "Failed to query map '$1' for contents of field '$2'."
				fi
				if [ ${fld_test_num_matches} -ne 1 ] ; then
					RET_FLD_TEST="Value '$fld_test_key' is not unique for field '$2' (${fld_test_num_matches} occurrences in attribute table of map '$1')."
					return
				fi
			done
		fi
	fi	
	
	# All ok
	RET_FLD_TEST="$2"
}


# FUNCTION
# check_input: Check input data for validity. ORDER MATTERS!
check_input () {
	
	# Check that input vector map has chosen layer.
	eval `v.info -e map="${GIS_OPT_INPUT}" | "${GREP}" "num_dblinks="`
	check_error "Failed to get basic info for chosen layer of input vector map."
	if [ -z ${num_dblinks} ] ; then
		exit_error "Failed to get basic info for chosen layer of input vector map."
	fi
	if [ ${num_dblinks} -lt ${GIS_OPT_LAYER} ] ; then
		exit_error "Chosen layer (${GIS_OPT_LAYER}) does not exist in input vector map."
	fi
	eval `v.info -t map="${GIS_OPT_INPUT}" layer="${GIS_OPT_LAYER}"`
	check_error "Failed to get topology info for chosen layer of input vector map."
	if [ ${points} -lt 1 ] ; then
		exit_error "No points found in chosen layer of input vector map."
	fi
	
	# This step is necessary in case we are using a file-based DBMS for attribute
	# table storage: In this case, the file path to the attribute table might contain
	# variables that need to be resolved. The most simple way to do this is to just
	# call 'v.db.connect' to query the connection parameters of the map to which
	# the attribute table in question is linked. However, in the case of the sorted
	# nodes maps, we do not have an attribute table until it gets copied over from
	# the original input points map. But at that point, we already need the resolved path
	# for the 'db.copy' command! So we just create a dummy map with one random point
	# and a minimal attribute table (using 'v.random') and use that for path resolution.
	# The 'db.copy' command that needs these resolved paths is called a little further
	# down.
	if [ ${DBMS_FILE_PATH} -gt 0 ] ; then
		FROM_DATABASE_PATH=`v.db.connect -g map="${GIS_OPT_INPUT}" | "${CUT}" -d '|' -f 4`
		check_error "Failed to resolve path to attribute table file."
		#echo "[${FROM_DATABASE_PATH}]"
		v.random output="${TMP_VECT_NODES_ORDER}" npoints="1" col="z" -z --o --quiet
		check_error "Failed to generate random dummy map for resolving attribute table path."
		TO_DATABASE_PATH=`v.db.connect -g map="${TMP_VECT_NODES_ORDER}" | "${CUT}" -d '|' -f 4`			
		check_error "Failed to resolve path to attribute table file."
		#echo "[${TO_DATABASE_PATH}]"
	fi
	
	# Validate that geometries (FID) and attribute links (CAT) start at '1',
	# and are in strictly ascending, unbroken order!
	g.message -i "Validating sequence of primary keys in input map..."
	IFS_BACKUP="$IFS"
	IFS="${IFS_NEWLINE}"
	get_grass_cats "${GIS_OPT_INPUT}"
	i=1
	for cur_key in $GRASS_CATS ; do
		if [ $i -ne $cur_key ] ; then
			exit_error "Primary key sequence of input map broken (column: $GRASS_PKEY, expected: $i, got: $cur_key)"
		fi
		if [ -n $BASH_VERSION ] ; then
			let i=${i}+1
		else		
			i=`${EXPR} $i + 1`
		fi
	done
	IFS="${IFS_BACKUP}"
	#
	# From this point onward, we can assume that the GRASS primary keys ('cat') of the input map
	# are in a strict, unbroken sequence "1,2,..n"!
	#
		
	# Check that any records are left after WHERE statement and/or "cats=" has been applied.
	# THIS CHECK MUST BE RUN!
	# Because it also creates the extracted temporary vector map that
	# contains exlusively the points that represent network nodes in layer 1!	
	if [ -n "${GIS_OPT_WHERE}" ] ; then
		# Apply given WHERE to points _only_.
		v.extract where="${GIS_OPT_WHERE}" input="${GIS_OPT_INPUT}" layer="${GIS_OPT_LAYER}" type="point" output="${TMP_VECT_NODES}" --overwrite --quiet		
		check_error "Chosen SQL WHERE statement failed on input vector map."
		# If we get this far then the extract succeeded.
		eval `v.info -t map="${TMP_VECT_NODES}" layer=1`
		check_error "Failed to get info for temporary layer with input points."
		if [ ${points} -lt 1 ] ; then
			exit_error "No points in chosen layer of input vector map (after WHERE)."
		fi
	fi
	if [ -n "${GIS_OPT_CATS}" ] ; then
		# Apply given "cats=" to points _only_.
		v.extract cats="${GIS_OPT_CATS}" input="${GIS_OPT_INPUT}" layer="${GIS_OPT_LAYER}" type="point" output="${TMP_VECT_NODES}" --overwrite --quiet		
		check_error "Chosen 'cats=' selection failed on input vector map."
		# If we get this far then the extract succeeded.
		eval `v.info -t map="${TMP_VECT_NODES}" layer=1`
		check_error "Failed to get info for temporary layer with input points."
		if [ ${points} -lt 1 ] ; then
			exit_error "No points in chosen layer of input vector map (after 'cats=')."
		fi
	fi
	if [ -z "${GIS_OPT_WHERE}" ] && [ -z "${GIS_OPT_CATS}" ] ; then
		# Extract points _only_.
		v.extract input="${GIS_OPT_INPUT}" layer="${GIS_OPT_LAYER}" type="point" output="${TMP_VECT_NODES}" --overwrite --quiet		
		check_error "Points extraction failed on input vector map."
		# If we get this far then the extract succeeded.
		eval `v.info -t map="${TMP_VECT_NODES}" layer=1`
		check_error "Failed to get info for temporary layer with input points."
		if [ ${points} -lt 1 ] ; then
			exit_error "No points in chosen layer of input vector map."
		fi
	fi
		
	# If we get this far, then we can be sure, that:
	# - we have an input map (currently in TMP_VECT_NODES)
	# - the input map contains only points
	# - all attribute data is linked to layer 1
	# - the GRASS primary key sequence of the input map is valid
		
	# Check that "size" attribute (if given) is present and valid.
	if [ -n "${GIS_OPT_SIZE}" ] ; then
		# Check if attribute exists
		#result=`v.info map="${TMP_VECT_NODES}" layer="1" --quiet -c | "${GREP}" -w "${GIS_OPT_SIZE}" | "${GREP}" -c "|${GIS_OPT_SIZE}"`
		result=`v.info -c --quiet map="${TMP_VECT_NODES}" layer="1" | ${CUT} -f 2 -d "|" | "${GREP}" "${GIS_OPT_SIZE}" -w`
		if [ "${result}" != "${GIS_OPT_SIZE}" ] ; then
			exit_error "Attribute '${GIS_OPT_SIZE}' not found in input vector map (case sensitive check)."
		fi
		# Check if attribute type is numeric
		int=`v.info map="${TMP_VECT_NODES}" layer="1" --quiet -c | "${GREP}" -w "${GIS_OPT_SIZE}" | "${GREP}" -i -c "INTEGER|"`
		dbl=`v.info map="${TMP_VECT_NODES}" layer="1" --quiet -c | "${GREP}" -w "${GIS_OPT_SIZE}" | "${GREP}" -i -c "PRECISION|"`
		if [ ${int} -lt 1 ] && [ ${dbl} -lt 1 ] ; then
			exit_error "Attribute '${GIS_OPT_SIZE}' in input vector map is not of numeric type."
		fi
		# - must contain data for each feature (=${points})
		num_vals=`v.db.select -c --quiet columns="${GIS_OPT_KEY}" map="${TMP_VECT_NODES}" layer="1" | "${GREP}" -v -e '^$' -c`
		check_error "Key field (option 'key=') is not valid."
		if [ ${points} -ne ${num_vals} ] ; then
			exit_error "Number of 'size' fields with data (option 'size=') does not match number of input points (${num_keys} vs ${num_vals})."
		fi
		# Check that "size" attribute field name does not clash with a reserved field name
		if [ "${GIS_OPT_SIZE}" = "${NODES_FLD_COORD_X}" ] ; then
			exit_error "Attribute for 'size' must not have reserved field name '${NODES_FLD_COORD_X}'."
		fi
		if [ "${GIS_OPT_SIZE}" = "${NODES_FLD_COORD_Y}" ] ; then
			exit_error "Attribute for 'size' must not have reserved field name '${NODES_FLD_COORD_Y}'."
		fi
	fi
		
	# Warn if reserved field names are present in input map's attribute table
	fld=`v.info map="${TMP_VECT_NODES}" layer="1" --quiet -c | "${GREP}" -i -w "${NODES_FLD_COORD_X}"`
	if [ -n "${fld}" ] ; then
		g.message -w "Found attribute with reserved field name '${NODES_FLD_COORD_X}' in input points map."
	fi
	fld=`v.info map="${TMP_VECT_NODES}" layer="1" --quiet -c | "${GREP}" -i -w "${NODES_FLD_COORD_Y}"`
	if [ -n "${fld}" ] ; then
		g.message -w "Found attribute with reserved field name '${NODES_FLD_COORD_Y}' in input points map."
	fi

	# Success? Then the map with extracted nodes is now our main nodes input map!
	GIS_OPT_INPUT="${TMP_VECT_NODES}"
	
	# Reduce points to those in current region (either cost raster or '-r' flag)?
	if [ -n "${GIS_OPT_COSTMAP}" ] || [ ${GIS_FLAG_R} -eq 1 ] ; then
		# Get bbox polygon of current region.
		v.in.region output="${TMP_VECT_REGION}" --quiet --overwrite
		check_error "Failed to create bounding box of current region."
		# Reduce nodes to those within current region.
		v.select ainput="${TMP_VECT_NODES}" alayer="1" atype="point" binput="${TMP_VECT_REGION}" blayer="1" btype="area" operator="overlap" output="${TMP_VECT_SELECT}" --overwrite --quiet
		check_error "Failed to extract input points in current region."
		points_before="${points}"
		# If we get this far then the selection succeeded.
		eval `v.info -t map="${TMP_VECT_SELECT}" layer=1`
		check_error "Failed to get info for temporary layer with selected input points (points within current region)."
		if [ -n "${GIS_OPT_COSTMAP}" ] && [ ${GIS_FLAG_R} -eq 0 ] ; then
			# Warn if input points were reduced due to current cost map raster's regional extent!
			if [ ${points_before} -ne ${points} ] ; then
				g.message -w "Cost map region limits: input points reduced to ${points} (from ${points_before})."
			fi
		else
			if [ ${points_before} -ne ${points} ] ; then
				g.message -i "Input points reduced to ${points} (from ${points_before}) in current region."
			fi
		fi
		# (Re-)Sort filtered points by primary keys of attribute fields, enforcing a strictly ascending
		# key order with step size "1". All logics running after this point will rely on that order!
		v.sort input="${TMP_VECT_SELECT}" output="${TMP_VECT_SORT}" layer=1 order="asc" sqlbuflen="${GIS_OPT_SQLBUFLEN}" --overwrite
		# Success? Then this filtered map is now our nodes input map!
		GIS_OPT_INPUT="${TMP_VECT_SORT}"
	fi
	
	# Cost raster? Exit if only "null" cells present in current region!
	if [ -n "${GIS_OPT_COSTMAP}" ] ; then
		g.message -i "Checking cost raster values..."
		result=`r.stats input="${GIS_OPT_COSTMAP}" -N nsteps=1 --quiet`
		check_error "Failed to read cell values from cost raster map."
		if [ -z "${result}" ] ; then
			exit_error "Input cost raster map contains only NULL cells in current region."
		fi
	fi
	
	# If option "costres=" is provided, then we need to change the GRASS region
	# resolution NOW, because otherwise the adjustment of input nodes will be inaccurate!
	if [ ${GIS_OPT_COSTRES} -gt 1 ] ; then
		#g.message -i "Resampling cost raster to $GIS_OPT_COSTRES times original resolution..."
		# Store original region
		g.region save="${TMP_GEN_REGION_ORG}"
		check_error "Failed to store original GRASS region prior to increasing resolution."
		# Increase current resolution:
		awk_calc "${nsres}/${GIS_OPT_COSTRES}"
		new_nsres="$AWK_VALUE"
		awk_calc "${ewres}/${GIS_OPT_COSTRES}"
		new_ewres="$AWK_VALUE"		
		g.region nsres="${new_nsres}" ewres="${new_ewres}"	
		check_error "Failed to increase GRASS region resolution."
	fi
	
	# Cost raster? Adjust input nodes to lie exactly in the center of region's raster cells!
	# We do this by rasterizing the original input points first, then re-vectorizing them
	# as points that lie exactly in the centers of the raster cells (that represent the
	# original input points). We then re-attach the original attribute table. This works,
	# because we can preserve the 'cat' primary key throught these operations.
	if [ -n "${GIS_OPT_COSTMAP}" ] ; then		
		g.message -i "Aligning input nodes (points) with cost raster..."
		# Store number of points of original input map:
		points_before="${points}"
		# Rasterize original input nodes (points), and re-vectorized them as an aligned copy.
		v.to.rast input="${GIS_OPT_INPUT}" type="point" use="cat" output="${TMP_RAST_NODES_RASTERIZED}" --o --quiet
		check_error "Failed to rasterize input nodes (points)."
		# Note: This calls r.to.vect without creating an attribute table! We connect that table later.
		if [ ${DBMS_FILE_PATH} -gt 0 ] ; then
			# Make a dummy vector map first, just so we can use v.db.connect on it for path resolution:
			v.random output="${TMP_VECT_NODES_ALIGNED}" npoints="1" col="z" -z --o --quiet 2>/dev/null
			check_error "Failed to generate random dummy map for resolving attribute table path."
			TO_DATABASE_PATH=`v.db.connect -g map="${TMP_VECT_NODES_ALIGNED}" | "${CUT}" -d '|' -f 4`	
			check_error "Failed to resolve path to attribute table file."
			#echo "[${TO_DATABASE_PATH}]"
		fi
		r.to.vect -t -v input="${TMP_RAST_NODES_RASTERIZED}" type="point" col="cat" output="${TMP_VECT_NODES_ALIGNED}" --o --quiet 2>/dev/null
		check_error "Failed to re-vectorize input nodes (points) for alignment."		
		if [ ${DBMS_FILE_PATH} -gt 0 ] ; then
			# File-based DBMS: Resolve database file path for 'db.copy':
			FROM_DATABASE_PATH=`v.db.connect -g map="${GIS_OPT_INPUT}" | "${CUT}" -d '|' -f 4`
			check_error "Failed to resolve path to attribute table file."
			#echo "[${FROM_DATABASE_PATH}]"						
			db.copy from_database="${FROM_DATABASE_PATH}" from_table="${GIS_OPT_INPUT}" to_database="${TO_DATABASE_PATH}" to_table="${TMP_VECT_NODES_ALIGNED}" --o --quiet 2>/dev/null
		else
			# Client/server DBMS: just use singular database:
			db.copy from_table="${GIS_OPT_INPUT}" to_table="${TMP_VECT_NODES_ALIGNED}" --o --quiet 2>/dev/null		
		fi
		check_error "Failed to attach attribute table for aligned input nodes (points)."		
		get_tbl_info "${GIS_OPT_INPUT}"
		check_error "Failed to get attribute table information for nodes input map (rasterization pass)."
		
		if [ ${DBMS_FILE_PATH} -gt 0 ] ; then
			# File-based DBMS: Resolve path to individual attribute table file
			# (we recycle the path that we resolved earlier, for the 'db.copy' operation):		
			v.db.connect map="${TMP_VECT_NODES_ALIGNED}" database="$TO_DATABASE_PATH" table="${TMP_VECT_NODES_ALIGNED}" --o --quiet
		else
			# Client/server DBMS: Just link to table in singular database as provided by 'get_tbl_info'
			v.db.connect map="${TMP_VECT_NODES_ALIGNED}" database="$attribute_database" table="${TMP_VECT_NODES_ALIGNED}" --o --quiet
		fi
		check_error "Failed to attach attribute table to aligned input nodes (points)."
		
		# Check that none of the input points were lost during rasterization.
		eval `v.info -t map="${TMP_VECT_NODES_ALIGNED}" layer=1`
		check_error "Failed to get info for temporary layer with aligned input points."
		if [ ${points_before} -ne ${points} ] ; then
			exit_error "Input nodes reduced after alignment with cost raster. Please ensure that computational region's resolution is sufficient."			
		fi
		# Success? Then the map with aligned nodes is now our main nodes input map!
		GIS_OPT_INPUT="${TMP_VECT_NODES_ALIGNED}"
		if [ ${DBMS_FILE_PATH} -gt 0 ] ; then
			# Make a dummy vector map first, just so we can use v.db.connect on it for path resolution:
			v.random output="${TMP_VECT_NODES_ORDER}" npoints="1" col="z" -z --o --quiet 2>/dev/null
			check_error "Failed to generate random dummy map for resolving attribute table path."
			TO_DATABASE_PATH=`v.db.connect -g map="${TMP_VECT_NODES_ORDER}" | "${CUT}" -d '|' -f 4`	
			check_error "Failed to resolve path to attribute table file."
			#echo "[${TO_DATABASE_PATH}]"
		fi
		# UNFORTUNATELY, since we have no control over the order in which r.to.vect creates
		# geometries (FID), we have to order the input nodes into a strictly ascending sequence!
		# Ensure that geometries (FID) and attribute links (CAT) start at '1',
		# and are in strictly ascending, unbroken order!	
		# After ordering the point geometries (using "v.extract -t" and "v.patch -a", i.e _without_
		# copying any attribute table data, we can blindly copy the original attribute table and
		# attach it to the new, ordered points map. This will work, because we have already made sure
		# that the attribute table data is well-ordered by validating the primary key sequence at
		# the start of "check_input"!
		#		
		min=1
		max=${points}
		g.message -i "Ensuring strict order of adjusted input nodes [$min..$max]:"
		i=$min
		while [ $i -le $max ] ; do
			if [ $i -eq $min ] ; then
				v.extract -t input="${GIS_OPT_INPUT}" cats="$i" output="${TMP_VECT_EXTRACT}" --o --quiet 2>/dev/null
				check_error "Primary key #$i not in unbroken sequence $min..$max (input nodes map, pass 2)."
				g.copy vect="${TMP_VECT_EXTRACT}","${TMP_VECT_NODES_ORDER}" --o --quiet 2>/dev/null
				check_error "Failed to copy input node #$i to new, ordered map of adjusted input nodes."
			else
				v.extract -t input="${GIS_OPT_INPUT}" cats="$i" output="${TMP_VECT_EXTRACT}" --o --quiet 2>/dev/null
				check_error "Primary key #$i not in unbroken sequence $min..$max (input nodes map, pass 2)."
				v.patch -a input="${TMP_VECT_EXTRACT}" output="${TMP_VECT_NODES_ORDER}" --o --quiet
				check_error "Failed to add input node #$i to ordered map of adjusted input nodes."
			fi
			g.message -p "${i} ${max} 1"
			if [ -n $BASH_VERSION ] ; then
				let i=${i}+1
			else
				i=`${EXPR} $i + 1`
			fi
		done		
		# Now attach attribute table!		
		get_tbl_info "${GIS_OPT_INPUT}"
		check_error "Failed to get attribute table information for nodes input map (rasterization pass 2)."
		if [ ${DBMS_FILE_PATH} -gt 0 ] ; then
			# File-based DBMS: Resolve database file path for 'db.copy':
			FROM_DATABASE_PATH=`v.db.connect -g map="${GIS_OPT_INPUT}" | "${CUT}" -d '|' -f 4`
			check_error "Failed to resolve path to attribute table file."
			#echo "[${FROM_DATABASE_PATH}]"
			db.copy from_database="${FROM_DATABASE_PATH}" from_table="${GIS_OPT_INPUT}" to_database="${TO_DATABASE_PATH}" to_table="${TMP_VECT_NODES_ORDER}" --o --quiet 2>/dev/null			
		else
			# Client/server DBMS: just use singular database:
			db.copy from_database="$attribute_database" from_table="${GIS_OPT_INPUT}" to_table="${TMP_VECT_NODES_ORDER}" --o --quiet 2>/dev/null
		fi
		check_error "Failed to create new attribute table for ordered map of adjusted input nodes."
		#db.copy from_database="$attribute_database" from_table="${GIS_OPT_INPUT}" to_table="${TMP_VECT_NODES_ORDER}" --o --quiet 2>/dev/null
		#check_error "Failed to create new attribute table for ordered map of input nodes (pass 2)."
		if [ ${DBMS_FILE_PATH} -gt 0 ] ; then
			# File-based DBMS: Resolve path to individual attribute table file
			# (we recycle the path that we resolved earlier, for the 'db.copy' operation):		
			v.db.connect map="${TMP_VECT_NODES_ORDER}" database="$TO_DATABASE_PATH" table="${TMP_VECT_NODES_ORDER}" --o --quiet
		else
			# Client/server DBMS: Just link to table in singular database as provided by 'get_tbl_info'
			v.db.connect map="${TMP_VECT_NODES_ORDER}" database="$attribute_database" table="${TMP_VECT_NODES_ORDER}" --o --quiet
		fi		
		#v.db.connect map="${TMP_VECT_NODES_ORDER}" database="$attribute_database" table="${TMP_VECT_NODES_ORDER}" --o --quiet
		check_error "Failed to attach attribute table to ordered map of adjusted input nodes."
		
		# Success? Then the map with STRICTLY ORDERED nodes is now our main nodes input map!
		GIS_OPT_INPUT="${TMP_VECT_NODES_ORDER}"		
	fi
	
	#DEBUG
	#d.erase
	#d.vect "${GIS_OPT_INPUT}"
	#read -n 1 -s
	#v.db.select "${GIS_OPT_INPUT}"	
	#exit_error "DEBUG"
	
	# Check if there are at least two points left now!
	eval `v.info -t map="${GIS_OPT_INPUT}" layer=1`
	check_error "Failed to get info for temporary layer with input points."
	if [ ${points} -lt 1 ] ; then
		exit_error "No points in chosen layer of input vector map (after 'cats=')."
	fi
	if [ ${points} -lt 2 ] ; then
		exit_error "Minimum of 2 points not available in input. Check 'cats=' and 'where=' options; if using a cost raster: check region."
	fi
	
	# Store (filtered) input points in global var:
	NUM_INPUT_NODES="${points}"

	
	# ATTENTION: ORDER MATTERS!
	# After this point, we run all validity checks for which it is
	# sufficient that they are passed by the *filtered* (if applicable) set of points.
	# This reduces overhead for slow validation ops on filtered input points.
	#
	
	# Check that 'key' field is valid:
	g.message -i "Checking key (and label) field/content validity..."
	# - must exist (case sensitive, white space possible)
	result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | ${CUT} -f 2 -d "|" | "${GREP}" "${GIS_OPT_KEY}" -w`
	if [ "${result}" != "${GIS_OPT_KEY}" ] ; then
		exit_error "Chosen 'key' field '${GIS_OPT_KEY}' does not exist in input points map (option 'key=')."
	fi
	# - must contain data for each feature (=${points})
	num_keys=`v.db.select -c --quiet columns="${GIS_OPT_KEY}" map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" -v -e '^$' -c`
	check_error "Key field (option 'key=') does not contain a key value for every feature."
	if [ ${points} -ne ${num_keys} ] ; then
		exit_error "Number of primary key records (option 'key=') does not match number of input points (${num_keys} keys vs ${points} points)."
	fi
	# - must be of type INTEGER
	result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "INTEGER|${GIS_OPT_KEY}" -w -c`
	if [ ${result} -ne 1 ] ; then
		exit_error "Type of 'key' field in input points layer is not integer (option 'key=')."
	fi
	# - must be UNIQUE for each feature: We us sort's abiliity to remove duplicate lines after sorting.
	#   At the same time, this will make sure that empty field values will be discarded.
	count_total=`v.db.select -c --quiet columns="${GIS_OPT_KEY}" map="${GIS_OPT_INPUT}" layer="1" | ${SORT} | ${WC} -l`
	count_unique=`v.db.select -c --quiet columns="${GIS_OPT_KEY}" map="${GIS_OPT_INPUT}" layer="1" | ${SORT} -u | ${WC} -l`
	# If number of unique lines after sorting key list != total number of lines: We have duplicates!
	if [ ${count_unique} -ne ${count_total} ] ; then
		exit_error "Primary key column '$key' does not contain unique data, (only $count_unique of $count_total values are unique)."
	fi
	# If number of lines != number of input points: We have empty values!
	if [ ${NUM_INPUT_NODES} -ne ${count_total} ] ; then
		exit_error "Primary key column '$key' does not contain as many values as there are input points, (only $count_total values present)."
	fi
	# - must not be the same as GRASS primary key for this layer	
	cmd=`v.info -e map="${GIS_OPT_INPUT}"`	
	check_error "Failed to query (filtered) input layer for extended metadata."
	eval_ws_safe "${cmd}" "attribute_primary_key"
	if [ "${EVAL_RESULT}" = "${GIS_OPT_KEY}" ] ; then
		exit_error "Name of 'key' field ('$key') is the same as GRASS primary key of input points layer (option 'key=')."
	fi

	# Set/validate 'label' field.
	if [ -n "${GIS_OPT_LABEL}" ] && [ "${GIS_OPT_LABEL}" != "${GIS_OPT_KEY}" ] ; then		
		# Check that 'label' field is valid:
		# - must exist (case sensitive, white space possible)
		result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | ${CUT} -f 2 -d "|" | "${GREP}" "${GIS_OPT_LABEL}" -w`
		if [ "${result}" != "${GIS_OPT_LABEL}" ] ; then
			exit_error "Chosen label field '${GIS_OPT_LABEL}' does not exist in input points map (option 'label=')."
		fi
		# - must contain data for each feature (=${points})
		num_keys=`v.db.select -c --quiet columns="${GIS_OPT_LABEL}" map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" -v -e '^$' -c`
		check_error "Label field (option 'label=') is not valid."
		if [ ${points} -ne ${num_keys} ] ; then
			exit_error "Number of label field records (option 'label=') does not match number of input points (${num_keys} vs ${num_points})."
		fi
		# - must be of type, integer, double or text
		LABEL_TYPE="UNKNOWN"
		result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "INTEGER|${GIS_OPT_LABEL}" -w -c`
		if [ ${result} -eq 1 ] ; then
			LABEL_TYPE="INTEGER"
		fi
		result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "DOUBLE PRECISION|${GIS_OPT_LABEL}" -w -c`
		if [ ${result} -eq 1 ] ; then
			LABEL_TYPE="DOUBLE PRECISION"
		fi
		result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "CHARACTER|${GIS_OPT_LABEL}" -w -c`
		if [ ${result} -eq 1 ] ; then
			LABEL_TYPE="CHARACTER"
		fi
		result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "TEXT|${GIS_OPT_LABEL}" -w -c`
		if [ ${result} -eq 1 ] ; then
			LABEL_TYPE="TEXT"
		fi
		if [ "${LABEL_TYPE}" = "UNKNOWN" ] ; then
			exit_error "Unable to determine type of 'label' field in input points layer (option 'label=')."
		fi
		# - should be unique for each feature with valid primary key
		count_total=`v.db.select -c --quiet columns="${GIS_OPT_KEY}" map="${GIS_OPT_INPUT}" layer="1" | ${SORT} | ${WC} -l`
		count_unique=`v.db.select -c --quiet columns="${GIS_OPT_KEY}" map="${GIS_OPT_INPUT}" layer="1" | ${SORT} -u | ${WC} -l`
		# If number of unique lines after sorting key list != total number of lines: We have duplicates!
		if [ ${count_unique} -ne ${count_total} ] ; then
			g.message -w "Label field '${GIS_OPT_LABEL}' contains at least on duplicate entry (option 'label=')."
		fi
		# - must not be the same as GRASS primary key for this layer	
		cmd=`v.info -e map="${GIS_OPT_INPUT}"`	
		check_error "Failed to query (filtered) input layer for extended metadata."
		eval_ws_safe "${cmd}" "attribute_primary_key"
		if [ "${EVAL_RESULT}" = "${GIS_OPT_LABEL}" ] ; then
			exit_error "Name of 'label' field ('$key') is the same as GRASS primary key of input points layer (option 'label=')."
		fi
	else
		# Default: label field = key field
		GIS_OPT_LABEL="${GIS_OPT_KEY}"
		LABEL_TYPE="INTEGER"
	fi

	# Model 'attsim': check that all fields exist in input
	if [ -n "${GIS_OPT_ATTRIBUTES}" ] ; then
		cmd=`v.db.select map="${GIS_OPT_INPUT}" layer="1" columns="${GIS_OPT_ATTRIBUTES}" -c --quiet`
		check_error "Not all attribute fields specified by 'attributes=' exist in input points map."
	fi
	
	# Run points topology test?
	grep_is_zero "${GIS_OPT_THRESHOLD}"
	if [ -n "${GREP_VALUE}" ] ; then
		# Run topological test for input points using v.distance and a user-definable threshold.
		g.message -i "Checking input points (${NUM_INPUT_NODES}) for duplicates:"		
		get_primary_keys "${GIS_OPT_INPUT}"
		step=1
		IFS_BACKUP="$IFS"
		IFS="${IFS_NEWLINE}"
		for key in $PRIMARY_KEYS ; do
			# TODO: One of the modules in this loop pollutes the console with
			#       'WARNING: Values in column <cat> will be overwritten' messages.
			get_label "${GIS_OPT_INPUT}" "$key"
			# Retrieve the one feature with the current primary key value and extract it to a
			# separate temp map.
			get_where_clause "${key}"
			v.extract input="${GIS_OPT_INPUT}" layer="1" type="point" where="${WHERE}" output="${TMP_VECT_EXTRACT}" -t --overwrite --quiet 2>/dev/null
			check_error "Failed to extract point with primary key='${key}' from copy of input vector map."
			# Retrieve all the other features and extract them to a separate temp map, as well.
			get_where_clause_inv "${key}"
			v.extract input="${GIS_OPT_INPUT}" layer="1" type="point" where="${WHERE}" output="${TMP_VECT_LINKS}" -t --overwrite --quiet 2>/dev/null
			check_error "Failed to extract points with primary key<>'${key}' from copy of input vector map."
			# Add attribute table with column to hold 'dist' value to extracted point
			${V_DB_ADDTABLE} map="${TMP_VECT_EXTRACT}" columns="dist DOUBLE PRECISION" --quiet 2>/dev/null
			check_error "Failed to add attribute table to map with extracted point with primary key='${key}'."
			# Get minimum distance between current point and all others and store it in attribute table.
			v.distance from="${TMP_VECT_EXTRACT}" to="${TMP_VECT_LINKS}" upload="dist" column="dist" --quiet
			check_error "Failed to compute distance between point with primary key '${key}' and all other points of input map."
			# Try to retrieve a distance value that is less than the threshold for duplicates.
			result=`v.db.select map="${TMP_VECT_EXTRACT}" columns="dist" where="dist<${GIS_OPT_THRESHOLD}" -c --quiet`
			if [ -n "${result}" ] ; then
				exit_error "Point '${key}' (label: '${LABEL}') lies too close to another point (distance: ${result} with threshold=${GIS_OPT_THRESHOLD}) and is considered a duplicate."
			fi
			# Show progress			
			g.message -p "${step} ${NUM_INPUT_NODES} 1"
			if [ -n $BASH_VERSION ] ; then
				let step=${step}+1
			else
				step=`"${EXPR}" ${step} + 1`
			fi
		done
		IFS="${IFS_BACKUP}"
	fi

	# CHECK 'INITIAL' LINKS MAP AFTER OTHER INPUT MAP TESTS HAVE BEEN COMPLETED
	# AND AFTER THE INPUT POINTS MAP HAS BEEN FILTERED. 
	# If we have an 'initial' links map, then we must run thorough checks on it
	# to ascertain its validity in terms of both geometry and attributes.
	# This is because, the links map is "normally" created by v.net.models itself,
	# i.e. with full control over its structure and content; consequently, much
	# of the program logics make very strong assumptions about this map. 
	if [ -n "${GIS_OPT_INITIAL}" ] ; then
		g.message -i "Verifying validity of initial links map (option 'initial=')..."
		#
		# 1. Test basic map properties: attribute table exists and only lines present?
		#
		eval `v.info -e map="${GIS_OPT_INITIAL}" | "${GREP}" "num_dblinks="`
		if [ -z ${num_dblinks} ] ; then
			exit_error "Failed to get basic info for chosen layer of input vector map."
		fi
		if [ ${num_dblinks} -lt 1 ] ; then
			exit_error "Table connection for layer '1' does not exist in 'initial' vector input map."
		fi
		eval `v.info -t map="${GIS_OPT_INITIAL}" layer="1"`
		check_error "Failed to get topology info for 'initial' input vector map."		
		if [ ${points} -gt 0 ] || [ ${boundaries} -gt 0 ] || [ ${centroids} -gt 0 ] || [ ${areas} -gt 0 ] || [ ${islands} -gt 0 ] ; then
			exit_error "Vector input map 'initial' must only contain line geometries."
		fi
		if [ ${lines} -lt 1 ] ; then
			exit_error "Vector input map 'initial' must contain at least one line geometry."
		fi
		# "from_id"
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_FROM_ID}" "INTEGER" 			"TRUE"	"FALSE"
		if [ "${RET_FLD_TEST}" != "${LINKS_FLD_FROM_ID}" ] ; then
			exit_error "${RET_FLD_TEST}"
		fi
		# "to_id"
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_TO_ID}" 	"INTEGER" 			"TRUE"	"FALSE"
		if [ "${RET_FLD_TEST}" != "${LINKS_FLD_TO_ID}" ] ; then
			exit_error "${RET_FLD_TEST}"
		fi
		# from_lbl
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_FROM_LBL}" "CHARACTER" 	"TRUE"	"FALSE"
		if [ "${RET_FLD_TEST}" != "${LINKS_FLD_FROM_LBL}" ] ; then
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_FROM_LBL}" "TEXT" 	"TRUE"	"FALSE"
			if [ "${RET_FLD_TEST}" != "${LINKS_FLD_FROM_LBL}" ] ; then
				exit_error "Field '${LINKS_FLD_FROM_LBL}' in attribute table of map '${GIS_OPT_INITIAL}' is not of type 'CHARACTER' or 'TEXT'."
			fi
		fi
		# to_lbl
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_TO_LBL}" 	"CHARACTER" 	"TRUE"	"FALSE"
		if [ "${RET_FLD_TEST}" != "${LINKS_FLD_TO_LBL}" ] ; then
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_TO_LBL}" 	"TEXT" 	"TRUE"	"FALSE"
			if [ "${RET_FLD_TEST}" != "${LINKS_FLD_TO_LBL}" ] ; then
				exit_error "Field '${LINKS_FLD_TO_LBL}' in attribute table of map '${GIS_OPT_INITIAL}' is not of type 'CHARACTER' or 'TEXT'."
			fi
		fi
		#
		# If these attributes are missing, we trigger auto-computation:
		TRIGGER_ATTR_COORDINATES="FALSE" # Rebuild all coordinates stored in attributes (from/to x/y)
		TRIGGER_ATTR_LENGTH="FALSE"
		TRIGGER_ATTR_COST="FALSE"		
		# Coordinate fields
		num_init_valid_coord_flds=0
		# from_x
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_FROM_X}"
		if [ "${RET_FLD_TEST}" == "${LINKS_FLD_FROM_X}" ] ; then
			# Field exists: Check if it is ok.
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_FROM_X}" 	"DOUBLE PRECISION" 	"TRUE"	"FALSE"
			if [ "${RET_FLD_TEST}" != "${LINKS_FLD_FROM_X}" ] ; then
				g.message -e "Attribute field '${LINKS_FLD_FROM_X}' has wrong type or incomplete data."
				g.message -e "Please fix manually or delete ALL coordinate fields from initial links map to rebuild automatically."
				g.message -e "Coordinate fields are: '${LINKS_FLD_FROM_X}'/'${LINKS_FLD_FROM_Y}' and '${LINKS_FLD_TO_X}'/'${LINKS_FLD_TO_Y}'."
				exit_error "${RET_FLD_TEST}"
			else
				num_init_valid_coord_flds=`"${EXPR}" ${num_init_valid_coord_flds} + 1`
			fi
		fi
		# from_x
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_FROM_Y}"
		if [ "${RET_FLD_TEST}" == "${LINKS_FLD_FROM_Y}" ] ; then
			# Field exists: Check if it is ok.
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_FROM_Y}" 	"DOUBLE PRECISION" 	"TRUE"	"FALSE"
			if [ "${RET_FLD_TEST}" != "${LINKS_FLD_FROM_Y}" ] ; then
				g.message -e "Attribute field '${LINKS_FLD_FROM_Y}' has wrong type or incomplete data."
				g.message -e "Please fix manually or delete ALL coordinate fields from initial links map to rebuild automatically."
				g.message -e "Coordinate fields are: '${LINKS_FLD_FROM_X}'/'${LINKS_FLD_FROM_Y}' and '${LINKS_FLD_TO_X}'/'${LINKS_FLD_TO_Y}'."
				exit_error "${RET_FLD_TEST}"
			else
				num_init_valid_coord_flds=`"${EXPR}" ${num_init_valid_coord_flds} + 1`
			fi
		fi		
		# to_x
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_TO_X}"
		if [ "${RET_FLD_TEST}" == "${LINKS_FLD_TO_X}" ] ; then
			# Field exists: Check if it is ok.
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_TO_X}" 	"DOUBLE PRECISION" 	"TRUE"	"FALSE"
			if [ "${RET_FLD_TEST}" != "${LINKS_FLD_TO_X}" ] ; then
				g.message -e "Attribute field '${LINKS_FLD_TO_X}' has wrong type or incomplete data."
				g.message -e "Please fix manually or delete ALL coordinate fields from initial links map to rebuild automatically."
				g.message -e "Coordinate fields are: '${LINKS_FLD_FROM_X}'/'${LINKS_FLD_FROM_Y}' and '${LINKS_FLD_TO_X}'/'${LINKS_FLD_TO_Y}'."
				exit_error "${RET_FLD_TEST}"
			else
				num_init_valid_coord_flds=`"${EXPR}" ${num_init_valid_coord_flds} + 1`
			fi
		fi
		# to_y
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_TO_Y}"
		if [ "${RET_FLD_TEST}" == "${LINKS_FLD_TO_Y}" ] ; then
			# Field exists: Check if it is ok.
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_TO_Y}" 	"DOUBLE PRECISION" 	"TRUE"	"FALSE"
			if [ "${RET_FLD_TEST}" != "${LINKS_FLD_TO_Y}" ] ; then
				g.message -e "Attribute field '${LINKS_FLD_TO_Y}' has wrong type or incomplete data."
				g.message -e "Please fix manually or delete ALL coordinate fields from initial links map to rebuild automatically."
				g.message -e "Coordinate fields are: '${LINKS_FLD_FROM_X}'/'${LINKS_FLD_FROM_Y}' and '${LINKS_FLD_TO_X}'/'${LINKS_FLD_TO_Y}'."
				exit_error "${RET_FLD_TEST}"
			else
				num_init_valid_coord_flds=`"${EXPR}" ${num_init_valid_coord_flds} + 1`
			fi
		fi
		#
		# Make sure that ALL FOUR coordinate fields are valid or trigger auto-computation:
		if [ ${num_init_valid_coord_flds} -eq 0 ] ; then
			# No coordinate fields present: trigger
			g.message -w "Coordinate attribute fields are missing from initial map '${GIS_OPT_INITIAL}'."
			g.message -w "They will be added and their contents computed automatically."
			g.message -w "Coordinate fields are: '${LINKS_FLD_FROM_X}'/'${LINKS_FLD_FROM_Y}' and '${LINKS_FLD_TO_X}'/'${LINKS_FLD_TO_Y}'."
			TRIGGER_ATTR_COORDINATES="TRUE"
		else
			if [ ${num_init_valid_coord_flds} -lt 4 ] ; then
				# At least one coord field present, but less than four valid fields: error
				g.message -e "Not all coordinate fields present or invalid coordinate field(s) found."
				g.message -e "Please fix manually or delete ALL coordinate fields from initial links map to rebuild automatically."
				g.message -e "Coordinate fields are: '${LINKS_FLD_FROM_X}'/'${LINKS_FLD_FROM_Y}' and '${LINKS_FLD_TO_X}'/'${LINKS_FLD_TO_Y}'."
				exit ${EXIT_ERROR}
			fi
		fi			
		# length_km: If this exists, then it must have the right type, and it must be complete!
		# If it does not exist, then it will be rebuild automatically ONLY if 'length_m' is also missing!
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_LEN_KM}"
		if [ "${RET_FLD_TEST}" == "${LINKS_FLD_LEN_KM}" ] ; then
			# Field exists: Check if it is ok.
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_LEN_KM}" 	"DOUBLE PRECISION" 	"TRUE"	"FALSE"
			if [ "${RET_FLD_TEST}" != "${LINKS_FLD_LEN_KM}" ] ; then
				g.message -e "Attribute field '${LINKS_FLD_LEN_KM}' has wrong type or incomplete data."
				g.message -e "Please fix manually or delete it AND field '${LINKS_FLD_LEN_M}' from initial links map to rebuild both automatically."
				exit_error "${RET_FLD_TEST}"
			fi
		fi
		# [length_m] -> ad hoc	[+length_km]
		check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_LEN_M}"
		if [ "${RET_FLD_TEST}" == "${LINKS_FLD_LEN_M}" ] ; then
			# Field exists: Check if it is ok.
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_LEN_M}" 	"DOUBLE PRECISION" 	"TRUE"	"FALSE"
			if [ "${RET_FLD_TEST}" != "${LINKS_FLD_LEN_M}" ] ; then
				g.message -e "Attribute field '${LINKS_FLD_LEN_M}' has wrong type or incomplete data."
				g.message -e "Please fix manually or delete field from initial links map to rebuild automatically."
				exit_error "${RET_FLD_TEST}"
			fi
			TRIGGER_ATTR_LENGTH="FALSE"
		else
			# Field does not exist at all: Trigger auto-computation:
			g.message -w "Attribute field '${LINKS_FLD_LEN_M}' is missing from initial map '${GIS_OPT_INITIAL}'."
			g.message -w "It will be added and its contents computed automatically."
			TRIGGER_ATTR_LENGTH="TRUE"
			# Check if field "length_km" also exists and warn if it does, because it will be re-computed:				
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_LEN_KM}"
			if [ "${RET_FLD_TEST}" == "${LINKS_FLD_LEN_KM}" ] ; then
				# It exists (further up, we have already made sure that it has the right type!).
				g.message -w "Contents of existing field '${LINKS_FLD_LEN_KM}' will also be re-computed."
			fi					
		fi
		# [cost] -> ad hoc (if cost raster provided) 
		if [ -n "${GIS_OPT_COSTMAP}" ] ; then # There is a cost map
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_COST}"
			if [ "${RET_FLD_TEST}" == "${LINKS_FLD_COST}" ] ; then
				# Field exists: Check if it is ok.
				check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_COST}" 	"DOUBLE PRECISION" 	"TRUE"	"FALSE"
				if [ "${RET_FLD_TEST}" != "${LINKS_FLD_COST}" ] ; then
					g.message -e "Attribute field '${LINKS_FLD_COST}' has wrong type or incomplete data."
					g.message -e "Please fix manually or delete field from initial links map and provide 'cost=' to rebuild automatically."
					exit_error "${RET_FLD_TEST}"
				else
					# 'cost' attribute exists and has complete data, but we also have a costmap: ERROR
					g.message -e "Initial links map '${GIS_OPT_INITIAL}' has a valid field '${LINKS_FLD_COST}' with cost data."
					g.message -e "But a cost raster ('${GIS_OPT_COSTMAP}') has also been provided via option 'cost='."
					exit_error "Ambiguous cost data sources. Choose one or the other."
				fi
				TRIGGER_ATTR_COST="FALSE"
			else
				# Field does not exist at all: Trigger auto-computation:
				g.message -w "Attribute field '${LINKS_FLD_COST}' is missing from initial map '${GIS_OPT_INITIAL}'."
				g.message -w "It will be added and its contents computed automatically."
				TRIGGER_ATTR_COST="TRUE"
			fi
		else # no cost map, but maybe still a cost field in initial map
			RUNMODE_COST="FALSE" # default if no cost raster provided
			check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_COST}"
			if [ "${RET_FLD_TEST}" == "${LINKS_FLD_COST}" ] ; then
				# Field exists: Check if it is ok.
				check_field "${GIS_OPT_INITIAL}"	"${LINKS_FLD_COST}" 	"DOUBLE PRECISION" 	"TRUE"	"FALSE"
				if [ "${RET_FLD_TEST}" != "${LINKS_FLD_COST}" ] ; then
					g.message -e "Attribute field '${LINKS_FLD_COST}' has wrong type or incomplete data."
					g.message -e "Please fix manually or delete field from initial links map and provide 'cost=' to rebuild automatically."
					exit_error "${RET_FLD_TEST}"
				else
					RUNMODE_COST="TRUE" # We have a valid 'cost' field and can switch into cost-based mode now.
					TRIGGER_ATTR_COST="FALSE" # Data in field is fine: No need to trigger rebuilding.
				fi
			else
				TRIGGER_ATTR_COST="FALSE" # No cost field: No need to trigger rebuilding.
			fi
		fi
		if [ ${GIS_FLAG_S} -eq 1 ] ; then
			# Skipping consistency checks.
			g.message -i "Consistency checks skipped. Some statistics might be faulty."
		else
			# CHECK INPUT LINKS IN RELATION TO INPUT NODES	
			#
			# 1. Check that links and nodes MATCH. The aim is to prevent users from
			#    using an links map computed for a different set of input nodes.
			#   
			# First check that all nodes in $GIS_OPT_INPUT are connected to at least
			# one link in $GIS_OPT_INITIAL via the from_id/to_id fields.
			# If not, then we issue a warning, since the presence of unconnected nodes
			# is not harmful.
			# Get and store attribute table info for links maps:
			get_tbl_info "${GIS_OPT_INITIAL}"
			attribute_table_links="${attribute_table}"
			attribute_database_links="${attribute_database}"
			# Get and store attribute table info for nodes maps:
			get_tbl_info "${GIS_OPT_INPUT}"
			attribute_table_nodes="${attribute_table}"
			attribute_database_nodes="${attribute_database}"
			#
			g.message -i "Checking connections of input nodes with input links (1/3):"
			get_primary_keys "${GIS_OPT_INPUT}"
			OLD_IFS="$IFS"
			IFS="${IFS_NEWLINE}"
			i=0
			for key in ${PRIMARY_KEYS} ; do
				if [ -n $BASH_VERSION ] ; then
					let i=${i}+1
				else
					i=`"${EXPR}" ${i} + 1`
				fi
			done
			max=${i}
			i=0
			for key in ${PRIMARY_KEYS} ; do
				# Step through all input nodes and count number of connections:
				num_connections_from=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_FROM_ID} FROM ${GIS_OPT_INITIAL} WHERE ${LINKS_FLD_FROM_ID}=$key;" -c --quiet | "${GREP}" "${key}" -c`
				if [ -z "${num_connections_from}" ] ; then
					num_connections_from=0
				fi
				num_connections_to=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_TO_ID} FROM ${GIS_OPT_INITIAL} WHERE ${LINKS_FLD_TO_ID}=$key;" -c --quiet | "${GREP}" "${key}" -c`
				if [ -z "${num_connections_to}" ] ; then
					num_connections_to=0
				fi
				if [ -n $BASH_VERSION ] ; then
					let num_connections_total=${num_connections_from}+${num_connections_to}
				else
					num_connections_total=`"${EXPR}" ${num_connections_from} + ${num_connections_to}`
				fi
				if [ ${num_connections_total} -lt 1 ] ; then
					g.message -w "Node with primary key '${GIS_OPT_KEY}=${key}' is unconnected in links map."
				fi
				if [ -n $BASH_VERSION ] ; then
					let i=${i}+1
				else
					i=`"${EXPR}" ${i} + 1`
				fi
				g.message -p "${i} ${max} 1"
			done
			IFS="${OLD_IFS}"
		
			# Now the other way around: we traverse all from/to ID fields in links map
			# and check if there are two corresponding nodes in GIS_OPT_INPUT.
			# If NOT, then we have a FATAL ERROR.
			g.message -i "Checking connections of input nodes with input links (2/3):"
			get_grass_cats "${GIS_OPT_INITIAL}"
			OLD_IFS="$IFS"
			IFS="${IFS_NEWLINE}"
			i=0
			for cat in ${GRASS_CATS} ; do
				if [ -n $BASH_VERSION ] ; then
					let i=${i}+1
				else
					i=`"${EXPR}" ${i} + 1`
				fi
			done		
			max=${i}		
			# Check all from_id fields:
			i=0
			for cat in ${GRASS_CATS} ; do
				# Get value of 'from_id' for this link:
				init_from_id=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_FROM_ID} FROM ${GIS_OPT_INITIAL} WHERE ${GRASS_PKEY}=${cat};" -c --quiet`
				check_error "Failed to retrieve value of field ('${LINKS_FLD_FROM_ID}') from links input map ('${GRASS_PKEY}=${cat}')."
				# Check if 'from_id' occurs as primary key of any input node:
				num_connections_from=`db.select database="${attribute_database_nodes}" sql="SELECT ${GIS_OPT_KEY} FROM ${GIS_OPT_INPUT} WHERE ${GIS_OPT_KEY}=${init_from_id};" -c --quiet | "${GREP}" "${init_from_id}" -c`
				if [ -z "${num_connections_from}" ] ; then
					num_connections_from=0
				fi
				# Get value of 'to_id' for this link:		
				init_to_id=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_TO_ID} FROM ${GIS_OPT_INITIAL} WHERE ${GRASS_PKEY}=${cat};" -c --quiet`
				check_error "Failed to retrieve value of field ('${LINKS_FLD_TO_ID}') from links input map ('${GRASS_PKEY}=${cat}')."
				# Check if 'to_id' occurs as primary key of any input node:
				num_connections_to=`db.select database="${attribute_database_nodes}" sql="SELECT ${GIS_OPT_KEY} FROM ${GIS_OPT_INPUT} WHERE ${GIS_OPT_KEY}=${init_to_id};" -c --quiet | "${GREP}" "${init_to_id}" -c`
				if [ -z "${num_connections_to}" ] ; then
					num_connections_to=0
				fi
				if [ -n $BASH_VERSION ] ; then
					let num_connections_total=${num_connections_from}+${num_connections_to}
				else
					num_connections_total=`"${EXPR}" ${num_connections_from} + ${num_connections_to}`
				fi
				if [ ${num_connections_total} -lt 2 ] ; then				
					exit_error "Initial link with primary key '${GRASS_PKEY}=${cat}' is not connected to two nodes in input map. Hint: Check extents of GRASS region (must completely contain links)."				
				fi
				if [ -n $BASH_VERSION ] ; then
					let i=${i}+1
				else
					i=`"${EXPR}" ${i} + 1`
				fi
				g.message -p "${i} ${max} 1"
			done
			IFS="${OLD_IFS}"	
			#
			# 2. Check that the same two nodes are not linked more than once in links map:
			#
			g.message -i "Checking connections of input nodes with input links (3/3):"
			get_grass_cats "${GIS_OPT_INITIAL}"
			i=0
			OLD_IFS="$IFS"
			IFS="${IFS_NEWLINE}"
			for cat in ${GRASS_CATS} ; do
				if [ -n $BASH_VERSION ] ; then
					let i=${i}+1
				else
					i=`"${EXPR}" ${i} + 1`
				fi
			done
			max=${i}
			i=0
			for cat in ${GRASS_CATS} ; do
				init_from_id=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_FROM_ID} FROM ${GIS_OPT_INITIAL} WHERE ${GRASS_PKEY}=${cat};" -c --quiet`
				check_error "Failed to retrieve value for field ('${LINKS_FLD_FROM_ID}') from links input map."
				init_to_id=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_TO_ID} FROM ${GIS_OPT_INITIAL} WHERE ${GRASS_PKEY}=${cat};" -c --quiet`		
				check_error "Failed to retrieve value for field ('${LINKS_FLD_TO_ID}') from links input map."
				# Check for occurrences of this from/to pair:
				num_init_pairs_ft=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_FROM_ID} FROM ${GIS_OPT_INITIAL} WHERE ${LINKS_FLD_FROM_ID}=${init_from_id} AND ${LINKS_FLD_TO_ID}=${init_to_id};" -c --quiet | "${GREP}" "${init_from_id}" -c`
				# Check for occurrences of this to/from pair:
				num_init_pairs_tf=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_FROM_ID} FROM ${GIS_OPT_INITIAL} WHERE ${LINKS_FLD_FROM_ID}=${init_to_id} AND ${LINKS_FLD_TO_ID}=${init_from_id};" -c --quiet | "${GREP}" "${init_from_id}" -c`
				if [ -n $BASH_VERSION ] ; then
					let num_init_pairs=${num_init_pairs_ft}+${num_init_pairs_tf}
				else
					num_init_pairs=`"${EXPR}" ${num_init_pairs_ft} + ${num_init_pairs_tf}`
				fi
				if [ $num_init_pairs -gt 1 ] ; then
					exit_error "At least one pair of nodes connected by more than one link in links map."
				fi
				g.message -p "${i} ${max} 1"
				if [ -n $BASH_VERSION ] ; then
					let i=${i}+1
				else
					i=`"${EXPR}" ${i} + 1`
				fi
			done # Checking map passed as "links="
			IFS="${OLD_IFS}"
		fi # Finished links:nodes consistency checks		
	fi # Finished all input data checks for option "initial="
	
	g.message -i "Input data has passed all validity checks."
}


# FUNCTION
# check_params:		Check parametrization for validity.
#					This is done before any data is produced.
#					So we can use g.message -e/exit here to abort without
#					triggering any clean-ups!
check_params () {
	# Options "where=" and "cats=" are mutually exclusive.
	if [ -n "${GIS_OPT_WHERE}" ] && [ -n "${GIS_OPT_CATS}" ] ; then
		g.message -e "Options 'where=' and 'cats=' are mutually exclusive."
		exit ${EXIT_ERROR}
	fi
	
	# Turn on cost-based mode if "cost" raster is provided 
	if [ -n "${GIS_OPT_COSTMAP}" ] ; then
		RUNMODE_COST="TRUE" # default if cost raster provided
	fi
		
	# Option "costsyn" is only meaningful if "costmap" is also provided.
	# Option "costsyn" cannot run in multi-threading mode.
	# Option "costsyn" cannot be combined with option "initial=".#
	grep_is_zero "${GIS_OPT_COSTSYN}"
	if [ -n "${GREP_VALUE}" ] ; then
		if [ -z "${GIS_OPT_COSTMAP}" ] ; then
			g.message -e "Option 'costsyn=' requires 'costmap=', which was not provided."
			exit ${EXIT_ERROR}
		fi
		if [ ${GIS_OPT_THREADS} -gt 1 ] ; then
			g.message -e "Option 'costsyn=' cannot run in multi-threading mode (set 'threads=1')."
			exit ${EXIT_ERROR}
		fi
		if [ -n "${GIS_OPT_INITIAL}" ] ; then
			g.message -e "Option 'costsyn=' cannot be combined with option ('initial=')."
			exit ${EXIT_ERROR}
		fi
	fi
	
	# Option "costerr" is only meaningful if "costmap" is also provided.
	grep_is_zero "${GIS_OPT_COSTERR}"
	if [ -n "${GREP_VALUE}" ] && [ -z "${GIS_OPT_COSTMAP}" ] ; then
		g.message -e "Option 'costerr=' requires 'costmap=', which was not provided."
		exit ${EXIT_ERROR}
	fi
	
	# Option "costres" is only meaningful if "costerr" is also provided.
	if [ ${GIS_OPT_COSTRES} -gt 1 ] && [ -z "${GREP_VALUE}" ] ; then		
		g.message -e "Option 'costres=' requires 'costerr=', which was not provided."
		exit ${EXIT_ERROR}
	fi
	
	# Option "costres" is only meaningful if "costmap" is also provided.
	if [ ${GIS_OPT_COSTRES} -gt 1 ] && [ -z "${GIS_OPT_COSTMAP}" ] ; then
		g.message -e "Option 'costres=' requires 'costmap=', which was not provided."
		exit ${EXIT_ERROR}
	fi
	
	# Option "costmem" is only meaningful if "costmap" is also provided.
	if [ ${GIS_OPT_COSTMEM} -gt 300 ] && [ -z "${GIS_OPT_COSTMAP}" ] ; then
		g.message -w "Option 'costmem=' is meaningless without 'costmap='. Ignored."		
	fi
	
	# Flag "-k" is only meaningful if "costmap" is also provided.
	if [ ${GIS_FLAG_K} -eq 1 ] && [ -z "${GIS_OPT_COSTMAP}" ] ; then
		g.message -e "Flag '-k(night's move)' is only useful if option 'costmap=' is also provided."
		exit ${EXIT_ERROR}
	fi
	
	# Flag "-m" is only meaningful if "costmap" is also provided.
	if [ ${GIS_FLAG_M} -eq 1 ] && [ -z "${GIS_OPT_COSTMAP}" ] ; then
		g.message -e "Flag '-m(eters)' is only useful if option 'costmap=' is also provided."
		exit ${EXIT_ERROR}
	fi
	
	# Flag "-l", together with options "maxdist="/"size=", is not meaningful for complete and unreduced models.
	if [ "${GIS_OPT_MODEL}" = "complete" ] ; then
		if [ -z "${GIS_OPT_MAXDIST}" ] ; then
			if [ ${GIS_FLAG_L} -eq 1 ] ; then
				g.message -e "Flag '-l(ink)' does not apply to model choice 'complete', unless 'maxdist=' is also provided."
				exit ${EXIT_ERROR}
			fi
		fi
	fi
	
	if [ ${GIS_OPT_SQLBUFLEN} -lt 1 ] ; then
		exit_error "SQL buffer size must be > 0 (option 'sqlbuflen=')."
	fi
	
	# Option "initial=" contradicts model choice "complete", unless "maxdist=" is also provided.
	if [ "${GIS_OPT_MODEL}" = "complete" ] ; then
		if [ -n "${GIS_OPT_INITIAL}" ] && [ -z "${GIS_OPT_MAXDIST}" ] ; then
			g.message -e "Option 'initial=' conflicts with model choice 'complete'."
			exit ${EXIT_ERROR}
		fi
	fi
	
		# Flag "-c" and options "maxdist=, size= and costmap=" are not meaningful for 'attsim' models.
	if [ "${GIS_OPT_MODEL}" = "attsim" ] ; then	
		if [ ${GIS_FLAG_L} -eq 1 ] ; then
			g.message -e "Flag '-l(ink)' does not apply to model choice 'attsim'."
			exit ${EXIT_ERROR}
		fi
		if [ -n "${GIS_OPT_MAXDIST}" ] ; then
			g.message -e "Option 'maxdist=' does not apply to model choice 'attsim'."
			exit ${EXIT_ERROR}
		fi
		if [ -n "${GIS_OPT_COSTMAP}" ] ; then
			g.message -e "Option 'costmap=' does not apply to model choice 'attsim'."
			exit ${EXIT_ERROR}
		fi
	fi	
	
	# Option "size=" applies only to XTENT and NN
	if [ -n "${GIS_OPT_SIZE}" ] ; then
		if [ "${GIS_OPT_MODEL}" != "xtent" ] && [ "${GIS_OPT_MODEL}" != "nn" ] ; then
			g.message -e "Option 'size=' applies only to model choices 'nn' and 'xtent'."
			exit ${EXIT_ERROR}
		else
			if [ -n "${GIS_OPT_NEIGHBORS}" ] && [ "${GIS_OPT_MODEL}" = "nn" ] ; then
				# "size=" conflicts with "neighbors="
				g.message -e "Model choice 'nn' requires either 'size=' or 'neighbors='."
				exit ${EXIT_ERROR}
			fi
		fi
	fi
	
	# Options A and K only apply to model XTENT
	if [ "${GIS_OPT_MODEL}" != "xtent" ] ; then		
		if [ -n "${GIS_OPT_A}" ] ; then
			g.message -e "Option 'a=' applies only to model choice 'xtent'."
			exit ${EXIT_ERROR}
		fi
		if [ -n "${GIS_OPT_K}" ] ; then
			g.message -e "Option 'k=' applies only to model choice 'xtent'."
			exit ${EXIT_ERROR}
		fi
	else
		# Options A and K must be provided for model choice XTENT		
		if [ -z "${GIS_OPT_A}" ] ; then
			g.message -e "Option 'a=' must be provided for model choice 'xtent'."
			exit ${EXIT_ERROR}
		fi
		if [ -z "${GIS_OPT_K}" ] ; then
			g.message -e "Option 'k=' must be provided for model choice 'xtent'."
			exit ${EXIT_ERROR}
		fi
	fi	
	
	# Option ATTRIBUTES only applies to model ATTSIM
	if [ "${GIS_OPT_MODEL}" != "attsim" ] ; then
		if [ -n "${GIS_OPT_ATTRIBUTES}" ] ; then
			g.message -e "Option 'attributes=' applies only to model choice 'attsim'."
			exit ${EXIT_ERROR}
		fi
	fi
	
	# Option NEIGHBORS only applies to model NN
	if [ "${GIS_OPT_MODEL}" != "nn" ] ; then
		if [ -n "${GIS_OPT_NEIGHBORS}" ] ; then
			g.message -e "Option 'neighbors=' applies only to model choice 'nn'."
			exit ${EXIT_ERROR}
		fi
	fi
	
	# If we got to here, then there is no inconsistency in the parametrization.
	# Now check individual model parameters for validity, depending on model choice!	
	
	# ATTRIBUTES
	if [ "${GIS_OPT_MODEL}" = "attsim" ] ; then
		# Option ATTRIBUTES must be provided for model choice ATTSIM
		if [ -z "${GIS_OPT_ATTRIBUTES}" ] ; then
			g.message -e "Option 'attributes=' must be provided for model choice 'attsim'."
			exit ${EXIT_ERROR}
		fi
	fi
	
	# NEIGHBORS
	if [ "${GIS_OPT_MODEL}" = "nn" ] ; then
		# nn: NEIGHBORS or SIZE must be provided
		if [ -z "${GIS_OPT_NEIGHBORS}" ] && [ -z "${GIS_OPT_SIZE}" ] ; then
			g.message -e "Either option 'neighbors=' or 'size=' must be provided for model choice 'nn'."
			exit ${EXIT_ERROR}
		fi
	fi
	if [ -n "${GIS_OPT_NEIGHBORS}" ] ; then						
		# if provided, then NEIGHBORS must be > 0.
		grep_is_positive ${GIS_OPT_NEIGHBORS}
		if [ -z "${GREP_VALUE}" ] ; then
			g.message -e "Option 'neighbors=' must be a positive number larger than '0'."
			exit ${EXIT_ERROR}
		fi
	fi
	
	# MAXDIST
	if [ -n "${GIS_OPT_MAXDIST}" ] ; then						
		# if provided, then MAXDIST must be > 0.
		grep_is_positive "${GIS_OPT_MAXDIST}"
		if [ -z "${GREP_VALUE}" ] ; then
			g.message -e "Option 'maxdist=' must be a positive number larger than '0'."
			exit ${EXIT_ERROR}
		fi
	fi
	
	# SIZE
	if [ "${GIS_OPT_MODEL}" = "xtent" ] ; then
		# Option "size=" must be provided for XTENT
		if [ -z "${GIS_OPT_SIZE}" ] ; then
			g.message -e "Option 'size=' must be provided for model choice 'xtent'."
			exit ${EXIT_ERROR}
		fi
	fi
		
	# K (XTENT)
	if [ "${GIS_OPT_MODEL}" = "xtent" ] ; then
		# Must be a positive number
		grep_is_positive ${GIS_OPT_K}
		if [ -z "${GREP_VALUE}" ] ; then
			g.message -e "Option 'k=' must be a positive number larger than '0'."
			exit ${EXIT_ERROR}
		fi
	fi
	
	# AVG (XTENT)
	if [ "${GIS_OPT_MODEL}" = "xtent" ] ; then
		# Default is 'mean'
		if [ -z "${GIS_OPT_AVG}" ] ; then
			GIS_OPT_AVG="mean"
		fi
	fi

}


# FUNCTION
# preprocess: Perform some input data manipulation before the actual network
#             reconstruction process starts.
#             ATTENTION:
#             All of these MUST have run successfully prior to preprocess():
#             - check_setup
#             - check_params
#             - check_input
#             - check_environment
#             ... because only then we can rely on ${GIS_OPT_INPUT} being a valid
#                 COPY of the original points input map!
#
preprocess () {
	# Drop fields with reserved names from copy of input points map (if necessary)
	fld=`v.info map="${GIS_OPT_INPUT}" layer="1" --quiet -c | "${GREP}" -w "${NODES_FLD_COORD_X}"`
	if [ -n "${fld}" ] ; then
		${V_DB_DROPCOLUMN} layer="1" map="${GIS_OPT_INPUT}" columns="${NODES_FLD_COORD_X}" --quiet
		check_error "Failed to remove reserved attribute '${NODES_FLD_COORD_X}' from copy of input points map."
	fi
	fld=`v.info map="${GIS_OPT_INPUT}" layer="1" --quiet -c | "${GREP}" -w "${NODES_FLD_COORD_Y}"`
	if [ -n "${fld}" ] ; then
		${V_DB_DROPCOLUMN} layer="1" map="${GIS_OPT_INPUT}" columns="${NODES_FLD_COORD_Y}" --quiet
		check_error "Failed to remove reserved attribute '${NODES_FLD_COORD_Y}' from copy of input points map."
	fi
	
	# Add coordinate fields to copy of input points map
	v.to.db map="${GIS_OPT_INPUT}" layer="1" option="coor" columns="${NODES_FLD_COORD_X},${NODES_FLD_COORD_Y}" --o --quiet
	check_error "Failed to add coordinate attribute fields to copy of input points map."
	
	# Increase resolution for sampling input cost surface?
	# NOTE: We already increased the resolution of the current region in "check_input()!"
	if [ ${GIS_OPT_COSTRES} -gt 1 ] ; then		
		# Create a new version of the original cost input raster, in which every
		# cell value is the original value divided by the resampling factor.
		# This is to ensure that the maximum costs of links do not grow when
		# using resampled cost rasters, which would be counter-intuitive!
		g.message -i "Resampling cost raster to $GIS_OPT_COSTRES times original resolution:"
		r.mapcalc expression="${TMP_RAST_COST_RSP}=( ${GIS_OPT_COSTMAP} / ${GIS_OPT_COSTRES} )" --overwrite
		# Swap original cost raster for resampled one:  
		GIS_OPT_COSTMAP="${TMP_RAST_COST_RSP}"
	fi
	
	# Add random error (noise) to cost surface?
	grep_is_zero "${GIS_OPT_COSTERR}"
	if [ -n "${GREP_VALUE}" ] ; then
		 # Create random surface in range [0;200]:
		 g.message -i "Creating random error/noise raster:"
		 r.surf.random output="${TMP_RAST_COST_ERR}" min="-${GIS_OPT_COSTERR}" max="+${GIS_OPT_COSTERR}" --overwrite
		 #r.random.surface output="${TMP_RAST_COST_ERR}" distance="0" high="200" --overwrite
		 check_error "Failed to create random error/noise raster (option 'costerr=')."
		 # Add error and compress to normalized range +/-100% with e.g. PERC=0.2 for a +/-20% error margin:
		 g.message -i "Normalizing random error/noise raster:"
		 #r.mapcalc expression="${TMP_RAST_COST_NRM}=( ${GIS_OPT_COSTMAP} * (1.0 + (100.0-${TMP_RAST_COST_ERR}) / (10000.0/${GIS_OPT_COSTERR})) )" --overwrite
		 r.mapcalc expression="${TMP_RAST_COST_NRM}=( ${GIS_OPT_COSTMAP} * ( 1.0 + (${TMP_RAST_COST_ERR} / 100.0 ) ) )" --overwrite
		 check_error "Failed to create normalized random error/noise raster (option 'costerr=')."
		 # Assign cost surface with error as new cost surface!
		 GIS_OPT_COSTMAP="${TMP_RAST_COST_NRM}"
	fi

	# Add cost synergy effect? Then we need two more temporary raster maps:
	# 1. A copy of the original cost map (we will overwrite this one with a new
	#    version for each LCP bundle later),
	# 2  and an initially empty map to iteratively rasterize LCP bundles with their
	#    cumulative cost effects.
	grep_is_zero "${GIS_OPT_COSTSYN}"
	if [ -n "${GREP_VALUE}" ] ; then
		# Create copy of original cost map and use that for input cost map from now on:
		g.message -i "Creating initial copy of cost map for cost synergy effect..."
		g.copy raster="${GIS_OPT_COSTMAP},${TMP_RAST_COST_SYN2}" --overwrite --quiet 2>/dev/null
		check_error "Failed to create copy of cost map (option 'costsyn=')."
		GIS_OPT_COSTMAP="${TMP_RAST_COST_SYN2}"
		# Initial LCP mask:
		g.message -i "Creating initial LCP mask for cost synergy effect..."
		r.mapcalc expression="${TMP_RAST_RSTLNKS1}=null()" --quiet --overwrite
		check_error "Failed to create initial LCP mask (option 'costsyn=')."
		# 
		# In addition: Save GRASS DB name of original cost map.
		# We need this to be able to refer back to the original, unmodified cell values
		# in r.mapcalc expression later:
		GIS_OPT_COSTMAP_ORG="${GIS_OPT_COSTMAP}"
	fi
	
	# Create default version of output nodes map by copying (filtered/sorted) input map
	g.copy vector="${GIS_OPT_INPUT},${GIS_OPT_NODES}" --overwrite --quiet 2>/dev/null
	check_error "Failed to copy input map to initial output nodes map '${GIS_OPT_NODES}'."
}


# FUNCTION
# model_attsim: Create a network where nodes are connected if they have common
#				attribute values.
#               In addition: Store an attribute "strength" in each similar link
#				that holds the number of similarities represented by the link.
model_attsim () {
	
	# Get and store attribute storage info for input and links maps:
	get_tbl_info "${GIS_OPT_INPUT}"
	attribute_database_driver_input="${attribute_database_driver}"
	attribute_database_input="${attribute_database}"
	attribute_table_input="${attribute_table}"
	get_tbl_info "${GIS_OPT_LINKS}"
	attribute_database_driver_links="${attribute_database_driver}"
	attribute_database_links="${attribute_database}"
	attribute_table_links="${attribute_table}"
	
	# Check_input() has already made sure that the fields listed in 'attributes=' all exist!
	g.message -i "Reducing network by connectivity model 'ATTSIM':"	
	# Add additional field 'strength' to output links map.
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_STRENGTH} INTEGER" --quiet
	check_error "Failed to add attribute field '${LINKS_FLD_STRENGTH}' (type 'INTEGER') to links output vector map."
	# Set strength to '0' for all links initially:
	${V_DB_UPDATE} map="${GIS_OPT_LINKS}" layer="1" column="${LINKS_FLD_STRENGTH}" value="0" --quiet
	check_error "Failed to initalize attribute field '${LINKS_FLD_STRENGTH}' to '0' for all links in output vector map."
	# Step through all (filtered) input nodes:
	get_primary_keys "${GIS_OPT_INPUT}"
	IFS_BACKUP="$IFS"
	IFS="${IFS_NEWLINE}"
	step=1 # This one is just for progress reporting.
	for key in $PRIMARY_KEYS ; do
		# Step through all attribute fields:
		OLD_IFS="$IFS"
		IFS=","
		for fld in ${GIS_OPT_ATTRIBUTES} ; do
			# Get field type
			fld_type="UNKNOWN"
			result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "TEXT|${fld}" -w -c`			
			if [ ${result} -eq 1 ] ; then
				fld_type="TEXT"
			else
				result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "CHARACTER|${fld}" -w -c`				
				if [ ${result} -eq 1 ] ; then
					fld_type="CHARACTER"
				else
					result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "INTEGER|${fld}" -w -c`					
					if [ ${result} -eq 1 ] ; then
						fld_type="INTEGER"
					else						
						result=`v.info -c --quiet map="${GIS_OPT_INPUT}" layer="1" | "${GREP}" "DOUBLE PRECISION|${fld}" -w -c`
						if [ ${result} -eq 1 ] ; then							
							fld_type="DOUBLE PRECISION"
						fi
					fi
				fi
			fi
			if [ "${fld_type}" = "UNKNOWN" ] ; then
				exit_error "Unable to determine type of field '${fld}' in input points layer (option 'attributes=')."
			fi
			# Build database query statement: Retrieve primary keys of all other nodes
			# that have the same value for the current field:
			get_where_clause "${key}"
			val=`db.select sql="SELECT ${fld} FROM ${attribute_table_input} WHERE ${WHERE};" driver="${attribute_database_driver_input}" database="${attribute_database_input}" -c --quiet`
			check_error "Failed to query attribute field '${fld}' for key='$key' in nodes input map."
			if [ "${fld_type}" = "CHARACTER" ] || [ "${fld_type}" = "TEXT" ] ; then
				where="${GIS_OPT_KEY}<>$key AND ${fld}='$val'"
			else
				where="${GIS_OPT_KEY}<>$key AND ${fld}=$val"
			fi
			# Get list of keys of nodes with identical attributes
			LIST=`db.select sql="SELECT ${GIS_OPT_KEY} FROM ${attribute_table_input} WHERE ${where};" driver="${attribute_database_driver_input}" database="${attribute_database_input}" -c --quiet`
			# Get info for connected database and table:
			if [ -n "${LIST}" ] ; then
				list=""
				IFS="${IFS_NEWLINE}"
				for item in ${LIST} ; do
					list="$list $item"
					# Get the one link with $item in field 'from_id' and our current primary key in 'to_id',
					# NOT the other way around (our links don't have directionality!). That way, we make sure
					# to only count every similarity once (from one end of the link).
					# Then update that link with the current link strength!
					where="${LINKS_FLD_FROM_ID}=$item AND ${LINKS_FLD_TO_ID}=$key"
					cat=`db.select sql="SELECT cat FROM ${attribute_table_links} WHERE ${where};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
					check_error "Failed to query attribute field '${LINKS_FLD_FROM_ID}' for link with cat='$cat' in links output vector map."					
					if [ -n "${cat}" ] ; then
						# Read strength of current link, increase by '1', update field:
						strength=`db.select sql="SELECT ${LINKS_FLD_STRENGTH} FROM ${attribute_table_links} WHERE cat = ${cat};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
						check_error "Failed to read from attribute field '${LINKS_FLD_STRENGTH}' of link with cat='$cat' in output vector map."
						if [ -n $BASH_VERSION ] ; then
							let strength=${strength}+1
						else
							strength=`"${EXPR}" ${strength} + 1`
						fi						
						SQL=""
						SQL="${SQL}UPDATE ${attribute_table_links} SET"
						SQL="${SQL} ${LINKS_FLD_STRENGTH} = ${strength}"
						SQL="${SQL} WHERE ${LINKS_FLD_KEY} = ${cat}; "
						"${ECHO}" "${SQL}" | db.execute database="${attribute_database_links}" input="-"
						check_error "Failed to update attribute field '${LINKS_FLD_STRENGTH}' to '${strength}' for link with cat='$cat' in output vector map."
					fi
				done
				IFS=","
			fi			
		done
		IFS="$OLD_IFS"
		g.message -p "${step} ${NUM_INPUT_NODES} 1"
		if [ -n $BASH_VERSION ] ; then
			let step=${step}+1
		else
			step=`"${EXPR}" ${step} + 1`
		fi
	done
	IFS="${IFS_BACKUP}"
	
	# PASS 2: Delete all links that have strength '0'!
	g.message -i "Removing disconnected links..."

	# Delete now!
	v.edit map="${GIS_OPT_LINKS}" layer="1" type="line" tool="delete" where="${LINKS_FLD_STRENGTH}<1" --quiet
	check_error "Failed to delete link geometries during NN reduction."
	# Drop associated rows of attribute table from links map:
	SQL="${DBMS_BEGIN}"
	SQL="$SQL
DELETE FROM $attribute_table WHERE ${LINKS_FLD_STRENGTH} < 1;"
	SQL="$SQL
${DBMS_COMMIT}"
	echo "${SQL}" | db.execute database="${attribute_database}" input="-"
	check_error "Failed to delete link attribute rows during NN reduction."

}


# FUNCTION
# mutex_acquire: Uses mkdir to create a mutex lock in the
# filesystem (default GRASS temp directory) that prevents race conditions
# on shared resources when running operations in multiple threads.
# Uses GRASS' TMPDIR environment variable to store the mutex dir.
# 
# Mkdir is suitable for creating a mutex, because (from the point of view
# of a shell scipt) it is atomic: A directory can be checked and created
# in one indivisible operation.
#
# Arguments:
#
#	$1 = miss sleep time in seconds (default: 0.01s)
#		 This sets the time that the main loop of this function
#		 spends idling before reattempting to acqurie the mutex lock.
#		 The default is very short, which is only suitable for locks
#		 that will be set and released rapidly (i.e. no code should
#		 spend much time holding the lock). If the time that any
#		 code segment spends holding the lock regularly exceeds the
#		 default, then $1 should be set higher to avoid excessive
#		 overhead by the 'sleep' command!
#
#	$2 = mutex name (default: v_net_models_<process PID>.lock)
#		 Setting $2 (in addition to $1) allows to create a 'named mutex'.
#        This should only be done if the mutex needs to be created
#		 with an individual name (e.g. by a nested function that
#		 has some need to create its own mutex). Note that in the
#		 latter case, mutex_release() must also be called with the
#		 same name.
#
# Adapted from: https://www.ewan.cc/?q=node/85
mutex_acquire() {
	
	if [ ${GIS_OPT_THREADS} -eq 1 ] ; then
		# If we are not running in multi-threading mode, then we return
		# immediately: No need to handle all of the below!
		return
	fi
	
	if [ "$1" = "" ] ; then
		sleeptime="0.01"
	else
		sleeptime="$1"
	fi
	if [ "$2" = "" ] ; then
		lock="v_net_models_lock"
	else
		lock="v_net_models_$2_lock"
	fi
	locked="false"
	# This will loop until the mutex was successfully created/acquired:
	while [ ${locked} = "false" ] ; do
		# Attempt to create mutex lock (=temp directory):
		mkdir "${TMPDIR}/${lock}" 2>/dev/null
		rc=$?
		if [ ${rc} -ne 0 ] ; then
			# mutex could not be acquired: volatile code segment must wait
			if [ -n "${SLEEP}" ] ; then
				${SLEEP} "${sleeptime}"
			fi
		else
			# mutex lock acquired: exit loop and allow execution of
			# volatile code segment.
			locked="true"
			# DEBUG
			#echo "MUTEX DIR CREATE: '${TMPDIR}/${lock}'"
		fi
	done
}


# FUNCTION
# mutex_release: Releases a mutex lock in the filesystem (default GRASS temp directory).
#
# Arguments:
#	
#	$1 = mutex name
#		 This must only be set if a 'named mutex' was created.
#		 See 'mutex_acquire()' for information.
#
mutex_release() {
	
	if [ ${GIS_OPT_THREADS} -eq 1 ] ; then
		# If we are not running in multi-threading mode, then we return
		# immediately: No need to handle all of the below!
		return
	fi

	if [ "$1" = "" ] ; then
		lock="v_net_models_lock"
	else
		lock="v_net_models_$1_lock"
	fi
	rmdir "${TMPDIR}/${lock}"
	# Not being able to release the mutex indicates a fatal flaw
	# in the multi-threaded processing and leads to program abortion!
	check_error "Failed to release mutex lock '${lock}'."

	# DEBUG
	#echo "MUTEX DIR DELETE: '${TMPDIR}/${lock}'"
}


# FUNCTION
# mutex_acquire_seq: Attempts to acquire the globally synchronised mutex
# lock (used only by model_complete_thread) in strict sequence.
#
# This function is _only_ used by 'model_complete_thread()'.
# It manages a very specific type of mutex that can only be acquired
# by a thread in a strict sequence. The purpose of this is to make
# absolutely sure that the all threads perform the very first operation
# on a data structure (the input points map from which one focal node
# after another is extracted into a local temporary map) in strict
# order of launching the background threads. This is necessary, because
# the individual focal networks created by each thread must be in a
# specific order for the attribute transfer in 'model_complete()' (which
# dispatches the individual worker threads) to work correctly.
#
# The only argument to this function is:
#
# 	$1 - sequence number of thread that wishes to acquire the mutex lock
#
# The mutex lock will be granted if the temp dir for thread $1 exists and
# could be removed successfully.
#
# This entire mechanism can only work if the first thread requests the lock
# for '$1=0', and if all consecute threads request the lock for a strictly
# incrementing (by 1) sequence value.
#
# Anything else would lead to a DEADLOCK.
#
mutex_acquire_seq() {
	# DEBUG
	# echo "MUTEX SEQ REQ: '$1'"
	
	if [ ${GIS_OPT_THREADS} -eq 1 ] ; then
		# If we are not running in multi-threading mode, then we return
		# immediately: No need to handle all of the below!
		return
	fi
	
	lock="v_net_models_lock_seq_$1"
	
	locked="false"
	# This will loop until the mutex was successfully created/acquired:
	while [ ${locked} = "false" ] ; do
		# Removing the temp dir for the requesting thread's unique ID
		# represents acquisition of mutex lock:
		rmdir "${TMPDIR}/${lock}" 2>/dev/null
		rc=$?
		if [ ${rc} -ne 0 ] ; then
			# mutex could not be acquired: volatile code segment must wait
			if [ -n "${SLEEP}" ] ; then
				${SLEEP} "0.01"
			fi
		else
			# mutex lock acquired: exit loop and allow execution of
			# volatile code segment.
			locked="true"
			# DEBUG
			# echo "MUTEX ACQ: '${TMPDIR}/${lock}'"
		fi
	done
}


# FUNCTION
# mutex_release_seq: Releases the globally synchronised mutex lock,
# used exclusively by 'model_complete_thread()'.
# See description of 'mutex_acquire_seq()' for details.
#
# This function takes only one argument:
#
#	$1: ID of next thread that will be allowed to acquire the lock.
#
mutex_release_seq() {
	
	if [ ${GIS_OPT_THREADS} -eq 1 ] ; then
		# If we are not running in multi-threading mode, then we return
		# immediately: No need to handle all of the below!
		return
	fi
	
	# Releasing the mutex is done by creating a temp dir with a name that contains
	# the ID of the next thread in the sequence (prefixed by a constant string).
	lock="v_net_models_lock_seq_$1"
	mkdir "${TMPDIR}/${lock}" 2>/dev/null
	rc=$?
	if [ ${rc} -ne 0 ] ; then
		check_error "Unable to relase mutex lock for thread #$1."
	fi
	# DEBUG
	# echo "MUTEX SEQ REL: '$1'"
}


# FUNCTION
# model_complete_thread: This is the code that does the heavy lifting
# processing work for model_complete(). It has been moved into a separate
# function to make it suitable for multi-threaded processing.
#
# This function is called _only_ from within the main loop of model_complete(),
# where the latter steps through all points of the input to extract the
# sub networks.
#
# Arguments:
# 	$1 - thread ID (a unique integer 0..n): Only used for debugging purposes
#   $2 - Goal contribution: pass 0 (int) to prevent this thread from
#	     updating the global progress counter. Any integer value > 0
#		 to make the thread update the global progress counter.
#	$3 - the primary key of the current input feature (network node/point)
#        to be processed by this thread
#	$4 - globally unique job ID: an integer value provided by the caller:
#		 Used to create unique resource handles (mutexes, temporary maps)
#	$5 - next primary key value (cat) for network links (provided by caller):
#        Used for upload of cost attribute values to LCP network links.
#   $6 - total number of threads/jobs run by caller (for accurate progress update)
#	$7 - PID of caller process (required to kill entire script on fatal error)
#
model_complete_thread () {
	id=$1
	goal=$2
	key=$3
	step=$4
	cat_next=$5
	num_jobs=$6
	global_pid=$7
	
	#DEBUG
	#echo "THREAD $id LAUNCHED (goal=$goal) (key=$key) (step=$step) (cat_next=$cat_next) (num_jobs=$num_jobs) (global_pid=$global_pid)"

	#DEBUG Test script termination from within thread
	#if [ $step -eq 5 ] ; then
	#	exit_error "STOP!" $global_pid
	#fi
	
	# MUTEX ON
	#mutex_acquire "0.1" "${global_pid}_g_copy_input"
	mutex_acquire_seq ${step}
	next_step=`"${EXPR}" ${step} + 1`
		
	# MUTEX ON
	#mutex_acquire "0.1" "${global_pid}_where"
	# Form SQL WHERE clause to get next primary key value.
	get_where_clause "${key}"
	local_where="${WHERE}"
	# MUTEX OFF
	#mutex_release "${global_pid}_where"	
	
	# Create a local copy of nodes input map:
	if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
		# Switch to thread-local DB driver and database:
		mutex_acquire "0.1" "${global_pid}_db_switch"
		grass_db_connect_local "${GIS_OPT_INPUT}_${step}.db"
	fi	
	g.copy vector="${GIS_OPT_INPUT},${GIS_OPT_INPUT}_${step}" --overwrite --quiet 2>/dev/null
	check_error "Failed to copy input nodes map '${GIS_OPT_INPUT}' to '${GIS_OPT_INPUT}_${step}' for thread safety." ${global_pid}
	if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
		mutex_release "${global_pid}_db_switch"
	fi

	# MUTEX ON
	#mutex_acquire "0.1" "${global_pid}_v_edit"
	# Delete extracted node from ORIGINAL (global!) nodes input map(!):
	if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
		# Switch to default (global) DB driver and database:
		mutex_acquire "0.1" "${global_pid}_db_switch"
		grass_db_connect_default
	fi
	#check_error "Failed to set default DB connection in background job/thread #${step} (after creating local map)."
	v.edit map="${GIS_OPT_INPUT}" layer="1" type="point" tool="delete" where="${local_where}" --overwrite --quiet
	check_error "Failed to delete point with primary key value '${key}' from copy of input vector map." ${global_pid}
	# MUTEX OFF
	#mutex_release "${global_pid}_v_edit"
	if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
		mutex_release "${global_pid}_db_switch"
	fi
	
	# TODO: Does this really have to be done within this scope/mutex?
	# MUTEX ON
	#mutex_acquire "0.1" "${global_pid}_v_db_update"
	# By setting the primary key of this feature to our 'no data' value, we mark the corresponding
	# attribute table record as *deleted*:								
	# HINT: We use V_DB_UPDATE here (not db.execute), since it will make sure to refresh the database
	#       connection with $GIS_OPT_INPUT (we manipulate that map!) each run through the loop.		
	${V_DB_UPDATE} map="${GIS_OPT_INPUT}" layer="1" column="${GIS_OPT_KEY}" value="${no_data}" where="${local_where}" --overwrite --quiet
	check_error "Failed to set primary key value '${key}' in copy of input vector map to 'no data' ('$no_data')." ${global_pid}
	# MUTEX OFF
	#mutex_release "${global_pid}_v_db_update"
	
	# MUTEX OFF
	#mutex_release "${global_pid}_g_copy_input"	
	mutex_release_seq ${next_step}
	
	# MUTEX ON
	mutex_acquire "0.1" "${global_pid}_v_db_select"	
	# Retrieve GRASS primary key ('cat') value:
	if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
		# Switch to thread-local DB driver and database:
		mutex_acquire "0.1" "${global_pid}_db_switch"
		grass_db_connect_local "${GIS_OPT_INPUT}_${step}.db"
	fi
	# Do selection:
	val=`v.db.select map="${GIS_OPT_INPUT}_${step}" column="${GIS_OPT_KEY}" where="${local_where}" -c`
	check_error "Failed to query attribute table of copy of input points map." ${global_pid}
	if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
		mutex_release "${global_pid}_db_switch"
	fi
	# MUTEX OFF	
	mutex_release "${global_pid}_v_db_select"
	
	if [ -n "${val}" ] ; then # Feature exists! Process it:
		# We extract each node in turn to a new map. Then we connect all other
		# nodes (that remain in the original map) to the extracted node. The
		# result is a new (lines) map with the a non-redundant subnetwork.
		#
		# Set name of temporary links output map for current pass through the main loop:
		tmp_vect_links="${TMP_VECT_LINKS_PATCH}_${step}"
		## MUTEX ON
		#mutex_acquire "0.1" "${global_pid}_v_extract"
		# Extract current node to new local (to this thread) temporary map:
		if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
			# Switch to thread-local DB driver and database:
			mutex_acquire "0.1" "${global_pid}_db_switch"
			grass_db_connect_local "${GIS_OPT_INPUT}_${step}.db"
		fi
		# Do extraction:
		v.extract input="${GIS_OPT_INPUT}_${step}" layer="1" type="point" where="${local_where}" output="${TMP_VECT_EXTRACT}_${step}" --overwrite --quiet						
		check_error "Failed to extract point with primary key value '${key}' from copy of input vector map." ${global_pid}
		# Delete extracted node from thread-local version of input map:
		v.edit map="${GIS_OPT_INPUT}_${step}" layer="1" type="point" tool="delete" where="${local_where}" --overwrite --quiet		
		check_error "Failed to delete point with primary key value '${key}' from thread-local copy of input vector map." ${global_pid}
		## MUTEX OFF
		if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
			mutex_release "${global_pid}_db_switch"
		fi
		#mutex_release "${global_pid}_v_extract"		
		
		# DEBUG
		#mutex_acquire "0.1" "${global_pid}_v_ops"
		
		# Connect extracted node with all remaining nodes in old map.			
		#
		# COST map provided? Then we must now change the shapes of the links to least-cost paths!
		if [ -n "${GIS_OPT_COSTMAP}" ] ; then
			# Compute least cost surface from current node to all other nodes:
			if [ ${GIS_FLAG_K} -eq 1 ] ; then
			    # Use 'knight's move' (more accurate but slower)
				r.cost -k -n input="${GIS_OPT_COSTMAP}" start_points="${TMP_VECT_EXTRACT}_${step}" stop_points="${GIS_OPT_INPUT}_${step}" memory="${GIS_OPT_COSTMEM}" output="${TMP_RAST_COST_MIN}_${step}" outdir="${TMP_RAST_COST_DIR}_${step}" --o --quiet
			else
				# Use simple diagonal moves (less accurate but faster, default if '-k' is not given
				r.cost -n input="${GIS_OPT_COSTMAP}" start_points="${TMP_VECT_EXTRACT}_${step}" stop_points="${GIS_OPT_INPUT}_${step}" memory="${GIS_OPT_COSTMEM}" output="${TMP_RAST_COST_MIN}_${step}" outdir="${TMP_RAST_COST_DIR}_${step}" --o --quiet
			fi
			check_error "Failed to compute cost and direction surfaces (iteration ${step})." ${global_pid}
			## MUTEX ON
			if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
				mutex_acquire "0.1" "${global_pid}_db_switch"
				# Switch to thread-local DB driver and database:			
				grass_db_connect_local "${GIS_OPT_INPUT}_${step}.db"
			fi
			# We now store the costs for each path on the current cost raster (we will need this later).
			from_id="${key}"
			TO_IDS=`v.db.select map="${GIS_OPT_INPUT}_${step}" columns="${GIS_OPT_KEY}" where="${GIS_OPT_KEY} != ${key}" -c --quiet`
			check_error "Failed to retrieve primary keys from temporary vector map for storing link costs." ${global_pid}
			# Get DBMS connection info for temp links map:
			get_tbl_info "${TMP_VECT_LINKS_COSTS}"
			# Get all least-cost values for all "to nodes" from current cost surface:
			COSTVAL=`r.what map="${TMP_RAST_COST_MIN}_${step}" points="${GIS_OPT_INPUT}_${step}" separator="|"`
			check_error "Failed to query temporary cost raster using map of 'to' nodes." ${global_pid}
			# First cat in attribute table is provided by calling function!
			cat_cost=$cat_next
			# Index of first cost value starts at '1' for each thread!
			IFS_BACKUP="$IFS"
			IFS="${IFS_NEWLINE}"
			next_cost=1	
			for to_id in $TO_IDS ; do
				# Initialize contents of first SQL_CHUNK to 'empty':
				SQL_CHUNK="${DBMS_BEGIN}"
				if [ "$to_id" != "$no_data" ] ; then
					SQL=""
					SQL="${SQL}UPDATE ${attribute_table} SET"
					SQL="${SQL} ${LINKS_FLD_FROM_ID} = ${key}"
					SQL="${SQL}, ${LINKS_FLD_TO_ID} = ${to_id}"
					SQL="${SQL} WHERE cat = ${cat_cost}; "
					SQL_CHUNK="${SQL_CHUNK}
${SQL}"
					#"${ECHO}" "${SQL}" | db.execute database="${attribute_database}" input="-"
					#check_error "Failed to update field '${LINKS_FLD_FROM_ID} or ${LINKS_FLD_TO_ID}' in temporary link costs vector map." ${global_pid}
					# Transfer matching cost value
					cur=1
					for cost in $COSTVAL ; do
						if [ $cur -eq $next_cost ] ; then 
							costval=`"${ECHO}" $cost | "${AWK}" -F "|" '{ print $4 }'`
							SQL=""
							SQL="${SQL}UPDATE ${attribute_table} SET"
							SQL="${SQL} ${LINKS_FLD_COST} = ${costval}"
							SQL="${SQL} WHERE ${LINKS_FLD_KEY} = ${cat_cost}; "
							SQL_CHUNK="${SQL_CHUNK}
${SQL}"
							#"${ECHO}" "${SQL}" | db.execute database="${attribute_database}" input="-"
							#check_error "Failed to update field '${LINKS_FLD_COST}' in temporary link costs vector map." ${global_pid}
						fi
						if [ -n $BASH_VERSION ] ; then
							let cur=${cur}+1
						else
							cur=`"${EXPR}" ${cur} + 1`
						fi
					done
					# Commit transaction of SQL chunk:
					SQL_CHUNK="${SQL_CHUNK}
${DBMS_COMMIT}"
					"${ECHO}" "${SQL_CHUNK}" | db.execute database="${attribute_database}" input="-"
					check_error "Failed to update field '${LINKS_FLD_FROM_ID} or ${LINKS_FLD_TO_ID}' in temporary link costs vector map." ${global_pid}
					# Empty chunk contents:
					SQL_CHUNK="${DBMS_BEGIN}"
					if [ -n $BASH_VERSION ] ; then
						let next_cost=${next_cost}+1
					else
						next_cost=`"${EXPR}" ${next_cost} + 1`
					fi
					# Set next primary key value for subsequent upload of cost value					
					if [ -n $BASH_VERSION ] ; then
						let cat_cost=${cat_cost}+1
					else
						cat_cost=`"${EXPR}" ${cat_cost} + 1`
					fi
				fi
			done			
			IFS="${IFS_BACKUP}"
						
			# Compute least cost vector paths based on directional surface computed above
			# (end points now become start points, as r.cost has produced back-links!):
			r.path input="${TMP_RAST_COST_DIR}_${step}" format="degree" vector_path="${tmp_vect_links}" start_points="${GIS_OPT_INPUT}_${step}" --overwrite --quiet
			check_error "Failed to compute least cost paths (iteration ${step})." ${global_pid}

			# Check whether we need to apply an iterative cost synergy effect (option 'costsyn='.
			# THIS WILL ONLY WORK IN SINGLE-THREADED MODE, since the costs computed in the current step inevitably
			# depends on the cost computations in the previous step
			grep_is_zero "${GIS_OPT_COSTSYN}"
			if [ -n "${GREP_VALUE}" ] ; then			
				# Ok: 'costsyn' has been set > 0.
				# 0. Initialize TMP_RAST_RSTLNKS1 (global LCP mask) to all null cells: Was done previously, as part of function preprocess()
				# 1. Rasterize path bundle into temporary raster map TMP_RAST_RSTLNKS2, with every cell on a path set to 'costsyn', all other cells 'null':
				v.to.rast input="${tmp_vect_links}" output="${TMP_RAST_RSTLNKS2}" type="line" use="val" value="${GIS_OPT_COSTSYN}" --quiet --overwrite
				check_error "Failed to rasterize least cost path(s) during step #${step}."
				# 2. Add TMP_RAST_RSTLNKS2 to global LCP mask TMP_RAST_RSTLNKS1:
				r.mapcalc expression="${TMP_RAST_RSTLNKS1}=(if(!isnull(${TMP_RAST_RSTLNKS2}),${TMP_RAST_RSTLNKS2},${TMP_RAST_RSTLNKS1}))" --quiet --overwrite
				check_error "Failed to add least cost path(s) to global LCP mask during step #${step}."				
				# 3. Set all non-null cells of TMP_RAST_RSTLNKS1 to cost effect in TMP_RAST_COST_SYN, set to unmodified cost surface value, otherwise:
				r.mapcalc expression="${TMP_RAST_COST_SYN}=(if(!isnull(${TMP_RAST_RSTLNKS1}),${GIS_OPT_COSTMAP_ORG}*(1-${TMP_RAST_RSTLNKS1}),${GIS_OPT_COSTMAP_ORG}))" --quiet --overwrite
				check_error "Failed to create modified cost surface (cost synergy factor) during step #${step}."
				# 4. Set TMP_RAST_COST_SYN to be our new GIS_OPT_COSTMAP:
				g.copy raster="${TMP_RAST_COST_SYN},${GIS_OPT_COSTMAP}" --overwrite --quiet 2>/dev/null				
			fi

			# We cannot release the DB mutex sooner, because up to this point, we have been writing
			# new tables into the shared mapset database!
			if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
				mutex_release "${global_pid}_db_switch"
			fi
			## MUTEX OFF
			
			# At this point, we already remove the temporary raster surfaces to release storage space:	
			## MUTEX ON		
			mutex_acquire "0.1" "${global_pid}_g_remove" 
			g.remove type="raster" name="${TMP_RAST_COST_MIN}_${step}" -f --quiet
			g.remove type="raster" name="${TMP_RAST_COST_DIR}_${step}" -f --quiet
			mutex_release "${global_pid}_g_remove"
			## MUTEX OFF
		else
			# We are running in straight-line links (Euclidean) mode: Create link as a new straight-line
			# connection, using 'v.distance output='.
			# NOTE: Since GRASS 8, 'upload=' is a mandatory option. So it is used here to upload the
			# distance to the nearest feature into a dummy (temporary) attribute field, even though
			# this is not a necessary operation in our context.
			
			# DEBUG
			#mutex_release "${global_pid}_v_ops"
			
			# MUTEX ON
			#mutex_acquire "0.1" "${global_pid}_v_distance"
			if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
				# Switch to thread-local DB driver and database:
				mutex_acquire "0.1" "${global_pid}_db_switch"
				grass_db_connect_local "${GIS_OPT_INPUT}_${step}.db"
			fi
			# Create distance lines maps:
			v.distance from="${GIS_OPT_INPUT}_${step}" from_layer="1" from_type="point" to="${TMP_VECT_EXTRACT}_${step}" to_layer="1" to_type="point" upload="dist" column="${TMP_FLD_DIST}" output="${tmp_vect_links}" --overwrite --quiet
			check_error "Failed to connect point with primary key value '${key}' to all other points of input vector map." ${global_pid}
			# MUTEX OFF
			if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
				mutex_release "${global_pid}_db_switch"
				#mutex_release "${global_pid}_v_distance"
			fi
		fi
		
		# Clean up! Remove local temporary maps, still within this thread's scope.
		mutex_acquire "0.1" "${global_pid}_g_remove" 
		if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
			# Switch to thread-local DB driver and database:
			mutex_acquire "0.1" "${global_pid}_db_switch"
			grass_db_connect_local "${GIS_OPT_INPUT}_${step}.db"
		fi
		# Remove temporary maps:		
		g.remove type="vector" name="${TMP_VECT_EXTRACT}_${step}" -f --quiet		
		g.remove type="vector" name="${GIS_OPT_INPUT}_${step}" -f --quiet		
		if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
			# Switch back to default (global) DB driver and database:
			grass_db_connect_default
		fi
		#check_error "Failed to set default DB connection in background job/thread #${step} (at end of processing)."
		if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
			# Remove thread-local database file:
			rm "$GISDBASE/$LOCATION_NAME/$MAPSET/sqlite/${GIS_OPT_INPUT}_${step}.db"
			check_warn "Failed to delete temporary database file '$GISDBASE/$LOCATION_NAME/$MAPSET/sqlite/${GIS_OPT_INPUT}_${step}.db'. Please remove manually."
		fi
		if [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then
			mutex_release "${global_pid}_db_switch"
		fi
		mutex_release "${global_pid}_g_remove"
		
	else
		# No feature to extract! This is a fatal error!		
		exit_error "Input data missing for primary key query '${local_where}'. Aborting."
	fi
	
	#DEBUG
	#echo "THREAD $id COMPLETED"

	return 0
}


# FUNCTION
# model_complete: Create a network where every node is connected to every other node.
# NOTE that this model is the ONLY one that reads cost raster values from "${GIS_OPT_COSTMAP}" directly!
# All other models MUST rely on RUNMODE_COST ["TRUE"|"FALSE"] and read link costs from
# the associated 'cost' attribute field!
model_complete () {
	
	# DEBUG
	#MARK=`date`
	#echo "0 MODEL COMPLETE START: '$MARK'"
	
	# CACHING:
	# If we are running in cost-based mode, then we need a temporary storage
	# to store the link costs after each run of r.cost. Since GRASS has insufficient
	# support for creating tables without attached features, we just (mis)use v.random
	# to create a new points vector map, and we use its attribute table to store the
	# cost data.
	if [ -n "${GIS_OPT_COSTMAP}" ] ; then	
		# We use v.random to create as many features with attached attributes as
		# we need (=number of links in complete network). We use the "column=" option to attach
		# an attribute table at the same time. Normally, this is used for random
		# Z values, but we will simply overwrite it with cost values later.
		num_links=`"${EXPR}" ${NUM_INPUT_NODES} \* \( ${NUM_INPUT_NODES} - 1 \) / 2`
		v.random output="${TMP_VECT_LINKS_COSTS}" column="${LINKS_FLD_COST}" npoints="${num_links}" --quiet --overwrite
		check_error "Failed to create temporary vector map for storing link costs."
		# Now we need to create attributes of the correct type for storing "from_id" and "to_id" fields
		${V_DB_ADDCOLUMN} map="${TMP_VECT_LINKS_COSTS}" layer="1" columns="${LINKS_FLD_FROM_ID} INTEGER" --quiet
		check_error "Failed to add attribute field '${LINKS_FLD_FROM_ID}' (type 'integer') to temporary vector map for storing link costs."
		${V_DB_ADDCOLUMN} map="${TMP_VECT_LINKS_COSTS}" layer="1" columns="${LINKS_FLD_TO_ID} INTEGER" --quiet
		check_error "Failed to add attribute field '${LINKS_FLD_TO_ID}' (type 'integer') to temporary vector map for storing link costs."
		# Set primary key (GRASS default 'cat' column) value for first upload of cost value.
		cat_cost=1
	else
		# Straight-line (Euclidean) links: Add a temporary field for 'distance to nearest feature'.
		# This is only required because 'v.distance' has a mandatory 'upload=' option since GRASS 8.
		${V_DB_ADDCOLUMN} map="${GIS_OPT_INPUT}" layer="1" columns="${TMP_FLD_DIST} double precision" --quiet
		check_error "Failed to add temporary attribute field '${TMP_FLD_DIST}' (type 'double precision') to copy of input map."
	fi	
	
	#############
	# MAIN LOOP #
	#############	
	
	# This loop steps through all input nodes EXCEPT THE LAST ONE(!).
	# The reason for this is that the last node will already be part
	# of the fully connected network when the loop reaches its index.
	get_primary_keys "${GIS_OPT_INPUT}"

	# Get info for database and table connected to points input map:
	get_tbl_info "${GIS_OPT_INPUT}"	

	# Initialize 'no data' representation for primary keys as empty string.
	no_data=
	# Make sure that we have a valid 'no data' encoding:
	IFS_BACKUP="$IFS"
	IFS="${IFS_NEWLINE}"
	for key in $PRIMARY_KEYS ; do
		if [ -z "${no_data}" ] ; then
			# 'no data' has not yet been set: We do so now.
			# The trick here is to simply use the first primary key value that we
			# encounter through this loop: Since this also happens to be the primary
			# key of the first node that we extract from the set of input nodes,
			# we can safely use this value to mark all remaining (non-extracted) records
			# as 'no data'.
			no_data="${key}"
			break
		fi
	done
	IFS="${IFS_BACKUP}"
	
	# PATCH_LIST: This list is where we keep the names of the temporary vector maps
	# with subnetworks that we patch together in one go, after the main loop has completed:
	PATCH_LIST=
	
	# Process all features except for the last one!
	num_features=`"${EXPR}" ${NUM_INPUT_NODES} - 1`
	
	# SQLite backend only: Force into per-map table storage mode now!
	if [ "${DBMS_NAME}" = "SQLite" ] && [ ${GIS_OPT_THREADS} -gt 1 ] && [ ${DBMS_LOCKS_REQUIRED} -eq 1 ] ; then		
		g.message -i "Switching to per-map table storage for backend '${DBMS_NAME}'."
		db.connect driver=sqlite database='$GISDBASE/$LOCATION_NAME/$MAPSET/vector/$MAP/sqlite.db'
		DBMS_LOCKS_REQUIRED_OLD=${DBMS_LOCKS_REQUIRED}
		DBMS_LOCKS_REQUIRED=0
	fi		
	
	# Main processing loop starts here:
	g.message -i "Creating network using connectivity model 'COMPLETE':"
	
	# Program execution diverges here, depending on whether we are running in single
	# or multi thread mode!
	if [ ${GIS_OPT_THREADS} = 1 ] ; then
		# SIMPLE CASE: We are running just one (foreground) thread to do the processing!
		num_jobs=${num_features}
		tid=0 # thread ID within current dispatch
		job=0; # global counter for runs through the loop [0..num input points]
		cat_next=1; # TODO
		for key in $PRIMARY_KEYS ; do
			if [ $job -lt $num_features ] ; then				
				#DEBUG
				#echo "SIM THREAD ${tid} LAUNCHED (goal=1) (key=$key) (step=$job) (cat_next=$cat_next) (num_jobs=$num_jobs) (global_pid=$$)"
				# Run processing task in foreground, passing it the primary key:
				model_complete_thread ${tid} 1 ${key} ${job} ${cat_next} ${num_jobs} $$
				cat_next=`"${EXPR}" ${cat_next} + \( $num_features - $job \)`
				# Add output of 'model_complete_thread' to list of link maps for delayed patching:
				PATCH_LIST="${PATCH_LIST}
${TMP_VECT_LINKS_PATCH}_${job}
"
				# Count up to next job ID:
				job=`"${EXPR}" ${job} + 1`
				# Update progress display:
				g.message -p "${job} ${num_features} 1"
			fi
		done
	else
		# TRICKY CASE: We are running processing jobs in parallel!	
		# Calculate feature processing intervals sizes (=dispatchers), based on number of
		# processing threads (option 'threads='). The list of DISPATCHES will be used
		# to control the outermost processing loop of this function.	
		if [ ${GIS_OPT_THREADS} -gt ${num_features} ] ; then
			# We have more (requested) threads than features: adjust!
			GIS_OPT_THREADS=${num_features}
		fi
		num_dispatches=`"${EXPR}" ${num_features} / ${GIS_OPT_THREADS}`	
		remainder=`"${EXPR}" ${num_features} % ${GIS_OPT_THREADS}`
		DISPATCHES=""
		cur=0
		while [ ${cur} -lt ${num_dispatches} ] ; do
			DISPATCHES="${DISPATCHES}
${GIS_OPT_THREADS}
"
			cur=`"${EXPR}" ${cur} + 1`
		done
		if [ ${remainder} -gt 0 ] ; then
			DISPATCHES="${DISPATCHES}
${remainder}
"
			num_dispatches=`"${EXPR}" ${num_dispatches} + 1`
		fi
		#
		# Calculate number of processing jobs to run in total:
		if [ ${remainder} -gt 0 ] ; then
			num_jobs=`"${EXPR}" \( ${num_dispatches} - 1 \) \* ${GIS_OPT_THREADS} + ${remainder}`
		else
			num_jobs=`"${EXPR}" ${num_dispatches} \* ${GIS_OPT_THREADS}`
		fi
		#
		# Step through all points in input map.
		# The actual processing work is done in a separate thread by model_complete_thread.
		# The list $DISPATCHES contains the number of processing jobs to be dispatched
		# in every run through the loop. For all but the last run, this will be the same
		# as $GIS_OPT_THREADS. Only the last job might happen to be smaller than $GIS_OPT_THREADS.
		mutex_release_seq 0 # Open global mutex lock for first thread in sequence.
		job=0; # global counter for runs through the loop [0..num input points]
		cat_next=1; # TODO
		for dispatch in ${DISPATCHES} ; do
			tid=0 # thread ID within current dispatch
			# Launch as many jobs as current dispatch says:
			while [ ${tid} -lt ${dispatch} ] ; do
				i=0
				for cur in $PRIMARY_KEYS ; do
					# Get the primary attribute table key that matches the current feature:
					if [ ${i} -eq ${job} ] ; then
						# DEBUG
						#echo "PK=${cur}"					
						break;
					fi
					if [ -n $BASH_VERSION ] ; then
						let i=${i}+1
					else					
						i=`"${EXPR}" ${i} + 1`
					fi
				done
				if [ ${GIS_OPT_THREADS} -gt 1 ] ; then
					# Launch a new processing thread in the background, passing it the primary key:
					model_complete_thread ${tid} 1 ${cur} ${job} ${cat_next} ${num_jobs} $$ &
				else
					# Run processing task in foreground, passing it the primary key:
					model_complete_thread ${tid} 1 ${cur} ${job} ${cat_next} ${num_jobs} $$
				fi
				cat_next=`"${EXPR}" ${cat_next} + \( $num_features - $job \)`
				tid=`"${EXPR}" ${tid} + 1`
				job=`"${EXPR}" ${job} + 1`
				if [ ${GIS_OPT_THREADS} -gt 1 ] ; then
					${SLEEP} "0.02s" # Add a short delay before launching next thread (synchronisation)
				fi
			done
			if [ ${GIS_OPT_THREADS} -gt 1 ] ; then
				${WAIT} # Wait for all dispatched jobs to complete.
			fi
			g.message -p "${job} ${num_features} 1"
		done # Done running all dispatches for concurrent processing.
		#
	fi # Main loop ends here (both single and multi threaded operation).
	
	# DEBUG
	#MARK=`date`
	#echo "0 MODEL COMPLETE DONE: '$MARK'"
	
	# SQLite backend only: Switch back into mapset's default table storage mode (if required)!
	if [ "${DBMS_NAME}" = "SQLite" ] && [ ${GIS_OPT_THREADS} -gt 1 ] && [ ${DBMS_LOCKS_REQUIRED} -ne ${DBMS_LOCKS_REQUIRED_OLD} ] ; then		
		g.message -i "Switching back to per-mapset table storage for backend '${DBMS_NAME}'."
		grass_db_connect_default
		DBMS_LOCKS_REQUIRED=${DBMS_LOCKS_REQUIRED_OLD}
	fi
	
	# All background threads done: CONTINUE single-threaded work!
	
	# Build SORTED list of subnetwork maps from all dispatched jobs.
	# It is of critical importance to maintain a well-defined order here,
	# because the attribute transfer (from input nodes) later will depend on it!
	job=0;
	for dispatch in ${DISPATCHES} ; do
		tid=0 # thread ID within current dispatch
		while [ ${tid} -lt ${dispatch} ] ; do
			PATCH_LIST="${PATCH_LIST}
${TMP_VECT_LINKS_PATCH}_${job}
"
			job=`"${EXPR}" ${job} + 1`
			tid=`"${EXPR}" ${tid} + 1`
		done
	done

	# MAIN LOOP DONE.
	
	# Now patch all temporary link output maps into a complete map!	
	# Count number of maps to patch:
	num_patches=0
	for map in $PATCH_LIST ; do
		num_patches=`"${EXPR}" ${num_patches} + 1`
	done
	if [ $num_patches -lt 1 ] ; then
		exit_error "No links found in result of 'complete' model run."
	fi
	# Do the patching:
	g.message -i "Merging ${num_patches} network link subsets:"
	step=0
	first="TRUE" # First run through patching loop
	for map in $PATCH_LIST ; do
		#DEBUG
		#echo patching: "${map}"
		if [ "${first}" = "TRUE" ] ; then
			# First map: Just copy
			g.copy vector="${map},${GIS_OPT_LINKS}" --overwrite --quiet 2>/dev/null
			check_error "Failed to copy first patch of complete links map."
			first="FALSE"
		else
			# 2nd or higher run: Append (-a) patch to output map
			v.patch input="${map}" output="${GIS_OPT_LINKS}" -a -b --overwrite --quiet
			check_error "Failed to merge patch #${step} of complete links map."
		fi
		if [ -n $BASH_VERSION ] ; then
			let step=${step}+1
		else
			step=`"${EXPR}" ${step} + 1`
		fi
		g.message -p "${step} ${num_patches} 1"
	done	
	
	# We have modified GIS_OPT_INPUT (heavily) and deleted many of its points.
	# But we have a copy of the (filtered) original input, made by 'preprocess()':
	# Copy that back!
	g.copy vector="${GIS_OPT_NODES},${GIS_OPT_INPUT}" --overwrite 2>/dev/null
	check_error "Failed to copy initial output nodes back to original input points map '${GIS_OPT_INPUT}'."
	
	# Build topology of links output map
	v.build map="${GIS_OPT_LINKS}" -e --overwrite
	check_error "Failed to build/check topology of output vector map (links)."
	
	# After v.patch, categories are a mess. We rebuild them now, so that every link has its own category ID!
	# Delete old category IDs:
	g.message -i "Rebuilding primary key sequence of links output map (1/2):"
	v.category input="${GIS_OPT_LINKS}" output="${TMP_VECT_LINKS_CAT}" layer="1" option="del" cat="-1" --overwrite --quiet
	check_error "Failed to remove defective category IDs from links output vector map."
	clean_links # Just to suppress useless overwrite warning
	g.message -i "Rebuilding primary key sequence of links output map (2/2):"
	v.category output="${GIS_OPT_LINKS}" input="${TMP_VECT_LINKS_CAT}" layer="1" option="add" cat="1" step="1" --overwrite --quiet
	check_error "Failed to add proper category IDs to links output vector map."
	
	eval `v.info -t map="${GIS_OPT_LINKS}" layer="1"`
	g.message -i "Fully connected network has ${lines} links."
	
	# ATTACH OUTPUT ATTRIBUTES
	# Attach an (empty except for 'cat') attribute table.	
	${V_DB_ADDTABLE} map="${GIS_OPT_LINKS}" layer="1" key="${LINKS_FLD_KEY}" --quiet 2>/dev/null
	check_error "Failed to add attribute table to links output vector map."
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_FROM_ID} INTEGER" --quiet
	check_error "Failed to add attribute field '${LINKS_FLD_FROM_ID}' (type 'integer') to links output vector map."
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_TO_ID} INTEGER" --quiet
	check_error "Failed to add attribute field '${LINKS_FLD_TO_ID}' (type 'integer') to links output vector map."
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_FROM_LBL} ${LABEL_TYPE_OUT}" --quiet
	check_error "Failed to add attribute field '${LINKS_FLD_FROM_LBL}' (type '${LABEL_TYPE_OUT}') to links output vector map."
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_TO_LBL} ${LABEL_TYPE_OUT}" --quiet
	check_error "Failed to add attribute field '${LINKS_FLD_TO_LBL}' (type '${LABEL_TYPE_OUT}') to links output vector map."
	
	# THIS ONE IS TRICKY.
	# We now have:
	# (A) The set of original attribute points, with user-specified primary keys (and labels).
	# (B) A completely separate set of lines that represent all possible links of the network.
	# We now need to transfer the primary keys (and labels) of A to the lines of B as from/to
	# attributes. The solution here is to once more loop through all original points in A,
	# same as we have just done, and to 'reconstruct' the 'rythm'.
	# To do this, we can rely on two simple properties of the links map:
	# 1. Number of links(x) in fully connected network: x = n(n - 1) / 2
	# 2. First node has (num_nodes-1) links, 2nd has (num_nodes-2), etc.
	
	# DEBUG
	#MARK=`date`
	#echo "1 TRANSFER ATTS TO LINKS START: '$MARK'"
	
	# Initialize chunk-based SQL statement collation
	if [ ${GIS_OPT_SQLBUFLEN} -gt ${lines} ] ; then
		chunk_size=${lines}
	else
		chunk_size=${GIS_OPT_SQLBUFLEN} # Number of SQL statements to collate before executing them (initialize to default)
	fi
	chunk_left=${chunk_size} # Number SQL statements left to collate in current chunk
	# Set Threshold variable for determining when to execute leftover statements in single mode:
	chunk_remainder=`"${EXPR}" ${lines} % ${chunk_size}`
	# Initialize contents of first SQL_CHUNK to 'empty':
	SQL_CHUNK="${DBMS_BEGIN}"
	#
	g.message -i "Transferring input point attributes to output lines (links):"	
	# Step through all points of input map and connect them with each other.
	previous="" # List of previous primary keys that have already been connected as "TO" nodes.
	step=1 # This one is just for progress reporting.
	cat=1 # This is the category value (GRASS primary key) of the current link. We use this
	      # to step through all links of the completely connected network, regardless of any
	      # other attribute values.
	links=`"${EXPR}" ${NUM_INPUT_NODES} - 1` # This is the number of links that are connected
										  # FROM the current node; this number is decreased by 1
										  # each step through the loop.
	
	# Step through all nodes in the same order once more; on this pass, we ONLY transfer
	# SOME (most important) attributes.
	#
	# PERFORMANCE: We do not use 'v.db.update' (huge overhead).
	# Instead, we first build a list of all SQL UPDATE statements, then feed that
	# into 'db.execute' in one go!
	#	
	# Add all useful indices to speed up operations	
	add_index "${GIS_OPT_INPUT}" "${LINKS_FLD_KEY}"	
	# Get and store info for table connected to input map:
	cmd=`v.info -e map="${GIS_OPT_INPUT}" layer="${GIS_OPT_LAYER}"`
	check_error "Failed to query vector map '$GIS_OPT_INPUT' for extended metadata."	
	# Get DB driver name:
	eval_ws_safe "${cmd}" "attribute_database_driver"
	if [ -z "${EVAL_RESULT}" ] ; then
		exit_error "Failed to retrieve driver of database connection for vector map 'GIS_OPT_INPUT'."
	fi
	in_attr_drv="${EVAL_RESULT}"	
	# Get name of connected database:
	eval_ws_safe "${cmd}" "attribute_database"
	if [ -z "${EVAL_RESULT}" ] ; then
		exit_error "Failed to retrieve name of database connection for vector map '$GIS_OPT_INPUT'."
	fi
	in_attr_db="${EVAL_RESULT}"
	# Get name of linked table in conntected DB:
	eval_ws_safe "${cmd}" "attribute_table"
	if [ -z "${EVAL_RESULT}" ] ; then
		exit_error "Failed to retrieve name of database table for vector map 'GIS_OPT_INPUT'."
	fi
	in_attr_tbl="${EVAL_RESULT}"
	# Get info for connected database and table (output links map):
	get_tbl_info "${GIS_OPT_LINKS}"
	# Now transfer attibutes from original input map to links output map!
	get_primary_keys "${GIS_OPT_INPUT}"
	IFS_BACKUP="$IFS"
	IFS="${IFS_NEWLINE}"
	for key in $PRIMARY_KEYS ; do
		if [ ${step} -lt ${NUM_INPUT_NODES} ] ; then
			previous="${previous} $key " # Add current key to list of previous keys.
 			# Compose SQL WHERE statement for retreiving  next primary key value.
			get_where_clause "${key}"
			val=`db.select database="${in_attr_db}" driver="${in_attr_drv}" sql="SELECT ${GIS_OPT_KEY} FROM ${in_attr_tbl} WHERE ${WHERE};" -c --quiet`
			check_error "Failed to query attribute table of copy of input points map."
			if [ -n "${val}" ] ; then # Feature exists! Process it:
				# Read "FROM" label field value (stays constant during this run through loop):
				get_label_fast "${in_attr_tbl}" "${key}" "${in_attr_drv}" "${in_attr_db}"
				from_lbl="${LABEL}"
				if [ -n $BASH_VERSION ] ; then
					let target=${cat}+${links}-1
				else
					target=`"${EXPR}" ${cat} + ${links} - 1`
				fi
				while [ ${cat} -le ${target} ] ; do
					# Inner loop: We transfer a FROM/TO pair in every pass through this loop.           
					# The FROM key is constant here,
					# while the TO key becomes, in turn, every entry on the list of
					# primary keys that is _neither_ the current key _nor_ any key that
					# was used previously as a FROM key!
					for cur in $PRIMARY_KEYS ; do
						str_substr "${previous}" " ${cur} "
						if [ -z "${SUBSTR_EXIST}" ] ; then # Key not found on list of previously transferred keys: Transfer as new TO key in FROM/TO pair.
							# Check if chunk size needs to be set to "1" (=single SQL transactions for remainder dataset)
							if [ -n $BASH_VERSION ] ; then
								let records_left=${lines}-${cat}
							else
								records_left=`${EXPR} ${lines} - ${cat}`
							fi
							if [ ${records_left} -lt ${chunk_remainder} ] ; then
								chunk_size=1
							fi
							# Get label of "To" node:
							get_label_fast "${in_attr_tbl}" "${cur}" "${in_attr_drv}" "${in_attr_db}"
							to_lbl="${LABEL}"
							# Transfer the actual from/to attributes to the output (links) map's table!
							SQL=""
							SQL="${SQL}UPDATE ${attribute_table} SET"
							SQL="${SQL} ${LINKS_FLD_FROM_ID} = ${key}"
							SQL="${SQL}, ${LINKS_FLD_TO_ID} = ${cur}"
							SQL="${SQL}, ${LINKS_FLD_FROM_LBL} = '${from_lbl}'"
							SQL="${SQL}, ${LINKS_FLD_TO_LBL} = '${to_lbl}'"
							SQL="${SQL} WHERE ${LINKS_FLD_KEY} = ${cat}; "
							#							
							# Now add attributes to output links.
							if [ ${chunk_size} -gt 1 ] && [ ${chunk_left} -gt 1 ] ; then
								# Keep collecting statements for current chunk.
								SQL_CHUNK="${SQL_CHUNK}
${SQL}"
								if [ -n $BASH_VERSION ] ; then
									let chunk_left=${chunk_left}-1
								else
									chunk_left=`${EXPR} ${chunk_left}-1`
								fi
							else
								if [ ${chunk_size} -eq 1 ] ; then
									SQL_CHUNK="$SQL" # Chunk contains only one piece.
								else
									# Add final chunk piece:
									SQL_CHUNK="${SQL_CHUNK}
${SQL}
${DBMS_COMMIT}"
								fi							
								"${ECHO}" "${SQL_CHUNK}" | db.execute database="${attribute_database}" input="-"
								check_error "Failed to upload attributes to links output vector map (value='${to_lbl}'; ${LINKS_FLD_KEY}=${cat})."
								# Empty chunk contents:
								SQL_CHUNK="${DBMS_BEGIN}"
								chunk_left=${chunk_size}
							fi							
							g.message -p "${cat} ${lines} 1"
							if [ -n $BASH_VERSION ] ; then
								let cat=${cat}+1
							else
								cat=`"${EXPR}" ${cat} + 1`
							fi
						fi
					done
				done
				if [ -n $BASH_VERSION ] ; then
					let links=${links}-1
				else
					links=`"${EXPR}" ${links} - 1`
				fi				
			fi
			if [ -n $BASH_VERSION ] ; then
				let step=${step}+1
			else
				step=`"${EXPR}" ${step} + 1`
			fi
		else # Last point reached: Do not process!
			step=`"${EXPR}" ${step} + 1`
		fi
	done
	IFS="${IFS_BACKUP}"
	
	# DEBUG
	#MARK=`date`
	#echo "1 TRANSFER ATTS TO LINKS DONE: '$MARK'"
	
	# Drop all previously created indices.	
	del_index "${GIS_OPT_INPUT}" "${LINKS_FLD_KEY}"
	
	# DEBUG
	#MARK=`date`
	#echo "2 UPDATE LINK COST START: '$MARK'"

	# Upload link costs (if cost raster given).
	if [ -n "${GIS_OPT_COSTMAP}" ] ; then
		#
		# Get info for connected database and table (output links map):
		get_tbl_info "${GIS_OPT_LINKS}"
		attribute_database_driver_links="${attribute_database_driver}"
		attribute_database_links="${attribute_database}"
		attribute_table_links="${attribute_table}"
		# Get info for connected database and table (temporary link costs map):
		get_tbl_info "${TMP_VECT_LINKS_COSTS}"
		attribute_database_driver_cost="${attribute_database_driver}"
		attribute_database_cost="${attribute_database}"
		attribute_table_cost="${attribute_table}"		
		#
		# Upload link costs. 
		# Step through all nodes in the same order once more; on this pass, we only transfer
		# some important attributes.
		${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_COST} DOUBLE PRECISION" --quiet
		check_error "Failed to add attribute field '${LINKS_FLD_COST}' to links output vector map."
		get_grass_cats "${GIS_OPT_LINKS}"
		# Initialize chunk-based SQL statement collation
		if [ ${GIS_OPT_SQLBUFLEN} -gt ${lines} ] ; then
			chunk_size=${lines}
		else
			chunk_size=${GIS_OPT_SQLBUFLEN} # Number of SQL statements to collate before executing them (initialize to default)
		fi
		chunk_left=${chunk_size} # Number SQL statements left to collate in current chunk
		# Set Threshold variable for determining when to execute leftover statements in single mode:
		chunk_remainder=`"${EXPR}" ${lines} % ${chunk_size}`
		# Initialize contents of first SQL_CHUNK to 'empty':
		SQL_CHUNK="${DBMS_BEGIN}"
		g.message -i "Updating link costs and uploading to links output attribute table:"		
		step=1 # This one is just for progress reporting.
		IFS_BACKUP="$IFS"
		IFS="${IFS_NEWLINE}"
		for cat in ${GRASS_CATS} ; do
			# Check if chunk size needs to be set to "1" (=single SQL transactions for remainder dataset)
			if [ -n $BASH_VERSION ] ; then
				let records_left=${lines}-${step}
			else
				records_left=`${EXPR} ${lines} - ${step}`
			fi
			if [ ${records_left} -lt ${chunk_remainder} ] ; then
				chunk_size=1
			fi
			# We now have the cached link costs with associated to/from IDs in the attribute table of $TMP_VECT_LINKS_COSTS!
			# We need to transfer the cost attribute from that map to the links output map.
			#
			# Read "From ID" from $GIS_OPT_LINKS:
			from_id=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_FROM_ID} FROM ${GIS_OPT_LINKS} WHERE ${GRASS_PKEY}=${cat};" -c --quiet`
			# Read "To ID" from $GIS_OPT_LINKS:
			to_id=`db.select database="${attribute_database_links}" sql="SELECT ${LINKS_FLD_TO_ID} FROM ${GIS_OPT_LINKS} WHERE ${GRASS_PKEY}=${cat};" -c --quiet`
			WHERE="${LINKS_FLD_FROM_ID}=$from_id AND ${LINKS_FLD_TO_ID}=$to_id" 
			# Read 'cost' attribute value from $TMP_VECT_LINKS_COST:
			costval=`db.select database="${attribute_database_cost}" sql="SELECT ${LINKS_FLD_COST} FROM ${TMP_VECT_LINKS_COSTS} WHERE ${WHERE};" -c --quiet`			
			if [ -z "$costval" ] ; then
				exit_error "No cost value available for path from '$from_id' to '$to_id'."
			fi
			# Create SQL statement for upload of 'cost' value into $GIS_OPT_LINKS:
			SQL=""
			SQL="${SQL}UPDATE ${attribute_table_links} SET"
			SQL="${SQL} ${LINKS_FLD_COST} = ${costval}"			
			SQL="${SQL} WHERE ${GRASS_PKEY} = ${cat}; "
			if [ ${chunk_size} -gt 1 ] && [ ${chunk_left} -gt 1 ] ; then
				# Keep collecting statements for current chunk.
				SQL_CHUNK="${SQL_CHUNK}
${SQL}"
				if [ -n $BASH_VERSION ] ; then
					let chunk_left=${chunk_left}-1
				else
					chunk_left=`${EXPR} ${chunk_left}-1`
				fi
			else
				if [ ${chunk_size} -eq 1 ] ; then
					SQL_CHUNK="$SQL" # Chunk contains only one piece.
				else
					# Add final chunk piece:
					SQL_CHUNK="${SQL_CHUNK}
${SQL}
${DBMS_COMMIT}"
				fi
				#DEBUG
				#echo "SQL_CHUNK="
				#echo "$SQL_CHUNK"
				# Update all 'cost' attribute values in $GIS_OPT_LINKS of all records in current chunk at once:
				"${ECHO}" "${SQL_CHUNK}" | db.execute database="${attribute_database_links}" input="-"
				check_error "Failed to upload attribute '${LINKS_FLD_COST}' to links output vector map (value='${costval}'; ${GRASS_PKEY}=${cat})."
				# Empty chunk contents:
				SQL_CHUNK="${DBMS_BEGIN}"
				chunk_left=${chunk_size}
			fi
			g.message -p "${step} ${lines} 1"
			if [ -n $BASH_VERSION ] ; then
				let step=${step}+1
			else
				step=`"${EXPR}" ${step} + 1`
			fi			
		done
		IFS="${IFS_BACKUP}"
	fi
	
	# DEBUG
	#MARK=`date`
	#echo "2 UPDATE LINK COST DONE: '$MARK'"
	
	# If we have least-cost paths as links, then we need to REVERSE the order
	# of attributes for every m:n from:to set of links. The reason for this
	# is that r.cost/r.path work in the exact reverse order of v.distance (Euclidean links)!
	# Instead of swapping the actual attribute values field-by-field (slow and error prone),
	# we just swap the GRASS primary key values "cat" for all records that have the same
	# user-defined primary key.	
	# NOTE: This will only work if the DBMS used is capable of strictly preserving
	#       record insertion order!
	if [ -n "${GIS_OPT_COSTMAP}" ] && [ ${DBMS_PRESERVES_ORDER} -eq 1 ] ; then
	
		# DEBUG
		#MARK=`date`
		#echo "3 REORDER LINK ATTS START: '$MARK'"
	
		# Get info for connected database and table:
		get_tbl_info "${GIS_OPT_LINKS}"
		attribute_database_driver_links="${attribute_database_driver}"
		attribute_database_links="${attribute_database}"
		attribute_table_links="${attribute_table}"
		
		g.message -i "Reordering link attributes:"
		get_primary_keys "${GIS_OPT_INPUT}"
		line_old=-1
		new_cat_old=-1
		step=1 # This one is just for progress reporting.
		IFS_BACKUP="$IFS"
		IFS="${IFS_NEWLINE}"
		for key in $PRIMARY_KEYS ; do
			WHERE="${LINKS_FLD_FROM_ID}=$key"
			RECS=`db.select database="${attribute_database_links}" sql="SELECT cat FROM ${GIS_OPT_LINKS} WHERE ${WHERE};" -c --quiet`
			check_error "Failed to query attribute table of links output map."
			num_cats=0
			for line in $RECS ; do
				if [ -n $BASH_VERSION ] ; then
					let num_cats=${num_cats}+1
				else
					num_cats=`"${EXPR}" ${num_cats} + 1`
				fi
				max_cat="${line}"
			done
			if [ -n $BASH_VERSION ] ; then
				let max_cat=${max_cat}+1
			else
				max_cat=`"${EXPR}" ${max_cat} + 1`
			fi
			offset=1
			for line in $RECS ; do
				if [ -n $BASH_VERSION ] ; then
					let new_cat=${max_cat}-${offset}
				else
					new_cat=`"${EXPR}" ${max_cat} - ${offset}`
				fi
				if [ ${new_cat} -ne ${line} ] ; then
					if [ ${new_cat} -eq ${line_old} ] && [ ${line} -eq ${new_cat_old} ] ; then
						# Reached the symmetry element of an even number of records: Done with this set.
						break
					fi
					# Initialize contents of first SQL_CHUNK to 'empty':
					SQL_CHUNK="${DBMS_BEGIN}"
					# Swap cats!
					# GRASS always starts automatic 'cat' values at '1', so we can use '0' as a safe temporary
					# and unique value in the swapping process.					
					SQL=""
					SQL="${SQL}UPDATE ${attribute_table_links} SET"
					SQL="${SQL} ${LINKS_FLD_KEY} = 0"
					SQL="${SQL} WHERE ${LINKS_FLD_KEY} = ${line}; "
					SQL_CHUNK="${SQL_CHUNK}
${SQL}"
					SQL=""
					SQL="${SQL}UPDATE ${attribute_table_links} SET"
					SQL="${SQL} ${LINKS_FLD_KEY} = ${line}"
					SQL="${SQL} WHERE ${LINKS_FLD_KEY} = ${new_cat}; "
					SQL_CHUNK="${SQL_CHUNK}
${SQL}"
					SQL=""
					SQL="${SQL}UPDATE ${attribute_table_links} SET"
					SQL="${SQL} ${LINKS_FLD_KEY} = ${new_cat}"
					SQL="${SQL} WHERE ${LINKS_FLD_KEY} = 0; "
					SQL_CHUNK="${SQL_CHUNK}
${SQL}"
					# Commit transaction to DB backend:
					SQL_CHUNK="${SQL_CHUNK}
${DBMS_COMMIT}"
					"${ECHO}" "${SQL_CHUNK}" | db.execute database="${attribute_database_links}" input="-"
					check_error "Failed to swap GRASS 'cat' value '0' with '$new_cat' in links output map."
				else
					# Reached the symmetry element of an odd number of records: Done with this set.
					break
				fi
				line_old=$line
				new_cat_old=$new_cat
				if [ -n $BASH_VERSION ] ; then
					let offset=${offset}+1
				else
					offset=`"${EXPR}" ${offset} + 1`
				fi				
			done
			g.message -p "${step} ${NUM_INPUT_NODES} 1"
			if [ -n $BASH_VERSION ] ; then
				let step=${step}+1
			else
				step=`"${EXPR}" ${step} + 1`
			fi
		done
		IFS="${IFS_BACKUP}"
		
		# DEBUG
		#MARK=`date`
		#echo "3 REORDER LINK ATTS DONE: '$MARK'"
		
	fi

	# We add the path length metrics at the very end (not earlier!), because the links are now properly ordered!
	v.to.db map="${GIS_OPT_LINKS}" layer="1" type="line" option="end" columns="${LINKS_FLD_FROM_X},${LINKS_FLD_FROM_Y}" --quiet
	check_error "Failed to add attribute fields '${LINKS_FLD_FROM_X}' & '${LINKS_FLD_FROM_Y}' to links output vector map."
	v.to.db map="${GIS_OPT_LINKS}" layer="1" type="line" option="start" columns="${LINKS_FLD_TO_X},${LINKS_FLD_TO_Y}" --quiet
	check_error "Failed to add attribute fields '${LINKS_FLD_TO_X}' & '${LINKS_FLD_TO_Y}' to links output vector map."
	v.to.db map="${GIS_OPT_LINKS}" layer="1" type="line" option="length" columns="${LINKS_FLD_LEN_M}" units="meters" --quiet
	check_error "Failed to add attribute field '${LINKS_FLD_LEN_M}' to links output vector map."
	v.to.db map="${GIS_OPT_LINKS}" layer="1" type="line" option="length" columns="${LINKS_FLD_LEN_KM}" units="kilometers" --quiet
	check_error "Failed to add attribute field '${LINKS_FLD_LEN_KM}' to links output vector map."
}


# FUNCTION
# model_delaunay: Create a network where nodes are connected using delaunay minimal triangulation.
model_delaunay () {
	#   Reduce the links to those that have identical copies in the set of lines
	#   produced by v.delaunay (upload start and end coordinates to delaunay lines,
	#	then compare with links of complete network).
	#
	# Get and store attribute storage info for input and links maps:
	get_tbl_info "${GIS_OPT_LINKS}"
	attribute_database_driver_links="${attribute_database_driver}"
	attribute_database_links="${attribute_database}"
	attribute_table_links="${attribute_table}"
	#
	# Add an attribute field to indicate whether a link must be preserved:
	fld_keep="keep" # Name of field to indicate "keep this link".
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${fld_keep} INTEGER" --quiet 2>/dev/null
	check_error "Failed to add field '${fld_keep}' to links output map ('${GIS_OPT_LINKS}')."
	# Initialize all links to "keep=0"
	${V_DB_UPDATE} map="${GIS_OPT_LINKS}" layer="1" column="${fld_keep}" value="0" --quiet 2>/dev/null
	check_error "Failed to update field '${fld_keep}' in links output map ('${GIS_OPT_LINKS}') with initial '0'."
	#
	g.message -i "Triangulating:"
	# NOTE: Current version of v.delaunay (GRASS 7.8.4) is botched: When using its '-l'
	# flag to produce lines, it produces a faulty geometry structure that prevents adding
	# valid categories (cats), using v.db.addtable or v.category, to the features.
	# As work-around, we create polygonal delaunay output and then use  
	# the rather clumsy v.to.lines, which is a Python script around v.edit & Co.,
	# that polutes the console with useless messages and also adds an attribute table
	# to layer 2, while expecting an attribute table to be present in layer 1.
	# We'll need to clean up all that mess to get something useful, then use v.to.db
	# to upload delaunay line start/end node coords to the attribute table in layer 1...
	v.delaunay input="${GIS_OPT_INPUT}" output="${TMP_VECT_LINKS_DELAUNAY_P}" --o --quiet 2>/dev/null
	check_error "Failed to compute Delaunay triangulation for input points/nodes."
	${V_DB_ADDTABLE} map="${TMP_VECT_LINKS_DELAUNAY_P}" layer="1" --quiet 2>/dev/null
	check_error "Failed to add attribute table (layer 1) to temporary map with Delaunay triangulation."
	${V_TO_LINES} input="${TMP_VECT_LINKS_DELAUNAY_P}" output="${TMP_VECT_LINKS_DELAUNAY_L}" --o --quiet 2>/dev/null
	check_error "Failed to convert Delaunay triangulation of input points/nodes to lines."
	${V_DB_DROPTABLE} map="${TMP_VECT_LINKS_DELAUNAY_L}" layer="2" -f --quiet 2>/dev/null
	check_error "Failed to delete attribute table (layer 2) from temporary map with Delaunay triangulation."
	${V_DB_ADDTABLE} map="${TMP_VECT_LINKS_DELAUNAY_L}" layer="1" --quiet 2>/dev/null
	check_error "Failed to add attribute table (layer 1) to temporary map with Delaunay triangulation."
	v.to.db map="${TMP_VECT_LINKS_DELAUNAY_L}" layer="1" type="line" option="start" columns="${LINKS_FLD_FROM_X},${LINKS_FLD_FROM_Y}" units="meters" --o --quiet 2>/dev/null
	check_error "Failed to upload line start coordinates to temporary map with Delaunay triangulation."
	v.to.db map="${TMP_VECT_LINKS_DELAUNAY_L}" layer="1" type="line" option="end" columns="${LINKS_FLD_TO_X},${LINKS_FLD_TO_Y}" units="meters" --o --quiet 2>/dev/null
	check_error "Failed to upload line end coordinates to temporary map with Delaunay triangulation."

	# Make sure to set correct IFS for coordinate list processing.
	IFS_BACKUP="$IFS"
	IFS="${IFS_NEWLINE}"

	# Get node coordinates of all Delaunay links and store them in two lists (X and Y):
	g.message -i "Building list of mesh node coordinates..."	
	tri_coords=`v.db.select separator="pipe" map="${TMP_VECT_LINKS_DELAUNAY_L}" layer="1" columns="${LINKS_FLD_FROM_X},${LINKS_FLD_FROM_Y},${LINKS_FLD_TO_X},${LINKS_FLD_TO_Y}" -c --quiet`
	check_error "Failed to retrieve vertex coordinates from Delaunay triangulation map."

	# Step through all links and mark them for deletion or preservation.
	g.message -i "Reducing network using connectivity model 'DELAUNAY':"
	get_grass_cats "${GIS_OPT_LINKS}"	
	step=1 # This one is just for progress reporting.
	for cat in ${GRASS_CATS} ; do				
		# Get node coordinates of current link in completely connected network (both directions):
		lnk_coords_1=`db.select separator="pipe" sql="SELECT ${LINKS_FLD_FROM_X},${LINKS_FLD_FROM_Y},${LINKS_FLD_TO_X},${LINKS_FLD_TO_Y} FROM ${attribute_table_links} WHERE ${GRASS_PKEY}=${cat};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
		check_error "Failed to retrieve link node coordinates from links map (item: ${GRASS_PKEY}=${cat})."
		lnk_coords_2=`db.select separator="pipe" sql="SELECT ${LINKS_FLD_TO_X},${LINKS_FLD_TO_Y},${LINKS_FLD_FROM_X},${LINKS_FLD_FROM_Y} FROM ${attribute_table_links} WHERE ${GRASS_PKEY}=${cat};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
		check_error "Failed to retrieve link node coordinates from links map (item: ${GRASS_PKEY}=${cat})."
		# Scan list of Delaunay coordinates and see if we have a match:
		preserve="false"
		for cur in $tri_coords ; do
			if [ "${lnk_coords_1}" = "${cur}" ] || [ "${lnk_coords_2}" = "${cur}" ] ; then
				preserve="true"
				break
			fi
		done
		if [ "${preserve}" = "true" ] ; then
			# Mark this link as "keep":
			SQL=""
			SQL="${SQL}UPDATE ${attribute_table_links} SET"
			SQL="${SQL} ${fld_keep} = 1"
			SQL="${SQL} WHERE ${LINKS_FLD_KEY} = ${cat}; "
			"${ECHO}" "${SQL}" | db.execute database="${attribute_database_links}" input="-"
			check_error "Failed to update field '${fld_keep}' to '1' in links output map ('${GIS_OPT_LINKS}') for 'cat=${cat}'."
		fi
		g.message -p "${step} ${lines} 1"
		if [ -n $BASH_VERSION ] ; then
			let step=${step}+1
		else
			step=`"${EXPR}" ${step} + 1`
		fi
	done
	IFS="${IFS_BACKUP}"
	
	# Now we delete all the links that are not marked "keep=1"
	g.message -i "Removing disconnected links..."
	# Delete now!
	v.edit map="${GIS_OPT_LINKS}" layer="1" type="line" tool="delete" where="${fld_keep}=0" --quiet
	check_error "Failed to delete link geometries during Delaunay reduction."
	# Drop associated rows of attribute table from links map:
	SQL="${DBMS_BEGIN}"
	SQL="$SQL
DELETE FROM $attribute_table_links WHERE ${fld_keep} = 0;"
	SQL="$SQL
${DBMS_COMMIT}"
	echo "${SQL}" | db.execute database="${attribute_database_links}" input="-"
	check_error "Failed to delete link attribute rows during Delaunay reduction."

	# Drop column "keep" from links output map: we don't need it any longer.
	${V_DB_DROPCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${fld_keep}" --quiet
	check_error "Failed to drop field '${fld_keep}' from links output map ('${GIS_OPT_LINKS}')."

}


# FUNCTION
# model_linkdist:	Create a network where nodes are connected only if they are at most a threshold 
#					distance or cost value apart (linking bounded by distance).
# 					ATTENTION: Function model_complete() MUST be called before this one, as it sets
#					some important variables that this function reads!
#					This model type is never called directly by the user!
#					Instead, it is run as an additional model, every time the option
#					'maxdist=' is given.
model_linkdist () {	
	
	g.message -i "Maximum linking distance set to '${GIS_OPT_MAXDIST}' (${UNITS_DIST})."
		
	g.message -i "Reducing network by distance threshold..."
	
	# Get and store attribute storage info for input and links maps:
	get_tbl_info "${GIS_OPT_LINKS}"
	attribute_database_driver_links="${attribute_database_driver}"
	attribute_database_links="${attribute_database}"
	attribute_table_links="${attribute_table}"
	
	# Add an attribute field to indicate whether a link must be preserved:
	fld_keep="keep" # Name of field to indicate "keep this link".
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${fld_keep} INTEGER" --quiet 2>/dev/null
	check_error "Failed to add field '${fld_keep}' to links output map ('${GIS_OPT_LINKS}')."
	# Initialize all links to "keep=0"
	${V_DB_UPDATE} map="${GIS_OPT_LINKS}" layer="1" column="${fld_keep}" value="0" --quiet 2>/dev/null
	check_error "Failed to update field '${fld_keep}' in links output map ('${GIS_OPT_LINKS}') with initial '0'."

	# Mark all links for preservation that DO NOT exceed the maximum length:
	${V_DB_UPDATE} map="${GIS_OPT_LINKS}" layer="1" column="${fld_keep}" value="1" where="${FLD_DIST}<=${GIS_OPT_MAXDIST}" --quiet 2>/dev/null
	
	# Now we delete all the links that are not marked "keep=1"
	g.message -i "Removing disconnected links..."
	# Delete now!
	v.edit map="${GIS_OPT_LINKS}" layer="1" type="line" tool="delete" where="${fld_keep}=0" --quiet
	check_error "Failed to delete link geometries during maxdist reduction."
	# Drop associated rows of attribute table from links map:
	SQL="${DBMS_BEGIN}"
	SQL="$SQL
DELETE FROM $attribute_table_links WHERE ${fld_keep} = 0;"
	SQL="$SQL
${DBMS_COMMIT}"
	echo "${SQL}" | db.execute database="${attribute_database_links}" input="-"
	check_error "Failed to delete link attribute rows during maxdist reduction."

	# Drop column "keep" from links output map: we don't need it any longer.
	${V_DB_DROPCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${fld_keep}" --quiet
	check_error "Failed to drop field '${fld_keep}' from links output map ('${GIS_OPT_LINKS}')."

}


# FUNCTION
# model_nn: Create a network where nodes are connected to their n nearest neighbors.
model_nn () {

	#  At this point, it is assured that EITHER 'neighbors=' has been provided and is > 0 OR 'size=' has been provided.
	if [ -z "${GIS_OPT_SIZE}" ] ; then
		#  Check that neighbors < num (filtered) input points:
		if [ ${NUM_INPUT_NODES} -le ${GIS_OPT_NEIGHBORS} ] ; then
			exit_error "Value of option 'neighbors=' must be smaller than number of (filtered) input points/nodes."
		fi
		g.message -i "Number of nearest neighbors to connect is '${GIS_OPT_NEIGHBORS}'."
	else
		g.message -i "Number of nearest neighbors will be read from '${GIS_OPT_SIZE}'."
	fi
	# Get and store attribute storage info for input and links maps:
	get_tbl_info "${GIS_OPT_INPUT}"
	attribute_database_driver_input="${attribute_database_driver}"
	attribute_database_input="${attribute_database}"
	attribute_table_input="${attribute_table}"
	get_tbl_info "${GIS_OPT_LINKS}"
	attribute_database_driver_links="${attribute_database_driver}"
	attribute_database_links="${attribute_database}"
	attribute_table_links="${attribute_table}"
	
	# Add an attribute field to indicate whether a link must be preserved:
	fld_keep="keep" # Name of field to indicate "keep this link".
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${fld_keep} INTEGER" --quiet
	check_error "Failed to add field '${fld_keep}' to links output map ('${GIS_OPT_LINKS}')."
	# Initialize all links to "keep=0"
	${V_DB_UPDATE} map="${GIS_OPT_LINKS}" layer="1" column="${fld_keep}" value="0" --quiet
	check_error "Failed to update field '${fld_keep}' in links output map ('${GIS_OPT_LINKS}') with initial '0'."	
	
	# Go!
	g.message -i "Reducing network by connectivity model 'NN':"
	
	# Step through all input nodes:
	get_primary_keys "${GIS_OPT_INPUT}"
	IFS_BACKUP="$IFS"
	IFS="${IFS_NEWLINE}"
	#
	step=1 # This one is just for progress reporting.	
	for key in $PRIMARY_KEYS ; do
		#
		if [ -n "${GIS_OPT_SIZE}" ] ; then
			# Read number of nearest neighbors from 'size' field of current node
			GIS_OPT_NEIGHBORS=`db.select sql="SELECT ${GIS_OPT_SIZE} FROM ${attribute_table_input} WHERE ${GIS_OPT_KEY}=${key};" driver="${attribute_database_driver_input}" database="${attribute_database_input}" -c --quiet`
			check_error "Failed to query field '${GIS_OPT_SIZE}' of input nodes map (key='$key')."
			grep_is_positive "${GIS_OPT_NEIGHBORS}"
			if [ -z ${GREP_VALUE} ] ; then
				exit_error "Invalid 'size' for input point with 'key'='${key}': Must be larger than '0'."
			fi
			if [ ${NUM_INPUT_NODES} -le ${GIS_OPT_NEIGHBORS} ] ; then
				exit_error "Number of nearest must be smaller than number of (filtered) input points/nodes (is: '${GIS_OPT_NEIGHBORS}' for input node with key'='${key})."
			fi
		fi
		# Get sorted list of lengths for all links connected to current node via 'from_id' or 'to_id'.
		# We look at 'from_id' first:
		lengths_from=`db.select sql="SELECT ${FLD_DIST} FROM ${attribute_table_links} WHERE ${LINKS_FLD_FROM_ID}=${key};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
		check_error "Failed to query fields '${FLD_DIST}' and '${LINKS_FLD_FROM_ID}' of links output map (key='${key}')."
		# Now 'to_id':
		lengths_to=`db.select sql="SELECT ${FLD_DIST} FROM ${attribute_table_links} WHERE ${LINKS_FLD_TO_ID}=${key};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
		check_error "Failed to query fields '${FLD_DIST}' and '${LINKS_FLD_TO_ID}' of links output map (key='${key}')."
lengths="${lengths_from}
${lengths_to}"
		if [ -n "${lengths}" ] ; then
			# Sorting with 'asorti(a,b)' is not support on macOS' AWK, so we use 'sort' here.
			# LIST=`"${ECHO}" "$lengths" | "${AWK}" '{a[$0]}END{asorti(a,b,"@ind_num_asc");for(i=1;i<=NR;i++)print b[i]}'`
			LIST=`"${ECHO}" "$lengths" | "${SORT}" -n`
			if [ -n "${LIST}" ] ; then
				#echo "$LIST"
				# Now get GRASS primary keys (cat) for all links connected FROM this node via 'from_id':
				CATS_FROM=`db.select sql="SELECT cat FROM ${attribute_table_links} WHERE ${LINKS_FLD_FROM_ID}=${key};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
				check_error "Failed to query field '${LINKS_FLD_FROM_ID}' of links output map (key='${key}')."
				# Now get GRASS primary keys (cat) for all links connected TO this node via 'to_id':
				CATS_TO=`db.select sql="SELECT cat FROM ${attribute_table_links} WHERE ${LINKS_FLD_TO_ID}=${key};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
				check_error "Failed to query field '${LINKS_FLD_TO_ID}' of links output map (key='${key}')."
CATS="${CATS_FROM}
${CATS_TO}"
				if [ -n "${CATS}" ] ; then
					connected=0 # Count of neighbors connected to this node
					for cat in ${CATS} ; do
						preserve="false" # If not 'true' by the end of this loop, link will be deleted!
						if [ $connected -lt ${GIS_OPT_NEIGHBORS} ] ; then
							# We are still looking to connect at least one more!
							len=`db.select sql="SELECT ${FLD_DIST} FROM ${attribute_table_links} WHERE cat=${cat};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
							check_error "Failed to query links output map for field '${FLD_DIST}' ('cat=${cat}')."
							# Get info for connected database and table:
							get_tbl_info "${GIS_OPT_LINKS}"
							# Step through sorted list of distances and see if we can get a match
							# in the first n items!
							neighbor=0;
							for cur in $LIST ; do
								if [ "$cur" = "$len" ] ; then
									if [ $neighbor -lt ${GIS_OPT_NEIGHBORS} ] ; then
										if [ -n $BASH_VERSION ] ; then
											let connected=${connected}+1
										else
											connected=`"${EXPR}" ${connected} + 1`
										fi
										# Mark this link as "keep":
										SQL=""
										SQL="${SQL}UPDATE ${attribute_table_links} SET"
										SQL="${SQL} ${fld_keep} = 1"
										SQL="${SQL} WHERE ${LINKS_FLD_KEY} = ${cat}; "
										"${ECHO}" "${SQL}" | db.execute database="${attribute_database_links}" input="-"
										check_error "Failed to update field '${fld_keep}' to '1' in links output map ('${GIS_OPT_LINKS}') for 'cat=${cat}'."
									fi
								fi
								if [ -n $BASH_VERSION ] ; then
									let neighbor=${neighbor}+1
								else
									neighbor=`"${EXPR}" ${neighbor} + 1` # Advance to next neighbor.
								fi
							done							
						fi						
					done
				fi
			fi
			g.message -p "${step} ${NUM_INPUT_NODES} 1"
			if [ -n $BASH_VERSION ] ; then
				let step=${step}+1
			else
				step=`"${EXPR}" ${step} + 1`
			fi
		fi
	done
	IFS="${IFS_BACKUP}"
	
	# Now we delete all the links that are not marked "keep=1"
	g.message -i "Removing disconnected links..."
	# Delete now!
	v.edit map="${GIS_OPT_LINKS}" layer="1" type="line" tool="delete" where="${fld_keep}=0" --quiet
	check_error "Failed to delete link geometries during NN reduction."
	# Drop associated rows of attribute table from links map:
	SQL="${DBMS_BEGIN}"
	SQL="$SQL
DELETE FROM $attribute_table_links WHERE ${fld_keep} = 0;"
	SQL="$SQL
${DBMS_COMMIT}"
	echo "${SQL}" | db.execute database="${attribute_database_links}" input="-"
	check_error "Failed to delete link attribute rows during NN reduction."

	# Drop column "keep" from links output map: we don't need it any longer.
	${V_DB_DROPCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${fld_keep}" --quiet
	check_error "Failed to drop field '${fld_keep}' from links output map ('${GIS_OPT_LINKS}')."
}


# FUNCTION
# model_xtent: Create a network where nodes are connected according to XTENT formula.
model_xtent () {
	g.message -i "Node size will be read from field '${GIS_OPT_SIZE}'."
	g.message -i "Exponential node weight 'a' set to '${GIS_OPT_A}'."
	g.message -i "Linear distance weight 'k' set to '${GIS_OPT_K}'."
	# Find min/max values of C in attribute table.
	Cmin=""
	Cmax=""
	result=`v.info map="${GIS_OPT_INPUT}" layer="1" --quiet -c | "${GREP}" -w "${GIS_OPT_SIZE}" | "${GREP}" -c "|${GIS_OPT_SIZE}"`
	check_error "Failed to get columns info for nodes input vector map ('${GIS_OPT_INPUT}')."
	if [ ${result} -gt 0 ] ; then		
		VALUES=`v.db.select map="${GIS_OPT_INPUT}" layer="1" columns="${GIS_OPT_SIZE}" -c --quiet`
		check_error "Failed to retrieve all values for 'C' from nodes input vector map ('${GIS_OPT_INPUT}')."
		for val in ${VALUES} ; do
			awk_max "${Cmax}" "${val}"
			Cmax="${AWK_VALUE}"
			awk_min "${Cmin}" "${val}"
			Cmin="${AWK_VALUE}"
		done
	else
		exit_error "Found no column for 'C' values in nodes input vector map ('${GIS_OPT_INPUT}')."
	fi
	if [ -z "$Cmax" ] ; then
		exit_error "Found no 'C' values in nodes input vector map ('${GIS_OPT_INPUT}')."
	fi
	g.message -i "Minimum 'C' value in data is '${Cmin}'."
	g.message -i "Maximum 'C' value in data is '${Cmax}'."
	
	# Compute link statistics:
	stats_compute_links

	# Get current attribute table info for (input) nodes and links maps:
	get_tbl_info "${GIS_OPT_INPUT}"
	attribute_database_driver_input="${attribute_database_driver}"
	attribute_database_input="${attribute_database}"
	attribute_table_input="${attribute_table}"
	get_tbl_info "${GIS_OPT_LINKS}"
	attribute_database_driver_links="${attribute_database_driver}"
	attribute_database_links="${attribute_database}"
	attribute_table_links="${attribute_table}"

	# Add an attribute field to indicate whether a link must be preserved:
	fld_keep="keep" # Name of field to indicate "keep this link".
	${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${fld_keep} INTEGER" --quiet
	check_error "Failed to add field '${fld_keep}' to links output map ('${GIS_OPT_LINKS}')."
	# Initialize all links to "keep=0"
	${V_DB_UPDATE} map="${GIS_OPT_LINKS}" layer="1" column="${fld_keep}" value="0" --quiet
	check_error "Failed to update field '${fld_keep}' in links output map ('${GIS_OPT_LINKS}') with initial '0'."

	# Reduce!
	g.message -i "Reducing network by connectivity model 'XTENT':"
	# Step through all links and use v.edit to delete every link which scores I <= 0 for XTENT!
	get_grass_cats "${GIS_OPT_LINKS}"
	IFS_BACKUP="$IFS"
	IFS="${IFS_NEWLINE}"
	step=1 # This one is just for progress reporting.
	for cat in ${GRASS_CATS} ; do
		# Get size of "from node":
		from_id=`db.select sql="SELECT ${LINKS_FLD_FROM_ID} FROM ${attribute_table_links} WHERE ${GRASS_PKEY}=${cat};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
		check_error "Failed to query field '${LINKS_FLD_FROM_ID}' of output nodes map (cat='${cat}')."
		from_size=`db.select sql="SELECT ${GIS_OPT_SIZE} FROM ${attribute_table_input} WHERE ${GIS_OPT_KEY}=${from_id};" driver="${attribute_database_driver_input}" database="${attribute_database_input}" -c --quiet`
		check_error "Failed to query field '${GIS_OPT_SIZE}' of output nodes map ('${GRASS_PKEY}=${cat}')."
		grep_is_positive "${from_size}"
		if [ -z ${GREP_VALUE} ] ; then
			exit_error "Invalid 'size' for input point with 'key'='${from_id}': Must be larger than '0'."
		fi
		# Get size of "to node":
		to_id=`db.select sql="SELECT ${LINKS_FLD_TO_ID} FROM ${attribute_table_links} WHERE ${GRASS_PKEY}=${cat};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
		check_error "Failed to query field '${LINKS_FLD_TO_ID}' of output nodes map ('${GRASS_PKEY}=${cat}')."
		to_size=`db.select sql="SELECT ${GIS_OPT_SIZE} FROM ${attribute_table_input} WHERE ${GIS_OPT_KEY}=${to_id};" driver="${attribute_database_driver_input}" database="${attribute_database_input}" -c --quiet`
		check_error "Failed to query field '${GIS_OPT_SIZE}' of output nodes map ('${GRASS_PKEY}=${cat}')."
		grep_is_positive "${to_size}"
		if [ -z ${GREP_VALUE} ] ; then
			exit_error "Invalid 'size' for input point with 'key'='${to_id}': Must be larger than '0'."
		fi
		distance=`db.select sql="SELECT ${FLD_DIST} FROM ${attribute_table_links} WHERE ${GRASS_PKEY}=${cat};" driver="${attribute_database_driver_links}" database="${attribute_database_links}" -c --quiet`
		check_error "Failed to query field '${FLD_DIST}' of output nodes map ('${GRASS_PKEY}=${cat}')."
		awk_calc "${from_size}^${GIS_OPT_A}"
		C_a="${AWK_VALUE}" # weighted 'from' size
		awk_calc "${to_size}^${GIS_OPT_A}"
		C_b="${AWK_VALUE}" # weighted 'to' size
		awk_calc "${C_a}+${C_b}"
		C="${AWK_VALUE}" # combination of weighted 'from' & 'to' sizes
		awk_calc "${GIS_OPT_K}*${distance}"
		dist="${AWK_VALUE}" # weighted distance
		# 'davg' is the _average_ length of links in complete network; by default, this is the arithmetic mean
		if [ "${RUNMODE_COST}" != "TRUE" ] ; then
			davg="${net_len_mean_unreduced}" # Default
		else
			davg="${net_cost_mean_unreduced}" # Default
		fi		
		if [ "${GIS_OPT_AVG}" = "median" ] ; then
			# Choice: Use median
			if [ "${RUNMODE_COST}" != "TRUE" ] ; then			
				davg="${net_len_median_unreduced}"
			else				
				davg="${net_cost_median_unreduced}"
			fi
		fi
		awk_calc "($C*($davg/$Cmax))-($dist)"
		I="${AWK_VALUE}" # must be > 0 to connect
		grep_is_positive "$I" # Will set GREP_VALUE if $I is positive
		if [ -n "${GREP_VALUE}" ] ; then
			# I > 0: Mark this link as KEEP
			SQL=""
			SQL="${SQL}UPDATE ${attribute_table_links} SET"
			SQL="${SQL} ${fld_keep} = 1"
			SQL="${SQL} WHERE ${LINKS_FLD_KEY} = ${cat}; "
			"${ECHO}" "${SQL}" | db.execute database="${attribute_database_links}" input="-"
			check_error "Failed to update field '${fld_keep}' to '1' in links output map ('${GIS_OPT_LINKS}') for 'cat=${cat}'."
		fi
		g.message -p "${step} ${lines} 1"
		if [ -n $BASH_VERSION ] ; then
			let step=${step}+1
		else
			step=`"${EXPR}" ${step} + 1`
		fi
	done
	IFS="${IFS_BACKUP}"
	
	# Now we delete all the links that are not marked "keep=1"
	g.message -i "Removing disconnected links..."
	# Delete now!
	v.edit map="${GIS_OPT_LINKS}" layer="1" type="line" tool="delete" where="${fld_keep}=0" --quiet
	check_error "Failed to delete link geometries during xtent reduction."
	# Drop associated rows of attribute table from links map:
	SQL="${DBMS_BEGIN}"
	SQL="$SQL
DELETE FROM $attribute_table_links WHERE ${fld_keep} = 0;"
	SQL="$SQL
${DBMS_COMMIT}"
	echo "${SQL}" | db.execute database="${attribute_database_links}" input="-"
	check_error "Failed to delete link attribute rows during xtent reduction."

	# Drop column "keep" from links output map: we don't need it any longer.
	${V_DB_DROPCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${fld_keep}" --quiet
	check_error "Failed to drop field '${fld_keep}' from links output map ('${GIS_OPT_LINKS}')."

}


# FUNCTION
# clean_initial_coords:	Helper function for checking coordinate values stored
#						 	in the attribute table of the initial links map (option 'initial=').
#							The challenge here is that it is possible to specify an initial links map
#							which does not contain the from/to x/y coordinate fields. However, the
#							values in those fields are used by some models to match input nodes with
#							links. This means that they must be _exact_ matches to the x/y coordinates
#							of input nodes. But we cannot trust this to be so, since the links map
#							might not be of perfect topological quality. So this function is called
#							after initial links start/end vertex snapping in the main program body,
#							to make sure that all is fine and dandy.
#
# 							Arguments:
#						    $1 - name of map that contains initial links
#			 				$2 - node coordinate value to test against
#							$3 - name of attribute field in initial links map that stores the same coordinate
#							$4 - name of primary key field in initial links map
#							$5 - primary key value to get correct record from initial links map.
#
clean_initial_coords () {
	# Set map to work on:
	map_init_links="$1"
	# Set node coordinate for comparison:
	val_coord_node="$2"
	# Set coordinate to read from link attribute field:
	fld_link_coord="$3"
	# Set primary key name:
	clean_id_pkey_fld="$4"
	# Set primary key value:
	clean_id_pkey_val="$5"
	# Coordinate from link map's attribute field:
	val_coord_link=`v.db.select map="${map_init_links}" column="${fld_link_coord}" where="${clean_id_pkey_fld}=${clean_id_pkey_val}" -c`												
	check_error "Failed to read attribute field '${fld_link_coord}' from copy of initial links map."						
	# Check if both coordinates are exactly equal:						
	awk_equal "${val_coord_link}" "${val_coord_node}"
	if [ ${AWK_VALUE} -ne 1 ] ; then
		# There is a difference!
		# Get absolute difference between node coordinate and link coordinate:						
		awk_abs "${val_coord_link}" "${val_coord_node}"
		diff="${AWK_VALUE}"
		# Let's check if abs diff is within the allowed threshold!
		awk_smaller_eq "${diff}" "${GIS_OPT_THRESHOLD}" 
		if [ ${AWK_VALUE} -ne 1 ] ; then
			# Difference too large: throw error and exit!
			g.message -e "Difference between coordinate '${fld_link_coord}' of initial link with '${clean_id_pkey_fld}=${clean_id_pkey_val}'"
			g.message -e "and coordinate of input point (node) with the same ID is too large (${val_coord_link} vs ${val_coord_node})!"
			g.message -e "Please check that the links provided in map 'initial=${GIS_OPT_INITIAL}' really"
			g.message -e "connect with points in map 'input=${GIS_OPT_INPUT}'. "
			g.message -e "Automatic correction failed with 'threshold=${GIS_OPT_THRESHOLD}'."
			exit_error "Topology error."
		else
			# Warn about difference.
			g.message -e "Difference between coordinate '${fld_link_coord}' of initial link with '${clean_id_pkey_fld}=${clean_id_pkey_val}'"
			g.message -e "and coordinate of input point (node) with the same ID detected (${val_coord_link} vs ${val_coord_node})."
			# Back up any DBMS info that the caller might have!
			clean_coords_att_database_driver="${attribute_database_driver}"
			clean_coords_att_database="${attribute_database}"
			clean_coords_att_table="${attribute_table}"
			# Get info for connected database and table:
			get_tbl_info "${map_init_links}"			
			# Copy node coordinate to link coordinate (field to field):
			SQL=""
			SQL="${SQL}UPDATE ${attribute_table} SET"
			SQL="${SQL} ${fld_link_coord} = ${val_coord_node}"
			SQL="${SQL} WHERE ${clean_id_pkey_fld} = ${clean_id_pkey_val}; "
			"${ECHO}" "${SQL}" | db.execute database="${attribute_database}" input="-"
			#TODO: DELETEME: Below call to "v.db.update" has been replaced by an SQL statement piped into 'db.execute'!
			#${V_DB_UPDATE} map="${map_init_links}" layer="1" column="${fld_link_coord}" value="${val_coord_node}" --quiet
			check_error "Failed to update field '${fld_link_coord}' in copy of initial links map."
			g.message -w "Automatic correction succeeded with 'threshold=${GIS_OPT_THRESHOLD}'."								
			# Restore DBMS info that the caller might have had!
			attribute_database_driver="${clean_coords_att_database_driver}"
			attribute_database="${clean_coords_att_database}"
			attribute_table="${clean_coords_att_table}"
		fi
	fi
}


# FUNCTION
# MAIN():	This is a bogus function. It exists only so that text
#			editors will find this as a marker when parsing the source
#		   	code in "SH" mode, and can add it to their document outline. 
MAIN () {
	"${ECHO}" ""
}

########
# MAIN #
########

# Keep track of starting time.
START=`"${DATE}"`

# Check GRASS environment:
check_environment

# Go!
g.message -i "$MODULE_NAME_EXEC ($MODULE_VERSION) started."

# Run all pre-flight checks:
check_setup
if [ -z "${MULTI_THREADING_SUPPORT}" ] ; then
	g.message -w "Multi-threaded operation not supported on this operating system. Forcing 'threads=1'."
	GIS_OPT_THREADS=1
fi
check_params
check_input

# Set up paramaters for multi-threaded processing
#
# Enable DBMS locking if required (e.g. SQLite Backend + threads > 1):
DBMS_LOCKS_REQUIRED=0
if [ ${GIS_OPT_THREADS} -gt 1 ] && [ ${DBMS_THREAD_SAFE} -lt 1 ] ; then
	DBMS_LOCKS_REQUIRED=1
	# Issue a performance warning for all database backends EXCEPT SQLite.
	# Reason: We can (and will) switch SQLite into a non-locking mode when it counts!
	if [ "${DBMS_NAME}" != "SQLite" ] ; then
		g.message -w "DBMS locks required for multi-threaded operation. Expect reduced performance."
	fi
fi

# Perform input data pre-processing:
preprocess

# GO! GO!
#GIS_OPT_INPUT is the input points map: Its handle has been set by check_input()!
g.message -i "Input network has ${NUM_INPUT_NODES} nodes."

# Report spatial accuracy of cost calculations.
if [ -n "${GIS_OPT_COSTMAP}" ] ; then
	# Compute least cost surface from current node to all other nodes:
	if [ ${GIS_FLAG_K} -eq 1 ] ; then
	    # Use 'knight's move' (more accurate but slower)
	    g.message -i "Using slower but more accurate cost computations ('r.cost -r')."
	else
		# Use simple diagonal moves (less accurate but faster, default if '-k' is not given
		g.message -i "Using faster but less accurate cost computations."
	fi
fi

# Compute complete model first (always, unless option "initial=" is provided):
if [ -n "${GIS_OPT_INITIAL}" ] ; then
	# Load initial model instead of computing complete model.
	eval `v.info -t map="${GIS_OPT_INITIAL}" layer="1"`
	g.message -i "Initial network has ${lines} links."
	# Copy initial map as (preliminary) links output map:
	g.copy vector="${GIS_OPT_INITIAL},${GIS_OPT_LINKS}" --overwrite --quiet 2>/dev/null
	check_error "Failed to copy initial links map as preliminary links output map."

	# There are some attributes that might be missing from the initial links map and	
	# that can be added automatically now. Note that we work on GIS_OPT_INITIAL which
	# (at this point) is just a copy of the original initial links map, so it's ok to modify!
	if [ ${TRIGGER_ATTR_LENGTH} == "TRUE" ] || [ ${TRIGGER_ATTR_COST} == "TRUE" ] || [ ${TRIGGER_ATTR_COORDINATES} == TRUE ] ; then
		if [ ${TRIGGER_ATTR_LENGTH} == "TRUE" ] ; then
			# We always rebuild both "length_m" and "length_km", so the two are sure to
			# be in sync!
			g.message -i "Adding length to attributes of 'initial' links map..."
			v.to.db map="${GIS_OPT_LINKS}" layer="1" type="line" option="length" columns="${LINKS_FLD_LEN_M}" units="meters" --quiet
			check_error "Failed to add attribute field '${LINKS_FLD_LEN_M}' to copy of initial links map."
			v.to.db map="${GIS_OPT_LINKS}" layer="1" type="line" option="length" columns="${LINKS_FLD_LEN_KM}" units="kilometers" --quiet
			check_error "Failed to add attribute field '${LINKS_FLD_LEN_KM}' to copy of initial links map."
		fi
		if [ ${TRIGGER_ATTR_COORDINATES} == TRUE ] ; then
			# TODO: This needs TESTING with faulty coordinates!
			#
			# We need to rebuild the from/to coordinate pairs for all links. These are
			# the extreme vertices of the links. The tricky part is: If these are user-supplied
			# line geometries, then we cannot trust that they lie EXACTLY at the coordinates
			# of any input nodes. However, this is a requirement, since some models match
			# links with their connected nodes via the coordinates stored in the attribute table!
			# So we try some "snapping" and hope for the best...
			#
			# Now add coordinates of extreme line vertices to attribute table.
			g.message -i "Adding start/end coordinates to attributes of 'initial' links map..."
			v.to.db map="${GIS_OPT_LINKS}" layer="1" type="line" option="end" columns="${LINKS_FLD_FROM_X},${LINKS_FLD_FROM_Y}" --quiet
			check_error "Failed to add attribute fields '${LINKS_FLD_FROM_X}' & '${LINKS_FLD_FROM_Y}' to copy of initial links map."
			v.to.db map="${GIS_OPT_LINKS}" layer="1" type="line" option="start" columns="${LINKS_FLD_TO_X},${LINKS_FLD_TO_Y}" --quiet
			check_error "Failed to add attribute fields '${LINKS_FLD_TO_X}' & '${LINKS_FLD_TO_Y}' to copy of initial links map."
			# Now check that the stored coordinates EXACTLY match those of the associated nodes.
			g.message -i "Validating start/end coordinates to attributes of 'initial' links map..."			
			#  
			# Now check that from/to x/y attributes of INITIAL links EXACTLY match ATTRIBUTE coordinates of the input nodes.     
			#     --> If the difference is < $GIS_OPT_THRESHOLD then WARN and copy the coordinate values from the nodes!
			#     --> If the difference is larger: TOPOLOGY ERROR -> EXIT (cannot trust provided coord fields!)
			# Get all GRASS primary keys ('cats') for initial links input map:
			get_grass_cats "${GIS_OPT_LINKS}"
			# Get all primary keys (GIS_OPT_KEY) for nodes input map:						
			get_primary_keys "${GIS_OPT_INPUT}"
			# Primary loop steps through all nodes in GIS_OPT_INPUT via 'key':
			IFS_BACKUP="$IFS"
			IFS="${IFS_NEWLINE}"
			step=1 # For progress reporting
			for key in ${PRIMARY_KEYS} ; do
				# Secondary loop steps through all nodes in GIS_OPT_LINKS via 'cat':
				for cat in ${GRASS_CATS} ; do					
					# Extract "from_id" and "to_id" values for current 'cat':
					val_from_id=`v.db.select map="${GIS_OPT_LINKS}" column="${LINKS_FLD_FROM_ID}" where="${GRASS_PKEY}=${cat}" -c`
					check_error "Failed to read attribute field '${LINKS_FLD_FROM_ID}' from copy of initial links map ('${GRASS_PKEY}=${cat}')."
					val_to_id=`v.db.select map="${GIS_OPT_LINKS}" column="${LINKS_FLD_TO_ID}" where="${GRASS_PKEY}=${cat}" -c`
					check_error "Failed to read attribute field '${LINKS_FLD_TO_ID}' from copy of initial links map ('${GRASS_PKEY}=${cat}')."
					# Get node coordinates if required (i.e. if current 'key' from nodes map matches a 'from' or 'to' ID from links map):
					if [ ${val_from_id} -eq ${key} ] || [ ${val_to_id} -eq ${key} ] ; then
						val_coord_x_node=`v.db.select map="${GIS_OPT_INPUT}" column="${NODES_FLD_COORD_X}" where="${GIS_OPT_KEY}=${key}" -c`
						check_error "Failed to read attribute field '${NODES_FLD_COORD_X}' from copy of nodes input map."
						val_coord_y_node=`v.db.select map="${GIS_OPT_INPUT}" column="${NODES_FLD_COORD_Y}" where="${GIS_OPT_KEY}=${key}" -c`
						check_error "Failed to read attribute field '${NODES_FLD_COORD_Y}' from copy of nodes input map."
					fi
					# Check if from/to matches current primary key. We pass to 'clean_initial_coords':
					# $1 - name of map that contains initial links
					# $2 - node coordinate value to test against
					# $3 - name of attribute field in initial links map that stores the same coordinate
					# $4 - name of primary key field in initial links map
					# $5 - primary key value to get correct record from initial links map.
					if [ ${val_from_id} -eq ${key} ] ; then
						# Check/fix FROM_X
						clean_initial_coords "${GIS_OPT_LINKS}" "${val_coord_x_node}" "${LINKS_FLD_FROM_X}" "${GRASS_PKEY}" "${cat}"
						# Check/fix FROM_Y
						clean_initial_coords "${GIS_OPT_LINKS}" "${val_coord_y_node}" "${LINKS_FLD_FROM_Y}" "${GRASS_PKEY}" "${cat}"
					fi
					if [ ${val_to_id} -eq ${key} ] ; then
						# Check/fix TO_X
						clean_initial_coords "${GIS_OPT_LINKS}" "${val_coord_x_node}" "${LINKS_FLD_TO_X}" "${GRASS_PKEY}" "${cat}"
						# Check/fix TO_Y
						clean_initial_coords "${GIS_OPT_LINKS}" "${val_coord_y_node}" "${LINKS_FLD_TO_Y}" "${GRASS_PKEY}" "${cat}"
					fi
				done
				# Progress update
				g.message -p "${step} ${NUM_INPUT_NODES} 1"
				if [ -n $BASH_VERSION ] ; then
					let step=${step}+1
				else
					step=`"${EXPR}" ${step} + 1`
				fi
			done
			IFS="${IFS_BACKUP}"
		fi
		if [ ${TRIGGER_ATTR_COST} == "TRUE" ] ; then
			g.message -i "Computing costs of links in 'initial' links map..."
			# Add 'cost' values to attribute table.
			# This one is tricky, because the links provided
			# in 'initial' might _not_ be identical with LCPs! So what we do is:
			#   1. Step through all links, and for each link do:
			#     a) rasterize the link with 'v.to.rast'
			#     b) run eval `r.univar map=rasterized_link" -g --quiet`
			#     c) read the sum of costs in all cells crossed by link from ${sum} and upload!
			g.message -i "Adding link costs to attribute table of inital links map..."
			g.message -w "Reconstructed costs are less accurate than results for model 'complete'."
			# Add 'cost' field to attribute table:
			${V_DB_ADDCOLUMN} map="${GIS_OPT_LINKS}" layer="1" columns="${LINKS_FLD_COST} DOUBLE PRECISION"
			check_error "Failed to add attribute field '${LINKS_FLD_COST}' (double) to copy of initial links map."
			# Get info for connected database and table:
			get_tbl_info "${GIS_OPT_LINKS}"
			# Process all links.
			get_grass_cats "${GIS_OPT_LINKS}"
			IFS_BACKUP="$IFS"
			IFS="${IFS_NEWLINE}"
			# Primary loop steps through all nodes in GIS_OPT_LINKS:
			step=1 # For progress reporting
			for cat in ${GRASS_CATS} ; do
				# Rasterize current link ("thin"):
				v.to.rast input="${GIS_OPT_LINKS}" output="${TMP_RAST_RSTLNKS1}" type="line" use="val" value="1" where="${GRASS_PKEY}=${cat}" --quiet --overwrite
				check_error "Failed to rasterize ('thin') link with ID '${GRASS_PKEY}=${cat}' from copy of initial links map."
				# Rasterize a second version, but this time we also rasterize cells between (-d)iagonal cells that are on the path ("thick"): 
				v.to.rast input="${GIS_OPT_LINKS}" output="${TMP_RAST_RSTLNKS2}" -d type="line" use="val" value="1" where="${GRASS_PKEY}=${cat}" --quiet --overwrite
				check_error "Failed to rasterize ('thick') link with ID '${GRASS_PKEY}=${cat}' from copy of initial links map."				
				# Diagonal movement weight:	
				# TODO: adjust depending on region's cell dimensions, just like r.cost does
				# 	    r.cost uses a very accurate weighting scheme, that applies 'DIAG_fac'
				#		(by multiplication with cost) to NW, SE, etc. movements, and 'V|H_DIAG_fac' to ESE, etc.
				#		There is no way we will be able to replicate this _exactly_, but we can compute 'DIAG_fac'
				#		and use it for 'diagonal_cost' (below).
				#
				#		This is from r.cost/main.d:
				#
				#		/* Find north-south, east_west and diagonal factors */
				#		EW_fac = 1.0;
				#		NS_fac = window.ns_res / window.ew_res;
				#		DIAG_fac = (double)sqrt((double)(NS_fac * NS_fac + EW_fac * EW_fac));
				#		V_DIAG_fac = (double)sqrt((double)(4 * NS_fac * NS_fac + EW_fac * EW_fac));							
				#		H_DIAG_fac = (double)sqrt((double)(NS_fac * NS_fac + 4 * EW_fac * EW_fac));
				#		EW_fac /= 2.0;
				#		NS_fac /= 2.0;
				#		DIAG_fac /= 2.0;
				#		V_DIAG_fac /= 4.0;
				#		H_DIAG_fac /= 4.0;
				# This weight gives 'close-enough' results for square cells, on average:
				DIAG_fac="0.188"
				# Compute total costs of LCP path.
				# Explanation: All cells on the rasterized path will be:
				#              = cost surface value (where intersected by the 'thin' (and by definition also the 'thick') rasterized path)
				#              = cost surface value * diagonal_cost (where intersected by _only_ the 'thick' rasterized path)
				#				= NULL (where intersected by _neither_ rasterized paths)
				r.mapcalc expression="${TMP_RAST_MAPCALC1}=if(!isnull(${TMP_RAST_RSTLNKS1}),${GIS_OPT_COSTMAP},${TMP_RAST_RSTLNKS2}*${GIS_OPT_COSTMAP}*${DIAG_fac})" --overwrite --quiet
				# Get univariate statistics for rasterized link:
				eval `r.univar map="${TMP_RAST_MAPCALC1}" -g --quiet`
				check_error "Failed to compute statistics for link with ID '${GRASS_PKEY}=${cat}' from copy of initial links map."
				# Upload cost value for current link:
				SQL=""
				SQL="${SQL}UPDATE ${attribute_table} SET"
				SQL="${SQL} ${LINKS_FLD_COST} = ${sum}"
				SQL="${SQL} WHERE ${GRASS_PKEY} = ${cat}; "
				"${ECHO}" "${SQL}" | db.execute database="${attribute_database}" input="-"
				#TODO: DELETEME: Below call to "v.db.update" has been replaced by an SQL statement piped into 'db.execute'!
				#${V_DB_UPDATE} map="${GIS_OPT_LINKS}" layer="1" column="${LINKS_FLD_COST}" value="${sum}" where="${GRASS_PKEY}=${cat}" --quiet
				check_error "Failed to update field '${LINKS_FLD_COST}' in copy of initial links map."
				# Progress update
				g.message -p "${step} ${points} 1"
				if [ -n $BASH_VERSION ] ; then
					let step=${step}+1
				else
					step=`"${EXPR}" ${step} + 1`
				fi
			done
			IFS="${IFS_BACKUP}"
			RUNMODE_COST="TRUE" # cost attribute exists now
		fi
	fi
else
	# Complete model needs to be computed.
	model_complete
fi

# Decide which attribute field to read for distance threshold
FLD_DIST="${LINKS_FLD_LEN_M}" # Default
UNITS_DIST="m"
if [ "${RUNMODE_COST}" == "TRUE" ] ; then
	FLD_DIST="${LINKS_FLD_COST}" # Default if costmap is provided
	UNITS_DIST="cost"		
fi
if [ ${GIS_FLAG_M} -eq 1 ] ; then
	FLD_DIST="${LINKS_FLD_LEN_M}" # Force distance units to be meters if '-m' flag is given
	UNITS_DIST="m"
fi

# Compute selected reduced model (if any).
if [ "${GIS_OPT_MODEL}" = "attsim" ] ; then
	model_attsim
fi
if [ "${GIS_OPT_MODEL}" = "delaunay" ] ; then
	model_delaunay
fi
if [ "${GIS_OPT_MODEL}" = "nn" ] ; then
	model_nn
fi
if [ "${GIS_OPT_MODEL}" = "xtent" ] ; then
	model_xtent
fi

# Reduce further if "maxdist=" is given:
if [ -n "${GIS_OPT_MAXDIST}" ] ; then
	model_linkdist
fi

if [ "${GIS_OPT_MODEL}" != "complete" ] || [ -n "${GIS_OPT_MAXDIST}" ] ; then
# Report: number of lines and connected points
	eval `v.info -t map="${GIS_OPT_LINKS}" layer="1" --quiet`
	check_error "Failed to get topology info for links output vector map."
	if [ ${lines} -lt 1 ] ; then
		exit_error "No links left in output vector map. Please review model parameter values."
	fi	
	g.message -i "${lines} links in output vector map after reduction."
fi


# DONE!

# Remove temp. maps, restore region, etc.
clean_up

# Show processing time.
g.message -i "Success."
g.message -i "Started: ${START}"
END=`"${DATE}"`
g.message -i "Completed: ${END}"

# Exit with status "OK"
exit ${EXIT_OK}
